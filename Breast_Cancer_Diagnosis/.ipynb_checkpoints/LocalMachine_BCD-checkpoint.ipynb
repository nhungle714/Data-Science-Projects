{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from skimage import color\n",
    "import copy\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import random\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "import itertools\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import copy\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Train/Valid/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = '/Users/nhungle/Box/Free/Data-Science-Projects/Breast Cancer Diagnosis_Deep Learning/excel_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_test = pd.read_csv(os.path.join(excel_path, 'calc_case_description_test_set.csv'))\n",
    "cal_train = pd.read_csv(os.path.join(excel_path, 'calc_case_description_train_set.csv'))\n",
    "mass_test = pd.read_csv(os.path.join(excel_path, 'mass_case_description_test_set.csv'))\n",
    "mass_train = pd.read_csv(os.path.join(excel_path, 'mass_case_description_train_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_test = cal_test[['patient_id','left or right breast', 'image view',\n",
    "            'pathology', 'image file path',\n",
    "        'cropped image file path', 'ROI mask file path']]\n",
    "mass_test = mass_test[['patient_id','left or right breast', 'image view',\n",
    "            'pathology', 'image file path',\n",
    "        'cropped image file path', 'ROI mask file path']]\n",
    "cal_train = cal_train[['patient_id','left or right breast', 'image view',\n",
    "        'pathology', 'image file path',\n",
    "    'cropped image file path', 'ROI mask file path']]\n",
    "mass_train = mass_train[['patient_id','left or right breast', 'image view',\n",
    "        'pathology', 'image file path',\n",
    "    'cropped image file path', 'ROI mask file path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "cal_test.dropna(axis = 0, how = 'all', inplace = True)\n",
    "mass_test.dropna(axis = 0, how = 'all', inplace = True)\n",
    "testSet = pd.concat([cal_test, mass_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid = pd.concat([cal_train, mass_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid['class'] = 0\n",
    "train_valid.loc[train_valid['pathology'] == 'BENIGN_WITHOUT_CALLBACK', 'class'] = 1\n",
    "train_valid.loc[train_valid['pathology'] == 'MALIGNANT', 'class'] = 2\n",
    "testSet['class'] = 0\n",
    "testSet.loc[testSet['pathology'] == 'BENIGN_WITHOUT_CALLBACK', 'class'] = 1\n",
    "testSet.loc[testSet['pathology'] == 'MALIGNANT', 'class'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 1248\n"
     ]
    }
   ],
   "source": [
    "patient_list = list(train_valid['patient_id'].unique())\n",
    "print('Number of patients: {}'.format(len(patient_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id_leftright = train_valid.groupby(['patient_id', 'left or right breast']).size().reset_index().rename(columns={0:'count'})\n",
    "unique_id_leftright = shuffle(unique_id_leftright)\n",
    "train_size = int(len(unique_id_leftright) * 0.8)\n",
    "#print(train_size)\n",
    "train_id_leftright = unique_id_leftright[:train_size][['patient_id', 'left or right breast']]\n",
    "valid_id_leftright = unique_id_leftright[train_size:][['patient_id', 'left or right breast']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = train_valid[(train_valid['patient_id'].isin(train_id_leftright['patient_id'])) &\n",
    "            (train_valid['left or right breast'].isin(train_id_leftright['left or right breast'])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "validSet = train_valid[(train_valid['patient_id'].isin(valid_id_leftright['patient_id'])) &\n",
    "            (train_valid['left or right breast'].isin(valid_id_leftright['left or right breast'])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "trainSet.to_csv(os.path.join(excel_path, 'trainSet.csv'))\n",
    "validSet.to_csv(os.path.join(excel_path, 'validSet.csv'))\n",
    "testSet.to_csv(os.path.join(excel_path, 'testSet.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######### Local Machine Paths ######## \n",
    "excel_path = '/Users/nhungle/Box/Free/Data-Science-Projects/Breast Cancer Diagnosis_Deep Learning/excel_files'\n",
    "train_local_csv = os.path.join(excel_path, \n",
    "                              'train_local.csv')\n",
    "validation_local_csv = os.path.join(excel_path, \n",
    "                              'validation_local.csv')\n",
    "test_local_csv = os.path.join(excel_path, \n",
    "                              'test_local.csv')\n",
    "\n",
    "image_path = '/Users/nhungle/Box/Free/Data-Science-Projects/Breast Cancer Diagnosis_Deep Learning'\n",
    "root_image = os.path.join(image_path ,'images')\n",
    "\n",
    "NUM_WORKERS = 1\n",
    "BATCH_SIZE = 2\n",
    "graph_path = '/Users/nhungle/Box/Free/Data-Science-Projects/Breast Cancer Diagnosis_Deep Learning/graphs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-e27513c12d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMamogramDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \"\"\"\n\u001b[1;32m      5\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class MamogramDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, image_column, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Csv file filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            image_column (string): name of the column image used\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.image_column = image_column\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data_frame.loc[idx, 'image_column'])\n",
    "\n",
    "        image = io.imread(img_name,as_gray=True)\n",
    "        \n",
    "        image = (image - image.mean()) / image.std()\n",
    "            \n",
    "        image_class = self.data_frame.loc[idx, 'Class']\n",
    "\n",
    "        sample = {'x': image[None,:], 'y': image_class}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataLoader(train_csv, validation_csv, test_csv, root_dir, image_column,\n",
    "               train_transform, validation_transform, \n",
    "               batch_size, shuffle, num_workers): \n",
    "    Mamogram_TrainData = MamogramDataset(csv_file = train_csv,\n",
    "                                        root_dir=root_dir, \n",
    "                                        image_column = image_column,\n",
    "                                        transform=train_transform)\n",
    "    train_loader = DataLoader(Mamogram_TrainData, batch_size=batch_size,\n",
    "                            shuffle = shuffle, num_workers = num_workers)\n",
    "\n",
    "    Mamogram_ValidationData = MamogramDataset(csv_file = validation_csv,\n",
    "                                        root_dir=root_dir, \n",
    "                                        image_column = image_column,\n",
    "                                        transform=train_transform)\n",
    "    validation_loader = DataLoader(Mamogram_ValidationData, batch_size=batch_size,\n",
    "                            shuffle = shuffle, num_workers = num_workers)\n",
    "\n",
    "\n",
    "    Mamogram_TestData = MamogramDataset(csv_file = test_csv,\n",
    "                                        root_dir=root_dir, \n",
    "                                        image_column = image_column,\n",
    "                                        transform=None)\n",
    "    test_loader = DataLoader(Mamogram_TestData, batch_size=batch_size,\n",
    "                            shuffle = shuffle, num_workers = num_workers)\n",
    "    \n",
    "    dataset_sizes = {'train': len(Mamogram_TrainData), \n",
    "                     'val': len(Mamogram_ValidationData)}\n",
    "    return train_loader, validation_loader, test_loader, dataset_sizes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
