{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from skimage import color\n",
    "import copy\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import random\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "import itertools\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import copy\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Train/Valid/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nhungle/Box/Free/Data-Science-Projects/Breast_Cancer_Diagnosis'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = '/Users/nhungle/Box/Free/Data-Science-Projects/Breast_Cancer_Diagnosis/excel_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_test = pd.read_csv(os.path.join(excel_path, 'calc_case_description_test_set.csv'))\n",
    "cal_train = pd.read_csv(os.path.join(excel_path, 'calc_case_description_train_set.csv'))\n",
    "mass_test = pd.read_csv(os.path.join(excel_path, 'mass_case_description_test_set.csv'))\n",
    "mass_train = pd.read_csv(os.path.join(excel_path, 'mass_case_description_train_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_test = cal_test[['patient_id','left or right breast', 'image view',\n",
    "            'pathology', 'image file path',\n",
    "        'cropped image file path', 'ROI mask file path']]\n",
    "mass_test = mass_test[['patient_id','left or right breast', 'image view',\n",
    "            'pathology', 'image file path',\n",
    "        'cropped image file path', 'ROI mask file path']]\n",
    "cal_train = cal_train[['patient_id','left or right breast', 'image view',\n",
    "        'pathology', 'image file path',\n",
    "    'cropped image file path', 'ROI mask file path']]\n",
    "mass_train = mass_train[['patient_id','left or right breast', 'image view',\n",
    "        'pathology', 'image file path',\n",
    "    'cropped image file path', 'ROI mask file path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_test.dropna(axis = 0, how = 'all', inplace = True)\n",
    "mass_test.dropna(axis = 0, how = 'all', inplace = True)\n",
    "testSet = pd.concat([cal_test, mass_test], axis=0)\n",
    "train_valid = pd.concat([cal_train, mass_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid['class'] = 0\n",
    "train_valid.loc[train_valid['pathology'] == 'MALIGNANT', 'class'] = 1\n",
    "testSet['class'] = 0\n",
    "testSet.loc[testSet['pathology'] == 'MALIGNANT', 'class'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 1248\n"
     ]
    }
   ],
   "source": [
    "patient_list = list(train_valid['patient_id'].unique())\n",
    "print('Number of patients: {}'.format(len(patient_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id_leftright = train_valid.groupby(['patient_id', 'left or right breast']).size().reset_index().rename(columns={0:'count'})\n",
    "unique_id_leftright = shuffle(unique_id_leftright)\n",
    "train_size = int(len(unique_id_leftright) * 0.8)\n",
    "#print(train_size)\n",
    "train_id_leftright = unique_id_leftright[:train_size][['patient_id', 'left or right breast']]\n",
    "valid_id_leftright = unique_id_leftright[train_size:][['patient_id', 'left or right breast']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = train_valid[(train_valid['patient_id'].isin(train_id_leftright['patient_id'])) &\n",
    "            (train_valid['left or right breast'].isin(train_id_leftright['left or right breast'])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validSet = train_valid[(train_valid['patient_id'].isin(valid_id_leftright['patient_id'])) &\n",
    "            (train_valid['left or right breast'].isin(valid_id_leftright['left or right breast'])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "trainSet.to_csv(os.path.join(excel_path, 'twoClass_trainSet.csv'))\n",
    "validSet.to_csv(os.path.join(excel_path, 'twoClass_validSet.csv'))\n",
    "testSet.to_csv(os.path.join(excel_path, 'twoClass_testSet.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a subset of data \n",
    "trainSet_sample = trainSet[:500]\n",
    "valSet_sample = validSet[:100]\n",
    "testSet_sample = testSet[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet_sample.to_csv(os.path.join(excel_path, 'twoClass_trainSet_sample.csv'))\n",
    "valSet_sample.to_csv(os.path.join(excel_path, 'twoClass_validSet_sample.csv'))\n",
    "testSet_sample.to_csv(os.path.join(excel_path, 'twoClass_testSet_sample.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MamogramDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, image_column, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Csv file filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            image_column (string): name of the column image used\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.image_column = image_column\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data_frame.loc[idx, 'image_column'])\n",
    "\n",
    "        image = io.imread(img_name,as_gray=True)\n",
    "        \n",
    "        image = (image - image.mean()) / image.std()\n",
    "            \n",
    "        image_class = self.data_frame.loc[idx, 'Class']\n",
    "\n",
    "        sample = {'x': image[None,:], 'y': image_class}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataLoader(train_csv, validation_csv, test_csv, root_dir, image_column,\n",
    "               train_transform, validation_transform, \n",
    "               batch_size, shuffle, num_workers): \n",
    "\n",
    "    train_data = MamogramDataset(csv_file = train_csv, \n",
    "                              root_dir = root_image,\n",
    "                              image_column = image_column,\n",
    "                               transform=train_transform)\n",
    "    val_data = MamogramDataset(csv_file = validation_csv, \n",
    "                            root_dir = root_image,\n",
    "                            image_column = image_column,\n",
    "                            transform = validation_transform)\n",
    "    test_data = MamogramDataset(csv_file = test_csv, \n",
    "                            root_dir = root_image,\n",
    "                            image_column = image_column,\n",
    "                            transform = validation_transform)\n",
    "    \n",
    "    image_datasets = {'train': train_data, 'val': val_data, 'test': test_data}\n",
    "#     train_loader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "#                             shuffle = shuffle, num_workers = NUM_WORKERS)\n",
    "#     val_loader = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "#                             shuffle = shuffle, num_workers = NUM_WORKERS)\n",
    "#     test_loader = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "#                             shuffle = shuffle, num_workers = NUM_WORKERS)\n",
    "    \n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                              batch_size=BATCH_SIZE, \n",
    "                                              shuffle=True, \n",
    "                                              num_workers=NUM_WORKERS) \n",
    "                    for x in ['train', 'val', 'test']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "#     print(len(image_datasets['train']), \n",
    "#           len(image_datasets['val']),\n",
    "#          len(image_datasets['test']))\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs = 10,verbose = True):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    acc_dict = {'train':[],'validation':[]}\n",
    "    loss_dict = {'train':[],'validation':[]}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            if epoch % 5 == 4:\n",
    "                print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "                print('-' * 10)\n",
    "            \n",
    "        for phase in ['train','val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for data in dataloaders[phase]:\n",
    "                \n",
    "                inputs = data['x']\n",
    "                labels = data['y']\n",
    "                \n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "                    labels = labels.to(device)\n",
    "                else:\n",
    "                    inputs = Variable(inputs).type(torch.FloatTensor)\n",
    "                    labels = Variable(labels).type(torch.LongTensor)\n",
    "\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                out = model(inputs)\n",
    "                _, preds = torch.max(out, dim = 1)\n",
    "                loss = criterion(out, labels)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                running_loss += loss.item() * inputs.size()[0]\n",
    "                running_corrects += torch.sum(preds == labels).item()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            if verbose:\n",
    "                if epoch % 5 == 4:\n",
    "                    print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'train':\n",
    "                loss_dict['train'].append(epoch_loss)\n",
    "                acc_dict['train'].append(epoch_acc)\n",
    "            else:\n",
    "                loss_dict['validation'].append(epoch_loss)\n",
    "                acc_dict['validation'].append(epoch_acc)\n",
    "                    \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                scheduler.step(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print('Training time: {}minutes {}s'.format(int(time_elapsed / 60), time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # for i, phase in enumerate(['train','validation']):\n",
    "\n",
    "    #     fig = plt.figure()\n",
    "        \n",
    "    #     a = fig.add_subplot(1,2,1*i+1)\n",
    "    #     plt.plot(loss_dict[phase])\n",
    "    #     plt.title('Loss per epoch for ' + phase)\n",
    "\n",
    "    #     a = fig.add_subplot(1,2,1*i+2)\n",
    "    #     plt.plot(acc_dict[phase])\n",
    "    #     plt.title('Accuracy per epoch for ' + phase)\n",
    "    #     plt.show()\n",
    "    #     plt.savefig(os.path.join(graph_path ,'Curve {}.png'.format(phase)))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model, os.path.join(graph_path, 'BestResNet34_tl.pt'))\n",
    "    \n",
    "    return {'Model': model, 'LossDict': loss_dict, 'AccDict': acc_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######### Local Machine Paths ######## \n",
    "excel_path = '/Users/nhungle/Box/Free/Data-Science-Projects/Breast_Cancer_Diagnosis/excel_files'\n",
    "train_local_csv = os.path.join(excel_path, \n",
    "                              'train_local.csv')\n",
    "validation_local_csv = os.path.join(excel_path, \n",
    "                              'validation_local.csv')\n",
    "test_local_csv = os.path.join(excel_path, \n",
    "                              'test_local.csv')\n",
    "\n",
    "image_path = '/Users/nhungle/Box/Free/Data-Science-Projects/Breast_Cancer_Diagnosis'\n",
    "root_image = os.path.join(image_path ,'images')\n",
    "\n",
    "NUM_WORKERS = 1\n",
    "BATCH_SIZE = 1\n",
    "graph_path = '/Users/nhungle/Box/Free/Data-Science-Projects/Breast_Cancer_Diagnosis/graphs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######### HPC Paths ######## \n",
    "# excel_path = '/home/nhl256/BreastCancer/excel_files'\n",
    "# train_local_csv = os.path.join(excel_path, \n",
    "#                              'trainSet.csv')\n",
    "# validation_local_csv = os.path.join(excel_path, \n",
    "#                               \"validationSet.csv\")\n",
    "# test_local_csv = os.path.join(excel_path, \n",
    "#                               \"testSet.csv\")\n",
    "\n",
    "# image_path = '/scratch/bva212/breastCancerData'\n",
    "# root_image = os.path.join(image_path ,'CBIS-DDSM')\n",
    "\n",
    "# NUM_WORKERS = 4\n",
    "# BATCH_SIZE = 16\n",
    "# graph_path = '/home/nhl256/HW2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if torch.cuda.is_available:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "#### Get Dataloaders and Datasets_sizes\n",
    "dataloaders, dataset_sizes = GetDataLoader(train_csv = train_local_csv, \n",
    "                                            validation_csv = validation_local_csv, \n",
    "                                            test_csv = test_local_csv, \n",
    "                                            root_dir = root_image, \n",
    "                                           image_column = 'local_image',\n",
    "               train_transform = None, validation_transform = None, \n",
    "               batch_size = BATCH_SIZE, shuffle = True, num_workers = NUM_WORKERS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(os.path.join(excel_path, 'train_local.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train/validatin/test local set to run code locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageName(image_string): \n",
    "    return image_string.split('/')[3].split('-')[-1] + '.dcm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "trainSet['local_image'] = ''\n",
    "trainSet['local_image'] = trainSet['image file path'].apply(lambda x: getImageName(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>left or right breast</th>\n",
       "      <th>image view</th>\n",
       "      <th>pathology</th>\n",
       "      <th>image file path</th>\n",
       "      <th>cropped image file path</th>\n",
       "      <th>ROI mask file path</th>\n",
       "      <th>class</th>\n",
       "      <th>local_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_00005</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>CC</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00005_RIGHT_CC/08-07...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00005_RIGHT_CC_1/08-...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00005_RIGHT_CC_1/08-...</td>\n",
       "      <td>1</td>\n",
       "      <td>38548.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_00005</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00005_RIGHT_MLO/08-0...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00005_RIGHT_MLO_1/09...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00005_RIGHT_MLO_1/09...</td>\n",
       "      <td>1</td>\n",
       "      <td>96727.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_00007</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00007_LEFT_CC/08-07-...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00007_LEFT_CC_1/09-0...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00007_LEFT_CC_1/09-0...</td>\n",
       "      <td>0</td>\n",
       "      <td>68297.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_00007</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00007_LEFT_MLO/08-07...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00007_LEFT_MLO_1/09-...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00007_LEFT_MLO_1/09-...</td>\n",
       "      <td>0</td>\n",
       "      <td>00446.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P_00008</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>BENIGN_WITHOUT_CALLBACK</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00008_LEFT_MLO/08-07...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00008_LEFT_MLO_1/09-...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00008_LEFT_MLO_1/09-...</td>\n",
       "      <td>0</td>\n",
       "      <td>97907.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P_00008</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>BENIGN_WITHOUT_CALLBACK</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00008_RIGHT_MLO/08-0...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00008_RIGHT_MLO_1/09...</td>\n",
       "      <td>CBIS-DDSM/Calc-Training_P_00008_RIGHT_MLO_1/09...</td>\n",
       "      <td>0</td>\n",
       "      <td>32980.dcm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id left or right breast image view                pathology  \\\n",
       "0    P_00005                RIGHT         CC                MALIGNANT   \n",
       "1    P_00005                RIGHT        MLO                MALIGNANT   \n",
       "2    P_00007                 LEFT         CC                   BENIGN   \n",
       "3    P_00007                 LEFT        MLO                   BENIGN   \n",
       "5    P_00008                 LEFT        MLO  BENIGN_WITHOUT_CALLBACK   \n",
       "7    P_00008                RIGHT        MLO  BENIGN_WITHOUT_CALLBACK   \n",
       "\n",
       "                                     image file path  \\\n",
       "0  CBIS-DDSM/Calc-Training_P_00005_RIGHT_CC/08-07...   \n",
       "1  CBIS-DDSM/Calc-Training_P_00005_RIGHT_MLO/08-0...   \n",
       "2  CBIS-DDSM/Calc-Training_P_00007_LEFT_CC/08-07-...   \n",
       "3  CBIS-DDSM/Calc-Training_P_00007_LEFT_MLO/08-07...   \n",
       "5  CBIS-DDSM/Calc-Training_P_00008_LEFT_MLO/08-07...   \n",
       "7  CBIS-DDSM/Calc-Training_P_00008_RIGHT_MLO/08-0...   \n",
       "\n",
       "                             cropped image file path  \\\n",
       "0  CBIS-DDSM/Calc-Training_P_00005_RIGHT_CC_1/08-...   \n",
       "1  CBIS-DDSM/Calc-Training_P_00005_RIGHT_MLO_1/09...   \n",
       "2  CBIS-DDSM/Calc-Training_P_00007_LEFT_CC_1/09-0...   \n",
       "3  CBIS-DDSM/Calc-Training_P_00007_LEFT_MLO_1/09-...   \n",
       "5  CBIS-DDSM/Calc-Training_P_00008_LEFT_MLO_1/09-...   \n",
       "7  CBIS-DDSM/Calc-Training_P_00008_RIGHT_MLO_1/09...   \n",
       "\n",
       "                                  ROI mask file path  class local_image  \n",
       "0  CBIS-DDSM/Calc-Training_P_00005_RIGHT_CC_1/08-...      1   38548.dcm  \n",
       "1  CBIS-DDSM/Calc-Training_P_00005_RIGHT_MLO_1/09...      1   96727.dcm  \n",
       "2  CBIS-DDSM/Calc-Training_P_00007_LEFT_CC_1/09-0...      0   68297.dcm  \n",
       "3  CBIS-DDSM/Calc-Training_P_00007_LEFT_MLO_1/09-...      0   00446.dcm  \n",
       "5  CBIS-DDSM/Calc-Training_P_00008_LEFT_MLO_1/09-...      0   97907.dcm  \n",
       "7  CBIS-DDSM/Calc-Training_P_00008_RIGHT_MLO_1/09...      0   32980.dcm  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_files = ['00446.dcm', '32980.dcm', '38548.dcm', '44292.dcm', '64189.dcm', '64555.dcm', \n",
    "         '68297.dcm', '83789.dcm', '96727.dcm', '97907.dcm']\n",
    "local_frame = trainSet[trainSet['local_image'].isin(images_files)]\n",
    "\n",
    "local_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local = local_frame[:4]\n",
    "validation_local = local_frame[4:5]\n",
    "test_local = local_frame[5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local.to_csv(os.path.join(excel_path, 'train_local.csv'))\n",
    "validation_local.to_csv(os.path.join(excel_path, 'validation_local.csv'))\n",
    "test_local.to_csv(os.path.join(excel_path, 'test_local.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_temp = pd.read_csv(os.path.join(excel_path, 'train_local.csv'))\n",
    "train_temp.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
