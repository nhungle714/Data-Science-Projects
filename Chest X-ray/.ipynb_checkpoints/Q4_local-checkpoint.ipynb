{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from skimage import color\n",
    "import copy\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import random\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "import itertools\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import copy\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"Chest X-ray dataset from https://nihcc.app.box.com/v/ChestXray-NIHCC.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data_frame.loc[idx, 'Image Index'])\n",
    "\n",
    "        image = io.imread(img_name,as_gray=True)\n",
    "        \n",
    "        image = (image - image.mean()) / image.std()\n",
    "            \n",
    "        image_class = self.data_frame.loc[idx, 'Class']\n",
    "\n",
    "        sample = {'x': image[None,:], 'y': image_class}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Define train, validation, and test loaders \n",
    "#################################################\n",
    "\n",
    "\n",
    "def GetDataLoader(train_csv, validation_csv, test_csv, root_dir, \n",
    "               train_transform, validation_transform, \n",
    "               batch_size, shuffle, num_workers): \n",
    "    chestXray_TrainData = ChestXrayDataset(csv_file = train_csv,\n",
    "                                        root_dir=root_dir, transform=train_transform)\n",
    "    train_loader = DataLoader(chestXray_TrainData, batch_size=batch_size,\n",
    "                            shuffle = shuffle, num_workers = num_workers)\n",
    "\n",
    "    chestXray_ValidationData = ChestXrayDataset(csv_file = validation_csv, \n",
    "                                                   root_dir=root_dir, \n",
    "                                                   transform = validation_transform)\n",
    "    validation_loader = DataLoader(chestXray_ValidationData, \n",
    "                                   batch_size =batch_size, \n",
    "                                   shuffle = shuffle, num_workers = num_workers)\n",
    "\n",
    "\n",
    "    chestXray_TestData = ChestXrayDataset(csv_file = test_csv, \n",
    "                                                   root_dir=root_dir, \n",
    "                                                   transform=None)\n",
    "    test_loader = DataLoader(chestXray_TestData, \n",
    "                             batch_size = batch_size, \n",
    "                             shuffle = shuffle, num_workers = num_workers)\n",
    "\n",
    "    return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs, data_sizes,\n",
    "               trainVal = ['train', 'val'], verbose = True): \n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0\n",
    "    best_loss = np.inf\n",
    "    loss_hist = {'train': [], 'val': []}\n",
    "    accuracy_hist = {'train': [], 'val': []}\n",
    "    \n",
    "    for epoch in range(num_epochs): \n",
    "        if verbose:\n",
    "            print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "            print('-' * 20)\n",
    "            \n",
    "        for phase in trainVal: \n",
    "            if phase == 'train': \n",
    "                imageLoader = train_loader\n",
    "            else:\n",
    "                imageLoader = validation_loader\n",
    "            print('Phase {}'.format(phase))\n",
    "        \n",
    "            cur_loss = 0\n",
    "            cur_correct = 0\n",
    "            \n",
    "            for sample in imageLoader: \n",
    "                x_input = sample['x']\n",
    "                y_true = sample['y']\n",
    "                \n",
    "                x_input = Variable(x_input).type(torch.FloatTensor)\n",
    "                y_true = Variable(y_true).type(torch.LongTensor)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                y_pred = model(x_input)\n",
    "                _, preds = torch.max(y_pred.data, 1)\n",
    "                loss = criterion(y_pred, y_true)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                \n",
    "                cur_loss += loss.data * x_input.size(0)\n",
    "                cur_correct += torch.sum(preds == y_true.data).item()\n",
    "                \n",
    "                #print(\"preds, y_true\", preds, y_true)\n",
    "                #print(\"cur_correct\", cur_correct)\n",
    "                \n",
    "            epoch_loss = cur_loss / data_sizes[phase]\n",
    "            epoch_acc = cur_correct / data_sizes[phase]\n",
    "\n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'train':\n",
    "                loss_hist['train'].append(epoch_loss)\n",
    "                accuracy_hist['train'].append(epoch_acc)\n",
    "            else:\n",
    "                loss_hist['val'].append(epoch_loss)\n",
    "                accuracy_hist['val'].append(epoch_acc)\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_accuracy = epoch_acc\n",
    "                best_weights = copy.deepcopy(model.state_dict())\n",
    "                best_loss = epoch_loss\n",
    "\n",
    "    print('Best Validation Acc: {:4f}'.format(best_accuracy))\n",
    "    \n",
    "    return model, loss_hist, accuracy_hist, best_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Local Machine Paths ######## \n",
    "excel_path = '/Users/nhungle/Box/Free/Deep Learning in Medicine/Deep-Learning-in-Medicine/HW2'\n",
    "train_local_csv = os.path.join(excel_path, \n",
    "                              'train_local.csv')\n",
    "validation_local_csv = os.path.join(excel_path, \n",
    "                              'validation_local.csv')\n",
    "test_local_csv = os.path.join(excel_path, \n",
    "                              'test_local.csv')\n",
    "\n",
    "image_path = '/Users/nhungle/Box/Free/Deep Learning in Medicine/Deep-Learning-in-Medicine/HW2'\n",
    "root_image = os.path.join(image_path ,'images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Loader Data ######\n",
    "train_loader, validation_loader, test_loader = GetDataLoader(train_csv = train_local_csv, validation_csv=validation_local_csv, test_csv=test_local_csv, \n",
    "               root_dir = root_image, train_transform=None, \n",
    "                validation_transform=None, \n",
    "               batch_size=1, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "data_sizes = {'train': len(train_loader), 'val': len(validation_loader)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 7, 'val': 2}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) CNN model definition (6 points)\n",
    "Since now we can import images for model training, next step is to define a CNN model that you will use to train disease classification task. Any model requires us to select model parameters like how many layers, what is the kernel size, how many feature maps and so on. The number of possible models is infinite, but we need to make some design choices to start. Lets design a CNN model with 2 convolutional layers, 2 residual units (similar to Figure 2 of https://arxiv.org/pdf/1512.03385.pdf) and a fully connected layer followed by a classification layer. Lets use\n",
    "\n",
    "3x3 convolution kernels (stride 1 in resnet units and stride 2 in convolutional layers)\n",
    "ReLU for an activation function\n",
    "max pooling with kernel 2x2 and stride 2 only after the convolutional layers.\n",
    "Define the number of feature maps in hidden layers as: 16, 16, 16, 32, 32, 32, 64 (1st layer, ..., 7th layer).\n",
    "\n",
    "Input --> Convolution1 --> ResNetBlock1 --> Convolution2 --> ResNetBlock2 --> FC --> Output\n",
    "\n",
    "Write a class which specifies this network details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Test for model\n",
    "chestXray_TrainData = ChestXrayDataset(csv_file = train_local_csv,\n",
    "                                        root_dir=root_image, transform=None)\n",
    "train_loader_t = DataLoader(chestXray_TrainData, batch_size=2,\n",
    "                            shuffle = True, num_workers =1)\n",
    "# idx = 0\n",
    "# data_frame = pd.read_csv(train_local_csv)\n",
    "# img_name_t = os.path.join(root_image,\n",
    "#                           data_frame.loc[idx, 'Image Index'])\n",
    "# image = io.imread(img_name_t ,as_gray=True)\n",
    "# image = (image - image.mean()) / image.std()\n",
    "            \n",
    "# image_class = data_frame.loc[idx, 'Class']\n",
    "\n",
    "# #image = Variable(image).type(torch.FloatTensor)\n",
    "# image = Variable(torch.from_numpy((image[np.newaxis,:])), requires_grad=False)\n",
    "# image=image.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after conv1 torch.Size([2, 16, 255, 255])\n",
      "shape after ResNet1 torch.Size([2, 16, 255, 255])\n",
      "shape after conv2 torch.Size([2, 32, 63, 63])\n",
      "shape after ResNet2 torch.Size([2, 32, 63, 63])\n",
      "shape of final torch.Size([2, 2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-2fb7fffb6226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv_ResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "model = Convnet5Layer()\n",
    "for sample in train_loader_t:\n",
    "    #print(sample['x'].shape)\n",
    "    x_input = sample['x']\n",
    "    y_true = sample['y']\n",
    "    x_input = Variable(x_input).type(torch.FloatTensor)\n",
    "    y_true = Variable(y_true).type(torch.LongTensor)\n",
    "    \n",
    "    #model(x_input)\n",
    "    conv1 = nn.Sequential(         # image shape (1, 1024, 1024)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # number of input channels\n",
    "                out_channels=16,            # number of output filters\n",
    "                kernel_size=3,              \n",
    "                stride=2                # stride ofor the conv operation                 \n",
    "            ),                              # output shape (16, 1024, 1024)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 255, 255)\n",
    "        )\n",
    "    img_conv1 = conv1(x_input)\n",
    "    print(\"shape after conv1\", img_conv1.size())\n",
    "    \n",
    "    res1_conv1 = nn.Conv2d(16, 16, 3, stride= 1, dilation = 1, padding= 1)\n",
    "    relu = nn.ReLU(inplace = True)\n",
    "    \n",
    "    residual = img_conv1 \n",
    "    image_res1 = res1_conv1(img_conv1)\n",
    "    image_res1 = relu(image_res1)\n",
    "    image_res1 = res1_conv1(image_res1)\n",
    "    image_res1 += residual\n",
    "    image_res1 = relu(image_res1)\n",
    "    print(\"shape after ResNet1\", image_res1.size())\n",
    "    \n",
    "    \n",
    "    conv2 = nn.Sequential(         # image shape (16, 255, 255)\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,              # number of input channels\n",
    "                out_channels=32,            # number of output filters\n",
    "                kernel_size=3,              \n",
    "                stride=2                # stride ofor the conv operation                 \n",
    "            ),                              # \n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (32, 63, 63)\n",
    "        )\n",
    "    img_conv2 = conv2(image_res1)\n",
    "    print(\"shape after conv2\", img_conv2.size())\n",
    "    \n",
    "    \n",
    "    res2_conv1 = nn.Conv2d(32, 32, 3, stride= 1, dilation = 1, padding= 1)\n",
    "    relu = nn.ReLU(inplace = True)\n",
    "    \n",
    "    residual = img_conv2 \n",
    "    image_res2 = res2_conv1(img_conv2)\n",
    "    image_res2 = relu(image_res2)\n",
    "    image_res2 = res2_conv1(image_res2)\n",
    "    image_res2 += residual\n",
    "    image_res2 = relu(image_res2)\n",
    "    print(\"shape after ResNet2\", image_res2.size())\n",
    "    \n",
    "    fc1 = nn.Linear(127008, 64)\n",
    "    #print(image_res2.size(0))\n",
    "    image_res2 = image_res2.view(image_res2.size(0), -1)\n",
    "    image_fc = fc1(image_res2)\n",
    "\n",
    "    \n",
    "    final = relu(image_fc)\n",
    "    out = nn.Linear(64, 2)\n",
    "    final = out(final)\n",
    "    print(\"shape of final\", final.size())\n",
    "    \n",
    "    model = Conv_ResNet()\n",
    "    model(x_input)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv_ResNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(         # image shape (1, 1024, 1024)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # number of input channels\n",
    "                out_channels=16,            # number of output filters\n",
    "                kernel_size=3,              \n",
    "                stride=2                # stride ofor the conv operation                 \n",
    "            ),                              # output shape (16, 1024, 1024)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 255, 255)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.res1_conv1 = nn.Conv2d(16, 16, 3, stride= 1, dilation = 1, padding= 1)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(         # image shape (16, 255, 255)\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,              # number of input channels\n",
    "                out_channels=32,            # number of output filters\n",
    "                kernel_size=3,              \n",
    "                stride=2                # stride ofor the conv operation                 \n",
    "            ),                              # \n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (32, 63, 63)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.res2_conv1 = nn.Conv2d(32, 32, 3, stride= 1, dilation = 1, padding= 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(127008, 64)\n",
    "        self.out = nn.Linear(64, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x): \n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        residual = x\n",
    "        image_res1 = res1_conv1(x)\n",
    "        image_res1 = relu(image_res1)\n",
    "        image_res1 = res1_conv1(image_res1)\n",
    "        image_res1 += residual\n",
    "        image_res1 = relu(image_res1)\n",
    "        \n",
    "        image_res1 = conv2(image_res1)\n",
    "        \n",
    "        residual = image_res1\n",
    "        image_res2 = res2_conv1(image_res1)\n",
    "        image_res2 = relu(image_res2)\n",
    "        image_res2 = res2_conv1(image_res2)\n",
    "        image_res2 += residual\n",
    "        image_res2 = relu(image_res2)\n",
    "        \n",
    "        image_res2 = image_res2.view(image_res2.size(0), -1)\n",
    "        image_fc = fc1(image_res2)\n",
    "        \n",
    "        final = relu(image_fc)\n",
    "        final = out(final)\n",
    "        \n",
    "        return final\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convnet5Layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Convnet5Layer, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(         # image shape (1, 1024, 1024)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # number of input channels\n",
    "                out_channels=16,            # number of output filters\n",
    "                kernel_size=3,              \n",
    "                stride=2                # stride ofor the conv operation                 \n",
    "            ),                              # output shape (16, 1024, 1024)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 512, 512)\n",
    "        )\n",
    "\n",
    "        self.res1_conv1 = nn.Conv2d(16, 16, 3, stride= 1, padding= 1)\n",
    "        self.res1_conv2 =  nn.Conv2d(16, 16, 3, stride= 1, padding= 1)\n",
    "\n",
    "        self.conv2 = nn.Sequential(         # image shape (1, 1024, 1024)\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,              # number of input channels\n",
    "                out_channels=32,            # number of output filters\n",
    "                kernel_size=3,              \n",
    "                stride=2                # stride ofor the conv operation                 \n",
    "            ),                              # output shape (16, 1024, 1024)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 512, 512)\n",
    "        )\n",
    "\n",
    "        self.res2_conv1 = nn.Conv2d(32, 32, 3, stride= 1, padding= 1)\n",
    "        self.res2_conv2 = nn.Conv2d(32, 32, 3, stride= 1, padding= 1)\n",
    "\n",
    "        self.fc = nn.Linear(127008, 64)\n",
    "        self.out = nn.Linear(64, 2) \n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.conv1(x)\n",
    "\n",
    "        residual1 = x \n",
    "        #out = F.relu(self.res1_conv1(x))\n",
    "        out = self.res1_conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.res1_conv2(out)\n",
    "        out += residual1\n",
    "        out = F.relu(out) \n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        residual2 = out\n",
    "        out1 = F.relu(self.res2_conv1(out))\n",
    "        out1 = self.res2_conv2(out1)\n",
    "        out1 += residual2 \n",
    "        out1 = F.relu(out1) \n",
    "\n",
    "        out1 = out1.view(out1.size(0), -1)\n",
    "        out1 = F.relu(self.fc(out1))\n",
    "\n",
    "        out1 = self.out(out1) \n",
    "\n",
    "        return out1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_ResNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (res1_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (res2_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=127008, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Conv_ResNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "--------------------\n",
      "Phase train\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-657e15d08390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m model_ft, model_ft_loss, model_ft_acc, model_ft_weights = train_model(model, criterion, optimizer=optimizer, \n\u001b[1;32m     13\u001b[0m                     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                trainVal = ['train', 'val'], verbose = True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-87-96ff5a839d11>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs, data_sizes, trainVal, verbose)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "########## Get the model and train ####### \n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "model = Convnet5Layer()\n",
    "model.train()  \n",
    "model_ft, model_ft_loss, model_ft_acc, model_ft_weights = train_model(model, criterion, optimizer=optimizer, \n",
    "                    num_epochs=3, data_sizes = data_sizes,\n",
    "               trainVal = ['train', 'val'], verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
