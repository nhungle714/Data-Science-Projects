{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch.optim.lr_scheduler as sched\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "data_root = os.path.join(root, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pickle.load(open(os.path.join(data_root, 'train_X.pickle'), \"rb\"))\n",
    "train_y = pickle.load(open(os.path.join(data_root, 'train_y.pickle'), \"rb\"))\n",
    "test_X = pickle.load(open(os.path.join(data_root, 'test_X.pickle'), \"rb\"))\n",
    "test_y = pickle.load(open(os.path.join(data_root, 'test_y.pickle'), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class ICUDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, input_array, label_df):\n",
    "        # Args:\n",
    "        #      input_array: list of list\n",
    "        #      label_array: list of list\n",
    "        \n",
    "        super(ICUDataset, self).__init__()\n",
    "        self.input_tensors = []\n",
    "        self.labels = torch.tensor(list(label_df.iloc[:,-1]), dtype=torch.long)\n",
    "        for sample in input_array:\n",
    "            self.input_tensors.append(torch.tensor([sample[:]], dtype=torch.float))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_tensors)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.input_tensors[index]\n",
    "        # want to have y as tensor([1]), for 1 being class\n",
    "        y = self.labels[index]\n",
    "                   \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = ICUDataset(train_X, train_y)\n",
    "data_test = ICUDataset(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data train\n",
    "x, y = next(iter(data_train))\n",
    "x.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_loader = DataLoader(data_train, batch_size = 64, shuffle=False, num_workers=4)\n",
    "data_test_loader = DataLoader(data_test, batch_size = 64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to have x.shape = [batch_size, height, width = len of input]\n",
    "# y.shape = [batch_size, 1] because y is a class\n",
    "x, y = next(iter(data_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.contiguous().view(-1,input_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_train_loader, data_train, optimizer, criterion):\n",
    "    y_true_list_train = []\n",
    "    y_score_list_train = []\n",
    "    num_correct = 0\n",
    "    cur_loss = 0\n",
    "    losslisttrain = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for iter_, (inputs, targets) in enumerate(data_train_loader):\n",
    "#         if iter_ % 500 == 0:\n",
    "#             print(\"Train Phase: Iteration {}/{}\".format(iter_+1, len(data_train_loader)))\n",
    "\n",
    "        # zero out the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Setup for forward\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "\n",
    "\n",
    "        # Feed forward to get the logits\n",
    "        logit = model(inputs)\n",
    "        loss = criterion(logit, targets)\n",
    "        loss_val = loss.item()\n",
    "        cur_loss += loss_val * batch_size\n",
    "        #print('cur_loss', cur_loss)\n",
    "\n",
    "        # Add y_true and y_pred to list to calculate AUC score\n",
    "        y_true_list_train += targets.data.tolist()\n",
    "        y_pred = logit.argmax(dim=1)\n",
    "        num_correct += (y_pred == targets).sum().item()\n",
    "        y_score_list_train += logit.data.numpy()[:, 1].tolist()\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    avg_train_loss = cur_loss / len(data_train)\n",
    "    losslisttrain.append(avg_train_loss)\n",
    "\n",
    "    train_auc =  roc_auc_score(y_true=(np.array(y_true_list_train)==1),\n",
    "                               y_score=np.array(y_score_list_train))\n",
    "\n",
    "\n",
    "    train_acc = (num_correct / len(data_train)) * 100 \n",
    "    print(f'Train Loss: {avg_train_loss:.4f}')\n",
    "    print(f'Train AUC: {train_auc:.4f}')\n",
    "    print(f'Train ACC: {train_acc:.4f}')\n",
    "\n",
    "    return(avg_train_loss, train_auc, train_acc, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_test_loader, data_test):\n",
    "    y_true_list_test = []\n",
    "    y_score_list_test = []\n",
    "    num_correct = 0\n",
    "    cur_loss = 0\n",
    "    losslisttest = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for iter_, (inputs, targets) in enumerate(data_test_loader):\n",
    "#         if iter_ % 500 == 0:\n",
    "#             print(\"Valid Phase: Iteration {}/{}\".format(iter_+1, len(data_test_loader)))\n",
    "        # Setup for forward\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "\n",
    "        # Feed forward to get the logits\n",
    "        logit = model(inputs)\n",
    "        loss = criterion(logit, targets)\n",
    "        loss_val = loss.item()\n",
    "        cur_loss += loss_val * batch_size\n",
    "        #print('cur_loss', cur_loss)\n",
    "\n",
    "        # Add y_true and y_pred to list to calculate AUC score\n",
    "        y_true_list_test += targets.data.tolist()\n",
    "        y_pred = logit.argmax(dim=1)\n",
    "        num_correct += (y_pred == targets).sum().item()\n",
    "        y_score_list_test += logit.data.numpy()[:, 1].tolist()\n",
    "\n",
    "\n",
    "\n",
    "    avg_test_loss = cur_loss / len(data_test)\n",
    "    losslisttest.append(avg_test_loss)\n",
    "\n",
    "    test_auc =  roc_auc_score(y_true=(np.array(y_true_list_test)==1),\n",
    "                               y_score=np.array(y_score_list_test))\n",
    "\n",
    "\n",
    "    test_acc = (num_correct / len(data_test)) * 100 \n",
    "    print(f'Valid Loss: {avg_test_loss:.4f}')\n",
    "    print(f'Valid AUC: {test_auc:.4f}')\n",
    "    print(f'Valid ACC: {test_acc:.4f}')\n",
    "\n",
    "    return(avg_test_loss, test_auc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid(model, data_train_loader, data_train, optimizer, criterion,\n",
    "                data_test_loader, data_test, num_epochs):\n",
    "    best_val_loss = 1000\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    history_train = {'loss': [], 'acc': [], 'auc': []}\n",
    "    history_test = {'loss': [], 'acc': [], 'auc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_train_loss, train_auc, train_acc, model = train(model, data_train_loader,\n",
    "                                                            data_train, optimizer, criterion)\n",
    "        avg_test_loss, test_auc, test_acc = test(model, data_test_loader, data_test)\n",
    "        history_train['loss'].append(avg_train_loss)\n",
    "        history_train['auc'].append(train_auc)\n",
    "        history_train['acc'].append(train_acc)\n",
    "        history_test['loss'].append(avg_test_loss)\n",
    "        history_test['auc'].append(test_auc)\n",
    "        history_test['acc'].append(test_acc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if avg_test_loss < best_val_loss:\n",
    "            best_val_loss = avg_test_loss\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        print('-'*20)\n",
    "    return (best_weights, metrics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn package also has different loss functions.\n",
    "# we use Cross Entropy loss for our regression task\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# we use the optim package to apply\n",
    "# stochastic gradient descent for our parameter updates\n",
    "# built-in L2\n",
    "learning_rate = 1e-3\n",
    "lambda_l2 = 1e-5\n",
    "\n",
    "input_size = 412\n",
    "hidden_size = 200\n",
    "output_size = 2\n",
    "\n",
    "model = MLPNet(input_size, hidden_size, output_size)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=lambda_l2) \n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3419\n",
      "Train AUC: 0.6225\n",
      "Train ACC: 91.2812\n",
      "Valid Loss: 0.2856\n",
      "Valid AUC: 0.7438\n",
      "Valid ACC: 90.9230\n",
      "--------------------\n",
      "Train Loss: 0.2562\n",
      "Train AUC: 0.7819\n",
      "Train ACC: 91.7010\n",
      "Valid Loss: 0.2523\n",
      "Valid AUC: 0.8076\n",
      "Valid ACC: 91.3864\n",
      "--------------------\n",
      "Train Loss: 0.2341\n",
      "Train AUC: 0.8223\n",
      "Train ACC: 92.1112\n",
      "Valid Loss: 0.2374\n",
      "Valid AUC: 0.8307\n",
      "Valid ACC: 91.7407\n",
      "--------------------\n",
      "Train Loss: 0.2232\n",
      "Train AUC: 0.8402\n",
      "Train ACC: 92.2707\n",
      "Valid Loss: 0.2293\n",
      "Valid AUC: 0.8428\n",
      "Valid ACC: 91.8498\n",
      "--------------------\n",
      "Train Loss: 0.2169\n",
      "Train AUC: 0.8501\n",
      "Train ACC: 92.3947\n",
      "Valid Loss: 0.2241\n",
      "Valid AUC: 0.8504\n",
      "Valid ACC: 92.0079\n",
      "--------------------\n",
      "Train Loss: 0.2125\n",
      "Train AUC: 0.8568\n",
      "Train ACC: 92.4751\n",
      "Valid Loss: 0.2203\n",
      "Valid AUC: 0.8559\n",
      "Valid ACC: 92.1223\n",
      "--------------------\n",
      "Train Loss: 0.2093\n",
      "Train AUC: 0.8619\n",
      "Train ACC: 92.5419\n",
      "Valid Loss: 0.2174\n",
      "Valid AUC: 0.8603\n",
      "Valid ACC: 92.2259\n",
      "--------------------\n",
      "Train Loss: 0.2066\n",
      "Train AUC: 0.8659\n",
      "Train ACC: 92.5773\n",
      "Valid Loss: 0.2150\n",
      "Valid AUC: 0.8638\n",
      "Valid ACC: 92.2913\n",
      "--------------------\n",
      "Train Loss: 0.2044\n",
      "Train AUC: 0.8693\n",
      "Train ACC: 92.6373\n",
      "Valid Loss: 0.2130\n",
      "Valid AUC: 0.8667\n",
      "Valid ACC: 92.3786\n",
      "--------------------\n",
      "Train Loss: 0.2025\n",
      "Train AUC: 0.8721\n",
      "Train ACC: 92.6850\n",
      "Valid Loss: 0.2112\n",
      "Valid AUC: 0.8691\n",
      "Valid ACC: 92.4276\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "best_weights, metrics_dict = train_valid(model, data_train_loader, data_train,\n",
    "                                         optimizer, criterion,\n",
    "                                         data_test_loader, data_test, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Generate diagnostic plots for the loss and accuracy\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(9, 4.5))\n",
    "for ax, metric in zip(axes, ['loss', 'acc']):\n",
    "    ax.plot(history_train[metric])\n",
    "    ax.plot(history_test[metric])\n",
    "    ax.set_xlabel('epoch', fontsize=12)\n",
    "    ax.set_ylabel(metric, fontsize=12)\n",
    "    ax.legend(['Train', 'Test'], loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.358191200780888,\n",
       "  0.2600617195867105,\n",
       "  0.2371008291074881,\n",
       "  0.2259151222011415,\n",
       "  0.21914252340915466,\n",
       "  0.2144179266708268,\n",
       "  0.21084155164688473,\n",
       "  0.2079680905138031,\n",
       "  0.205564409329486,\n",
       "  0.20351347075799384],\n",
       " 'train_auc': [0.5260674989520792,\n",
       "  0.7357140153954882,\n",
       "  0.79437409512393,\n",
       "  0.8203196285249976,\n",
       "  0.8346378306924611,\n",
       "  0.8441870736442694,\n",
       "  0.8512599232288889,\n",
       "  0.856805858118028,\n",
       "  0.8612875827349689,\n",
       "  0.8649775738944705],\n",
       " 'train_acc': [90.26850211258008,\n",
       "  91.66825678070056,\n",
       "  92.04988414883466,\n",
       "  92.22570532915361,\n",
       "  92.33610467493526,\n",
       "  92.42469674253783,\n",
       "  92.47921493798556,\n",
       "  92.51465176502658,\n",
       "  92.61278451683249,\n",
       "  92.65912498296306],\n",
       " 'test_loss': [0.29151189954383666,\n",
       "  0.256300459144056,\n",
       "  0.2409850781635104,\n",
       "  0.23244021789319108,\n",
       "  0.2267496171849885,\n",
       "  0.2225706548949582,\n",
       "  0.21932385395983864,\n",
       "  0.2166872709097574,\n",
       "  0.2144796348726815,\n",
       "  0.212603324746927],\n",
       " 'test_auc': [0.676206558246065,\n",
       "  0.7712491787188244,\n",
       "  0.8065846218258631,\n",
       "  0.8255407461712791,\n",
       "  0.8369923060886225,\n",
       "  0.844904083117101,\n",
       "  0.8508916643980928,\n",
       "  0.8556805089875729,\n",
       "  0.8595509401085009,\n",
       "  0.8627674153247622],\n",
       " 'test_acc': [90.9011612059096,\n",
       "  91.3536498936924,\n",
       "  91.63168511148668,\n",
       "  91.86065529084665,\n",
       "  91.98059205146377,\n",
       "  92.08417379926948,\n",
       "  92.23136891457231,\n",
       "  92.26407894019518,\n",
       "  92.31859564956659,\n",
       "  92.36766068800087]}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt(metrics_dict['train_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid(model, criterion, optimizer, epoch_num):\n",
    "\n",
    "losslisttrain = []\n",
    "losslisttest = []\n",
    "best_val_loss = 100\n",
    "\n",
    "for epoch in range(100):\n",
    "    print('Epoch {}'.format(epoch))\n",
    "    \n",
    "    y_true_list_train = []\n",
    "    y_score_list_train = [] # score of the malignant class - class 2\n",
    "    y_true_list_test = []\n",
    "    y_score_list_test = [] # score of the malignant class - class 2\n",
    "    \n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    model.train()\n",
    "\n",
    "    cur_loss = 0\n",
    "#     with torch.enable_grad(), \\\n",
    "#         tqdm(total=len(data_train_loader)) as progress_bar:\n",
    "    for iter_, (x, y_true) in enumerate(data_train_loader):\n",
    "\n",
    "        if iter_ % 10:\n",
    "            print(f'Train Phase:  Iteration {iter_+1}/{len(data_train_loader)}', end=\"\\r\")\n",
    "\n",
    "        # zero out the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "\n",
    "            # Setup for forward\n",
    "            x = x.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "            batch_size = x.size(0)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Feed forward to get the logits\n",
    "            logit = model(x)\n",
    "            loss = criterion(logit, y_true)\n",
    "            loss_val = loss.item()\n",
    "            cur_loss += loss_val * batch_size\n",
    "            #print('cur_loss', cur_loss)\n",
    "\n",
    "            # Add y_true and y_pred to list to calculate AUC score\n",
    "            y_true_list_train += y_true.data.tolist()\n",
    "            y_pred = logit.data.numpy().ravel()[2]\n",
    "            y_score_list_train += logit.data.numpy()[:, 2].tolist()\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#             progress_bar.update(batch_size)\n",
    "#             progress_bar.set_postfix(epoch=epoch,\n",
    "#                          NLL=loss_val)\n",
    "\n",
    "\n",
    "    avg_train_loss = cur_loss / len(data_train)\n",
    "    losslisttrain.append(avg_train_loss)\n",
    "    # get the auc\n",
    "    train_auc =  roc_auc_score(y_true=(np.array(y_true_list)==2), y_score=np.array(y_score_list))\n",
    "\n",
    "\n",
    "    print(f'Train Loss: {avg_train_loss:.4f}')\n",
    "    print(f'Train AUC: {train_auc:.4f}')\n",
    "\n",
    "\n",
    "    ######### Evaluation #####\n",
    "\n",
    "    val_loss = 0\n",
    "\n",
    "    for iter_, (x, y_true) in enumerate(data_test_loader):\n",
    "        if iter_ % 10:\n",
    "            print(f'Test Phase:  Iteration {iter_+1}/{len(data_test_loader)}', end=\"\\r\")\n",
    "        # Setup for forward\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Feed forward to get the logits\n",
    "        logit = model(x)\n",
    "        loss = criterion(logit, y_true)\n",
    "        loss_val = loss.item()\n",
    "        val_loss += loss_val * batch_size\n",
    "        #print('cur_loss', cur_loss)\n",
    "\n",
    "        # Add y_true and y_pred to list to calculate AUC score\n",
    "        y_true_list_test += y_true.data.tolist()\n",
    "        y_pred = logit.data.numpy().ravel()[2]\n",
    "        y_score_list_test += logit.data.numpy()[:, 2].tolist()\n",
    "\n",
    "    avg_val_loss = cur_loss / len(data_test)\n",
    "    losslisttest.append(avg_val_loss)\n",
    "    # get the auc\n",
    "    val_auc =  roc_auc_score(y_true=(np.array(y_true_list_test)==2),\n",
    "                             y_score=np.array(y_score_list_test))\n",
    "\n",
    "\n",
    "    print(f'Val Loss: {avg_val_loss:.4f}')\n",
    "    print(f'Val AUC: {val_auc:.4f}')\n",
    "\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "#             torch.save({\n",
    "#             'state_dict': EncoderTransformer_model.state_dict()\n",
    "#                 }, f'./chat_EncoderTransformer_model_best_{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
