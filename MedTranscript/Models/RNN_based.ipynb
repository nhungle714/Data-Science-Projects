{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - RNN Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nhungle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pickle as pkl\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = pkl.load(open(os.path.join(\"../data\",\n",
    "                                          \"train_data_tokens.p\"), \"rb\"))\n",
    "\n",
    "val_tokens = pkl.load(open(os.path.join(\"../data\",\n",
    "                                          \"val_data_tokens.p\"), \"rb\"))\n",
    "\n",
    "test_tokens = pkl.load(open(os.path.join(\"../data\",\n",
    "                                          \"test_data_tokens.p\"), \"rb\"))\n",
    "\n",
    "all_tokens = pkl.load(open(os.path.join(\"../data\",\n",
    "                                          \"all_data_tokens.p\"), \"rb\"))\n",
    "\n",
    "train_target = pkl.load(open(os.path.join(\"../data\", \"train_target.p\"), \"rb\"))\n",
    "val_target = pkl.load(open(os.path.join(\"../data\", \"val_target.p\"), \"rb\"))\n",
    "test_target = pkl.load(open(os.path.join(\"../data\", \"test_target.p\"), \"rb\"))\n",
    "label_mapping = pkl.load(open(os.path.join(\"../data\", \"target_mapping.p\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self, all_tokens, max_vocab_size, PAD_IDX, UNK_IDX):\n",
    "        res = self.buildVocab(all_tokens, max_vocab_size, PAD_IDX, UNK_IDX)\n",
    "        # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "        self.id2token = res[1]\n",
    "        # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "        self.token2id = res[0]\n",
    "    \n",
    "    def buildVocab(self, all_tokens, max_vocab_size, PAD_IDX, UNK_IDX):\n",
    "        token_counter = Counter(all_tokens)\n",
    "        vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "        id2token = list(vocab)\n",
    "        token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "        id2token = ['<pad>', '<unk>'] + id2token\n",
    "        token2id['<pad>'] = PAD_IDX \n",
    "        token2id['<unk>'] = UNK_IDX\n",
    "        return token2id, id2token\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.id2token)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 30000\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "corpus = Dictionary(all_tokens, max_vocab_size, PAD_IDX, UNK_IDX)\n",
    "id2token = corpus.id2token\n",
    "token2id = corpus.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30002"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert token (word) to ids\n",
    "\n",
    "For each dataset, each sample of tokens (i.e., words) will be represented as index of that word in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token2IndexDataset(object):\n",
    "    def __init__(self, tokens_data):\n",
    "        self.indices_data = self.token2index_dataset(tokens_data)\n",
    "        \n",
    "    def token2index_dataset(self, tokens_data):\n",
    "        indices_data = []\n",
    "        for tokens in tokens_data:\n",
    "            index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "            indices_data.append(index_list)\n",
    "        return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_indices = Token2IndexDataset(train_tokens).indices_data\n",
    "val_data_indices= Token2IndexDataset(val_tokens).indices_data\n",
    "test_data_indices= Token2IndexDataset(test_tokens).indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 13024 ; token fev\n",
      "Token fev; token id 13024\n"
     ]
    }
   ],
   "source": [
    "# Lets check the dictionary by loading random token from it\n",
    "import random\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using deep learning methods on NLP tasks, we usually utilize [word embedding](https://en.wikipedia.org/wiki/Word_embedding). To put it briefly, word embedding represent words, or tokens, in a vocabulary as a distributed numerical vector. There are a lot of methods to obtain a word embedding, with some of the most famous shallow models being Word2Vec, GloVe, and FastText while the deeper models are BERT, RoBERTa, T5. It is not difficult to find a general purpose word embedding trained by one of the aforementioned methods on the Internet that's been trained with a massive amount of data. It is usually a good idea to use these pre-trained embedding to save yourself some time and computing resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = glove2word2vec(os.path.join(\"../data\",'glove.6B.50d.txt'), 'tmp_file')\n",
    "glove_embedding = KeyedVectors.load_word2vec_format('tmp_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check the dimension is 50\n",
    "len(glove_embedding['brain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find similar words\n",
    "\n",
    "The word embedding vectors can help us find words with similar meanings. Word similarities can be measured by [Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity). The function below looks up the most similar words to a given word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('underwent', 0.8644347190856934),\n",
       " ('arthroscopic', 0.8504809141159058),\n",
       " ('undergoing', 0.8430145382881165),\n",
       " ('reconstructive', 0.8339141607284546),\n",
       " ('surgeries', 0.8272889852523804)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding.similar_by_word('surgery', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token2VectorDataset(object):\n",
    "    def __init__(self, tokens_data, embedding,):\n",
    "        self.tokens_data = tokens_data\n",
    "        self.embedding = embedding\n",
    "        self.UNK_IDX = UNK_IDX\n",
    "        self.indices_data = self.token2vector_dataset()\n",
    "        \n",
    "    def token2vector_dataset(self):\n",
    "        indices_data = []\n",
    "        for tokens in self.tokens_data:\n",
    "            index_list = [self.embedding[token] if token in self.embedding.vocab else UNK_IDX\n",
    "                          for token in tokens]\n",
    "            indices_data.append(index_list)\n",
    "        return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_vectors = Token2VectorDataset(train_tokens, glove_embedding).indices_data\n",
    "val_data_vectors = Token2VectorDataset(val_tokens, glove_embedding).indices_data\n",
    "test_data_vectors = Token2VectorDataset(test_tokens, glove_embedding).indices_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between train_data_indices and train_data_vectors\n",
    "\n",
    "Both train_data_indices and train_data_vectors have 1571 data points, each represent a sentence (or a text data)\n",
    "\n",
    "However, for train_data_indices, each sample is a list of token, each token represents a word in the corpus.\n",
    "\n",
    "For train_data_vectors, each sample is a list of arrays, each array is 50-dimension vector that represents the distance of that word in the embedding space "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MedTranscriptDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide MAX_SENTENCE_LENGTh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473.9898154042011"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(i) for i in train_data_indices]\n",
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medtranscript_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "#     batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    #print(data_list)\n",
    "    #print(length_list)\n",
    "    #print(label_list)\n",
    "    return [torch.from_numpy(np.array(data_list)),\n",
    "            torch.LongTensor(length_list),\n",
    "            torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = MedTranscriptDataset(train_data_indices, train_target)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=medtranscript_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = MedTranscriptDataset(val_data_indices, val_target)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=medtranscript_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = MedTranscriptDataset(test_data_indices, test_target)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=medtranscript_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   94,    70,  1720,  ...,    12,   795,   784],\n",
      "        [   39, 26780,   725,  ...,     0,     0,     0],\n",
      "        [   94,    70, 11367,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [   94,    70,    21,  ...,   212,   870,    12],\n",
      "        [ 2001,     5,    39,  ...,     0,     0,     0],\n",
      "        [   39,   651,    18,  ...,    52,     3,    28]])\n",
      "tensor([4, 4, 4, 4, 4, 2, 0, 0, 4, 4, 1, 0, 4, 0, 1, 1, 4, 4, 3, 2, 0, 3, 3, 0,\n",
      "        1, 3, 4, 1, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "data, lengths, labels = next(iter(test_loader))\n",
    "print(data)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this challenge, we will be exploring two variants of RNN: vanilla (or Elman) RNN and LSTM (Long-short term memory).\n",
    "\n",
    "- Each input word is represented by a vector of dimension ```embedding_dim```. Check out ```nn.Embedding``` to see how to initialize embeddings randomly.\n",
    "- Your model should take the following input parameters\n",
    "    - ```hidden_dim```: The number of features in the hidden state h of your RNN layer\n",
    "    - ```output_dim```: Number of output classes\n",
    "    - ```vocab_size``` Size of your vocabulary. \n",
    "    - ```embedding_dim```: Dimension of word embeddings\n",
    "- Your model should consist of an RNN layer (you can use either ```nn.RNN``` or ```nn.LSTM```) followed by a linear layer.\n",
    "- $h_{0}$ (and $c$ if you use LSTM) should be initialized as a zero vector of dimension ```hidden_dim```. You might want to check out ```nn.Parameter```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigating three layers: \n",
    "- Embedding\n",
    "- RNN\n",
    "- Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_len, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 600])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim=40\n",
    "output_dim=5\n",
    "vocab_size=len(corpus)\n",
    "embedding_dim=50\n",
    "rnn='RNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=PAD_IDX)\n",
    "rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "fc = nn.Linear(hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embed = emb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 600])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 600, 50])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emb_x: [batch_size, len_x, embedding_dim]\n",
    "x_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_packed = pack_padded_sequence(x_embed, x_len, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_packed, hidden = rnn(x_packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "output_padded, output_lengths = pad_packed_sequence(output_packed, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 600, 40])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to reshape before passing through fully connected layer\n",
    "hidden = hidden.view(-1, hidden_dim)\n",
    "output_padded = output_padded.view(-1, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19200, 40])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 40])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19200, 5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_output_padded = fc(output_padded)\n",
    "logits_output_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_hidden = fc(hidden)\n",
    "logits_hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=50\n",
    "hidden_dim=40\n",
    "output_dim=5\n",
    "num_layers=1\n",
    "rnn_dropout= 0.1\n",
    "options = {\n",
    "            'num_embeddings': len(corpus),\n",
    "            'embedding_dim': embedding_dim,\n",
    "            'padding_idx': PAD_IDX,\n",
    "            'input_size': embedding_dim,\n",
    "            'hidden_size': hidden_dim,\n",
    "            'num_layers': num_layers,\n",
    "            'rnn_dropout': rnn_dropout,\n",
    "            'output_size': output_dim\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    This model combines embedding, rnn and projection layer into a single model\n",
    "    \"\"\"\n",
    "    def __init__(self, options):\n",
    "        #optioins: a dictionary with key = argument, value = value of that argument\n",
    "        super().__init__()\n",
    "        \n",
    "        # create each LM part here \n",
    "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], \n",
    "                                   embedding_dim=options['embedding_dim'], \n",
    "                                   padding_idx=options['padding_idx'])\n",
    "        self.rnn = nn.RNN(options['input_size'],\n",
    "                          options['hidden_size'],\n",
    "                          options['num_layers'],\n",
    "                          dropout=options['rnn_dropout'],\n",
    "                          batch_first=True)\n",
    "#           If we want to predict the next word in the context, then\n",
    "#           we want output to have options['num_embeddings']\n",
    "#         self.projection = nn.Linear(options['hidden_size'],\n",
    "#                                     options['num_embeddings'])\n",
    "        self.projection = nn.Linear(options['hidden_size'],\n",
    "                                    options['output_size'])\n",
    "\n",
    "        \n",
    "    def forward(self, x, x_len):\n",
    "        \"\"\"\n",
    "        Forward method process the input from token ids to logits\n",
    "        \"\"\"\n",
    "        x_embed = self.lookup(x) \n",
    "        #rnn gives u all outputs / hidden as it has so far.\n",
    "        x_packed = pack_padded_sequence(x_embed,\n",
    "                                        x_len,\n",
    "                                        batch_first=True,\n",
    "                                        enforce_sorted=False)\n",
    "        output, hidden = self.rnn(x_packed) #\n",
    "#         output = output.reshape(-1, options['hidden_size'])\n",
    "        hidden = hidden.view(-1, options['hidden_size'])\n",
    "        logits = self.projection(hidden) \n",
    "        #rnn_outpus[0] = size of vocab, as we want to predict this specific word given the chain of words\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_device = 'cuda' if torch.cuda.device_count() > 0 else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhungle/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RNNLanguageModel(options).to(current_device)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# When we may want to think about the sum loss\n",
    "#criterion = nn.CrossEntropyLoss(ignore_index=wiki_dict.get_id('<pad>'), reduction='sum')\n",
    "\n",
    "# model_parameters = [p for p in rnn_model.parameters() if p.requires_grad]\n",
    "# optimizer = torch.optim.Adam(model_parameters, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_len, y = next(iter(train_loader))\n",
    "x, y = x.to(current_device), y.to(current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = rnn_model(x, x_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "outputs = rnn_model(x, x_len)\n",
    "loss = loss_fn(outputs.squeeze(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6525, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 2, 0, 0, 4, 4, 1, 0, 4, 0, 1, 1, 4, 4, 3, 2, 0, 3, 3, 0,\n",
       "        1, 3, 4, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 4, 2, 2, 1, 4, 0, 1, 0, 2, 3, 3, 1, 4, 4, 3, 1, 1, 4, 3, 2, 2, 1,\n",
       "        4, 3, 3, 0, 4, 1, 4, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = outputs.data.max(-1)[1]\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(pred.cpu().numpy())\n",
    "truths = list(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_loader=train_loader,\n",
    "          test_loader=val_loader, \n",
    "          learning_rate=0.001,\n",
    "          num_epoch=1,\n",
    "          print_every=100,\n",
    "          device=current_device):\n",
    "    \n",
    "    # Define the best weights\n",
    "    best_val_loss = np.inf\n",
    "    best_model_state_dict = model.state_dict()\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    \n",
    "    # Training steps\n",
    "    start_time = time.time()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model_parameters = [p for p in rnn_model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(model_parameters,\n",
    "                                 lr=learning_rate,\n",
    "                                 weight_decay=10**(-5))\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=10**(-5))\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        \n",
    "        for i, (data, data_len, labels) in enumerate(train_loader):\n",
    "            data, data_len, labels = data.to(device), data_len.to(device), labels.to(device)\n",
    "            outputs = model(data, data_len)\n",
    "            model.zero_grad()\n",
    "            loss = loss_fn(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "             # report performance\n",
    "            if (i + 1) % print_every == 0:\n",
    "                print('Train set | epoch: {:3d} | {:6d}/{:6d} batches | Loss: {:6.4f}'.format(\n",
    "                    epoch, i + 1, len(train_loader), loss.item()))\n",
    "                \n",
    "        train_losses.append(sum(train_loss) / len(train_loss)) \n",
    "    \n",
    "        # Evaluate after every epoch\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "\n",
    "        predictions = []\n",
    "        truths = []\n",
    "        valid_losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (data, data_len, labels) in enumerate(test_loader):\n",
    "                data, data_len, labels = data.to(device), data_len.to(device), labels.to(device)\n",
    "                outputs = model(data, data_len)\n",
    "                pred = outputs.data.max(-1)[1]\n",
    "                predictions += list(pred.cpu().numpy())\n",
    "                truths += list(labels.cpu().numpy())\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum()\n",
    "                loss = loss_fn(outputs.squeeze(), labels)\n",
    "                valid_losses.append(loss.item())\n",
    "               \n",
    "            correct = correct.item()\n",
    "            acc = (100 * correct / total)\n",
    "#             auc = roc_auc_score(truths, predictions)\n",
    "            avg_val_loss = sum(valid_losses) / len(valid_losses)\n",
    "            elapse = time.strftime('%H:%M:%S', time.gmtime(int((time.time() - start_time))))\n",
    "            print('Val set | Val Loss: {:6.4f} | Accuracy: {:6.4f} | time elapse: {:>9}'.format(\n",
    "                avg_val_loss, acc, elapse))\n",
    "\n",
    "            \n",
    "            if avg_val_loss <= best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "                # model.state_dict()\n",
    "                #copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "    return train_losses, val_losses, best_val_loss, best_model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set | Val Loss: 1.2406 | Accuracy: 63.3308 | time elapse:  00:00:19\n",
      "Val set | Val Loss: 1.2469 | Accuracy: 63.4072 | time elapse:  00:00:38\n",
      "Val set | Val Loss: 1.2596 | Accuracy: 63.1780 | time elapse:  00:00:58\n",
      "Val set | Val Loss: 1.2785 | Accuracy: 62.7960 | time elapse:  00:01:17\n",
      "Val set | Val Loss: 1.2889 | Accuracy: 63.4072 | time elapse:  00:01:37\n",
      "Val set | Val Loss: 1.3024 | Accuracy: 63.2544 | time elapse:  00:01:55\n",
      "Val set | Val Loss: 1.3358 | Accuracy: 62.4141 | time elapse:  00:02:14\n",
      "Val set | Val Loss: 1.3418 | Accuracy: 63.0252 | time elapse:  00:02:34\n",
      "Val set | Val Loss: 1.3642 | Accuracy: 63.2544 | time elapse:  00:02:53\n",
      "Val set | Val Loss: 1.3804 | Accuracy: 63.1780 | time elapse:  00:03:14\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, best_val_loss, best_model_state_dict = train(model=rnn_model,\n",
    "      train_loader=train_loader,\n",
    "      test_loader=val_loader, \n",
    "      learning_rate=0.005,\n",
    "      num_epoch=10,\n",
    "      print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model with pretrained-embedded layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pretrained_embedded data_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token2VectorDataset(object):\n",
    "    def __init__(self, tokens_data, embedding,):\n",
    "        self.tokens_data = tokens_data\n",
    "        self.embedding = embedding\n",
    "        self.UNK_IDX = UNK_IDX\n",
    "        self.indices_data = self.token2vector_dataset()\n",
    "        \n",
    "    def token2vector_dataset(self):\n",
    "        indices_data = []\n",
    "        for tokens in self.tokens_data:\n",
    "            index_list = [self.embedding[token] if token in self.embedding.vocab else UNK_IDX\n",
    "                          for token in tokens]\n",
    "            indices_data.append(index_list)\n",
    "        return indices_data\n",
    "train_data_vectors = Token2VectorDataset(train_tokens, glove_embedding).indices_data\n",
    "val_data_vectors = Token2VectorDataset(val_tokens, glove_embedding).indices_data\n",
    "test_data_vectors = Token2VectorDataset(test_tokens, glove_embedding).indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedTranscriptDataset_Glove(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tokens_data, target_list, embedding=glove_embedding):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.tokens_data = tokens_data\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.tokens_data) == len(self.target_list))\n",
    "        self.embedding = embedding\n",
    "        self.UNK_IDX = UNK_IDX\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        sentence = self.tokens_data[key]\n",
    "        embedded_token_idx = [self.embedding[token] for token in sentence\n",
    "                              if token in self.embedding.vocab]\n",
    "        label = self.target_list[key]\n",
    "        embedded_token_idx_tensor = torch.from_numpy(np.array(embedded_token_idx))\n",
    "        return [embedded_token_idx_tensor, label]\n",
    "    \n",
    "def pad_collate_glove(batch):\n",
    "    batch = filter(lambda x:x is not None, batch)\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "\n",
    "    return xx_pad, torch.as_tensor(x_lens), torch.LongTensor(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(tokens, target, embedding=glove_embedding, BATCH_SIZE=32):\n",
    "    dataset = MedTranscriptDataset_Glove(tokens,\n",
    "                                     target)\n",
    "    dataloader_embedded = torch.utils.data.DataLoader(\n",
    "                                               dataset=dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=pad_collate_glove,\n",
    "                                               shuffle=True)\n",
    "    \n",
    "    return dataset, dataloader_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_dataloader_embedded = generate_dataset(train_tokens, train_target)\n",
    "\n",
    "val_dataset, val_dataloader_embedded = generate_dataset(val_tokens, val_target)\n",
    "\n",
    "test_dataset, test_dataloader_embedded = generate_dataset(test_tokens, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
