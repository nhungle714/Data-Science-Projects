{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = '/Users/nhungle/Desktop/Submission'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "train_snli = pd.read_csv(os.path.join(root, \"data/snli_train.tsv\"), sep=\"\\t\")\n",
    "val_snli = pd.read_csv(os.path.join(root,\"data/snli_val.tsv\"), sep=\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in the training set: 100000\n",
      "Number of observations in the validation set: 1000\n"
     ]
    }
   ],
   "source": [
    "# Check number of observations\n",
    "print(\"Number of observations in the training set: %d\" % len(train_snli))\n",
    "print(\"Number of observations in the validation set: %d\" % len(val_snli))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class composition in the training set:\n",
      "entailment       33635\n",
      "neutral          33200\n",
      "contradiction    33165\n",
      "Name: label, dtype: int64\n",
      "Class composition in the validation set:\n",
      "neutral          338\n",
      "contradiction    331\n",
      "entailment       331\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class composition\n",
    "print(\"Class composition in the training set:\\n{}\".format(train_snli[\"label\"].value_counts()))\n",
    "print(\"Class composition in the validation set:\\n{}\".format(val_snli[\"label\"].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n",
    "#### 1.1 Tokenize sentences\n",
    "Tokenize premise and hypothesis in the training set and the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create tokenizer\n",
    "def tokenize(sent):\n",
    "  tokens = tokenizer(sent)\n",
    "  return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    # Track tokenize observations\n",
    "    token_dataset = []\n",
    "    # Track tokens\n",
    "    all_tokens = []\n",
    "    \n",
    "    for sample in dataset:\n",
    "        tokens = tokenize(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "\n",
    "    return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train tokens\n",
    "train_data_premise_tokens = pkl.load(open(os.path.join(root, \"data/snli_train_premise_tokens.p\"), \"rb\"))\n",
    "all_train_premise_tokens = pkl.load(open(os.path.join(root, \"data/snli_all_train_premise_tokens.p\"), \"rb\"))\n",
    "train_data_hypothesis_tokens = pkl.load(open(os.path.join(root, \"data/snli_train_hypothesis_tokens.p\"), \"rb\"))\n",
    "all_train_hypothesis_tokens = pkl.load(open(os.path.join(root, \"data/snli_all_train_hypothesis_tokens.p\"), \"rb\"))\n",
    "\n",
    "# Import test tokens\n",
    "val_data_premise_tokens = pkl.load(open(os.path.join(root, \"data/snli_val_premise_tokens.p\"), \"rb\"))\n",
    "all_val_premise_tokens = pkl.load(open(os.path.join(root, \"data/snli_all_val_premise_tokens.p\"), \"rb\"))\n",
    "val_data_hypothesis_tokens = pkl.load(open(os.path.join(root, \"data/snli_val_hypothesis_tokens.p\"), \"rb\"))\n",
    "all_val_hypothesis_tokens = pkl.load(open(os.path.join(root, \"data/snli_all_val_hypothesis_tokens.p\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please use the saved tokens and skip the following part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize training data\n",
    "# train_data_premise_tokens, all_train_premise_tokens = tokenize_dataset(train_snli[\"sentence1\"])\n",
    "# pkl.dump(train_data_premise_tokens, open(\"snli_train_premise_tokens.p\", \"wb\"))\n",
    "# pkl.dump(all_train_premise_tokens, open(\"snli_all_train_premise_tokens.p\", \"wb\"))\n",
    "\n",
    "# train_data_hypothesis_tokens, all_train_hypothesis_tokens = tokenize_dataset(train_snli[\"sentence2\"])\n",
    "# pkl.dump(train_data_hypothesis_tokens, open(\"snli_train_hypothesis_tokens.p\", \"wb\"))\n",
    "# pkl.dump(all_train_hypothesis_tokens, open(\"snli_all_train_hypothesis_tokens.p\", \"wb\"))\n",
    "\n",
    "# # Tokenize validation data\n",
    "# val_data_premise_tokens, all_val_premise_tokens = tokenize_dataset(val_snli[\"sentence1\"])\n",
    "# pkl.dump(val_data_premise_tokens, open(\"snli_val_premise_tokens.p\", \"wb\"))\n",
    "# pkl.dump(all_val_premise_tokens, open(\"snli_all_val_premise_tokens.p\", \"wb\"))\n",
    "\n",
    "# val_data_hypothesis_tokens, all_val_hypothesis_tokens = tokenize_dataset(val_snli[\"sentence2\"])\n",
    "# pkl.dump(val_data_hypothesis_tokens, open(\"snli_val_hypothesis_tokens.p\", \"wb\"))\n",
    "# pkl.dump(all_val_hypothesis_tokens, open(\"snli_all_val_hypothesis_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train premise dataset size is 100000\n",
      "Train hypothesis dataset size is 100000\n",
      "Validation premise dataset size is 1000\n",
      "Validation hypothesis dataset size is 1000\n",
      "Total number of tokens in train premise dataset is 1294135\n",
      "Total number of tokens in train hypothesis dataset is 743372\n",
      "Total number of tokens in validation premise dataset is 14057\n",
      "Total number of tokens in validation hypothesis dataset is 7614\n"
     ]
    }
   ],
   "source": [
    "# Check token size\n",
    "print (\"Train premise dataset size is {}\".format(len(train_data_premise_tokens)))\n",
    "print (\"Train hypothesis dataset size is {}\".format(len(train_data_hypothesis_tokens)))\n",
    "print (\"Validation premise dataset size is {}\".format(len(val_data_premise_tokens)))\n",
    "print (\"Validation hypothesis dataset size is {}\".format(len(val_data_hypothesis_tokens)))\n",
    "\n",
    "print (\"Total number of tokens in train premise dataset is {}\".format(len(all_train_premise_tokens)))\n",
    "print (\"Total number of tokens in train hypothesis dataset is {}\".format(len(all_train_hypothesis_tokens)))\n",
    "print (\"Total number of tokens in validation premise dataset is {}\".format(len(all_val_premise_tokens)))\n",
    "print (\"Total number of tokens in validation hypothesis dataset is {}\".format(len(all_val_hypothesis_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Convert the most common tokens to ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index 0 for special token <unk>\n",
    "PAD_IDX = 0\n",
    "# Index 1 for special token <pad>\n",
    "UNK_IDX = 1\n",
    "\n",
    "# Create the vocabulary of the most common tokens in the training set\n",
    "def build_vocab(all_tokens, \n",
    "                vocab_size = 10000):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    all_tokens:       all tokens in the dataset\n",
    "    max_vocab_size:   the vocabulary size\n",
    "    \n",
    "    Output:\n",
    "    id2token:   list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    token2id:   dictionary where keys represent tokens and corresponding values represent indices\n",
    "    \"\"\"\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2, 2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "# Convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data,\n",
    "                       token2id):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    tokens_data:    tokens in the dataset\n",
    "    token2id:       dictionary where keys represent tokens and corresponding values represent indices\n",
    "    \n",
    "    Output:\n",
    "    indices_data:   indices representing tokens in the dataset\n",
    "    \"\"\"\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "def token2index_all(vocab_size):\n",
    "    # Create vocabulary for all training sentences\n",
    "    all_train_token = all_train_premise_tokens + all_train_hypothesis_tokens\n",
    "    token2id, id2token = build_vocab(all_tokens = all_train_token, \n",
    "                                     vocab_size = vocab_size)\n",
    "\n",
    "    # Convert tokens in premise and hypothesis in the training set into indices\n",
    "    train_premise_ind = token2index_dataset(train_data_premise_tokens, token2id)\n",
    "    train_hypothesis_ind = token2index_dataset(train_data_hypothesis_tokens, token2id)\n",
    "\n",
    "    # Convert tokens in premise and hypothesis in the validation set into indices\n",
    "    val_premise_ind = token2index_dataset(val_data_premise_tokens, token2id)\n",
    "    val_hypothesis_ind = token2index_dataset(val_data_hypothesis_tokens, token2id)\n",
    "    \n",
    "    return token2id, id2token, train_premise_ind, train_hypothesis_ind, val_premise_ind, val_hypothesis_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 4600 ; token chimney\n",
      "Token chimney; token id 4600\n"
     ]
    }
   ],
   "source": [
    "# Use vocab size = 10000 for baseline\n",
    "token2id, id2token, train_premise_ind, train_hypothesis_ind, val_premise_ind, val_hypothesis_ind = token2index_all(10000)\n",
    "\n",
    "# Check token to index\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of tokens in premise is 12.94135\n",
      "The average number of tokens in hypothesis is 7.43372\n"
     ]
    }
   ],
   "source": [
    "# Check average sentence length\n",
    "print(f'The average number of tokens in premise is {np.mean([len(i) for i in train_data_premise_tokens])}')\n",
    "print(f'The average number of tokens in hypothesis is {np.mean([len(i) for i in train_data_hypothesis_tokens])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set max sentence length as 10 as the average number of token is around 13\n",
    "MAX_SENTENCE_LENGTH = 10\n",
    "# Set batch size\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Create SNLIDataset class for DataLoader\n",
    "class SNLIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    \"\"\"\n",
    "    def __init__(self, premise, hypothesis, labels):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        data_list: list of tokens \n",
    "        target_list: list of target label\n",
    "        \"\"\"\n",
    "        self.premise = premise\n",
    "        self.hypothesis = hypothesis\n",
    "        # Convert string label to integer\n",
    "        self.labels = labels.replace({'entailment': 0, 'neutral': 1, 'contradiction': 2})\n",
    "        assert (len(self.premise) == len(self.hypothesis))\n",
    "        assert (len(self.premise) == len(self.labels))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.premise)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\" \n",
    "        premise_idx = self.premise[key][:MAX_SENTENCE_LENGTH]\n",
    "        hypothesis_idx = self.hypothesis[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.labels[key]\n",
    "        return [premise_idx, len(premise_idx), hypothesis_idx, len(hypothesis_idx), label]\n",
    "    \n",
    "# Create collate function for fixed length representation\n",
    "def snli_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    premise_list = []\n",
    "    premise_len_list = []\n",
    "    hypothesis_list= []\n",
    "    hypothesis_len_list = []\n",
    "    label_list = []\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[-1])\n",
    "        premise_len_list.append(datum[1])\n",
    "        hypothesis_len_list.append(datum[3])\n",
    "    # Add padding\n",
    "    for datum in batch:\n",
    "        padded_premise = np.pad(np.array(datum[0]),\n",
    "                               pad_width = ((0, MAX_SENTENCE_LENGTH-datum[1])),\n",
    "                               mode=\"constant\", constant_values = 0)\n",
    "        premise_list.append(padded_premise)\n",
    "        \n",
    "        padded_hypothesis = np.pad(np.array(datum[2]),\n",
    "                               pad_width = ((0, MAX_SENTENCE_LENGTH-datum[3])),\n",
    "                               mode=\"constant\", constant_values = 0)\n",
    "        hypothesis_list.append(padded_hypothesis)\n",
    "        \n",
    "    return [torch.from_numpy(np.array(premise_list)), \n",
    "            torch.LongTensor(premise_len_list), \n",
    "            torch.from_numpy(np.array(hypothesis_list)), \n",
    "            torch.LongTensor(hypothesis_len_list), \n",
    "            torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SNLIDataset classes\n",
    "train_dataset = SNLIDataset(train_premise_ind, train_hypothesis_ind, train_snli[\"label\"])\n",
    "val_dataset = SNLIDataset(val_premise_ind, val_hypothesis_ind, val_snli[\"label\"])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=snli_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=snli_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SNLI Modeling\n",
    "\n",
    "#### 2.1 Baseline Models\n",
    "The baseline model uses the following parameters:\n",
    "- Vocabulary size = 10000 (excluding two special tokens for `pad` and `unk`) \n",
    "- Embedding dimension = 100\n",
    "- Interaction method = `concat`\n",
    "\n",
    "#### 2.1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWords(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 emb_dim, \n",
    "                 interaction,\n",
    "                 neural_net = False,\n",
    "                 hidden_dim1 = None,\n",
    "                 hidden_dim2 = None):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        vocab_size:   size of the vocabulary\n",
    "        emb_dim:      size of the word embedding\n",
    "        interaction:  interaction methods for two representations\n",
    "        neural_net:   whether to build a neural network with two hidden layers or a logistic\n",
    "                      regression model\n",
    "        hidden_dim1:  dimension of the first hidden layer of neural net\n",
    "        hidden_dim2:  dimension of the second hidden layer of neural net\n",
    "        \"\"\"\n",
    "        super(BagOfWords, self).__init__()\n",
    "        # Pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.interaction = interaction\n",
    "        self.neural_net = neural_net\n",
    "        # Set linear dimension based on interaction methods and model types\n",
    "        # Neural network with two hidden layers\n",
    "        if neural_net:\n",
    "            if interaction == 'concat':\n",
    "                self.first_layer = nn.Linear(2*emb_dim, hidden_dim1)\n",
    "            else:\n",
    "                self.first_layer = nn.Linear(emb_dim, hidden_dim1)\n",
    "            self.second_layer = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "            self.last_linear = nn.Linear(hidden_dim2, 3)\n",
    "        # Logistic regression\n",
    "        else:\n",
    "            if interaction == 'concat':\n",
    "                self.linear = nn.Linear(2*emb_dim,3)\n",
    "            else:\n",
    "                self.linear = nn.Linear(emb_dim,3)\n",
    "\n",
    "    def forward(self, premise, p_length, hypothesis, h_length):\n",
    "        \"\"\"\n",
    "        Input: \n",
    "        premise:     matrix of size (batch_size, max_sentence_length). \n",
    "                     Each row in data is a premise represented by index in the same length\n",
    "        p_length:    an int tensor of size (batch_size)\n",
    "        hypothesis:  matrix of size (batch_size, max_sentence_length). \n",
    "                     Each row in data is a hypothesis represented by index in the same length\n",
    "        h_length:    an int tensor of size (batch_size)\n",
    "        \"\"\"\n",
    "        p_out = self.embed(premise)\n",
    "        p_out = torch.sum(p_out, dim=1)\n",
    "        p_out /= p_length.view(p_length.size()[0],1).expand_as(p_out).float()\n",
    "     \n",
    "        h_out = self.embed(hypothesis)\n",
    "        h_out = torch.sum(h_out, dim=1)\n",
    "        h_out /= h_length.view(h_length.size()[0],1).expand_as(h_out).float()\n",
    "        \n",
    "        # Combine two representations\n",
    "        out = self.interaction_func(p_out, h_out)\n",
    "        if self.neural_net:\n",
    "            out = F.relu(self.first_layer(out.float()))\n",
    "            out = F.relu(self.second_layer(out))\n",
    "            out = self.last_linear(out)\n",
    "        else:\n",
    "            out = self.linear(out.float())\n",
    "        return out\n",
    "    \n",
    "    # Interact premise with hypothesis using method specified\n",
    "    def interaction_func(self, premise, hypothesis):\n",
    "        \"\"\"\n",
    "        Input: \n",
    "        premise:     matrix of size (batch_size, max_sentence_length). \n",
    "                     Each row in data is a premise represented by index in the same length\n",
    "        hypothesis:  matrix of size (batch_size, max_sentence_length). \n",
    "                     Each row in data is a hypothesis represented by index in the same length\n",
    "        \n",
    "        Output:\n",
    "        A matrix that represents the combination of premise and hypothesis\n",
    "        \"\"\"\n",
    "        if self.interaction == 'concat':\n",
    "            return torch.cat((premise, hypothesis), dim = 1)\n",
    "        elif self.interaction == 'sum':\n",
    "            return (premise + hypothesis)\n",
    "        elif self.interaction == 'element_wise_product':\n",
    "            return (premise * hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Test the model's performance on a dataset\n",
    "    Input:\n",
    "    loader: DataLoader for the dataset to test against\n",
    "    model:  trained model\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for premise, p_length, hypothesis, h_length, labels in loader:\n",
    "        outputs = model(premise, p_length, hypothesis, h_length)\n",
    "        loss = criterion(outputs, labels)\n",
    "        predicted = F.softmax(outputs, dim=1).max(1, keepdim=True)[1]\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return loss, (100 * correct / total)\n",
    "\n",
    "def train_and_val(train_loader, \n",
    "                  val_loader, \n",
    "                  model, \n",
    "                  num_epochs,\n",
    "                  verbose = False):\n",
    "    \"\"\"\n",
    "    Train model and test model performance on the validation set\n",
    "    Input:\n",
    "    train_loader: DataLoader for training data\n",
    "    val_loader:   DataLoader for validation data\n",
    "    model:        model to be trained\n",
    "    num_empochs:  number of epochs\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    # Model Parameter\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    learning_rate = 0.001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # Keep track of accuracy and loss history\n",
    "    train_loss_hist = []\n",
    "    val_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (premise, p_length, hypothesis, h_length, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(premise, p_length, hypothesis, h_length)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if verbose:\n",
    "                if i % 150 == 0:\n",
    "                    print(f'Epoch: [{epoch+1}/{num_epochs}], Step: [{i+1}/{len(train_loader)}], Train Loss: {loss:.4f}')\n",
    "\n",
    "                # Validate every 100 iterations\n",
    "                if i > 0 and i % 250 == 0:\n",
    "                    # Validate\n",
    "                    val_loss, val_acc = test_model(val_loader, model)\n",
    "                    print('Epoch: [{}/{}], Step: [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Acc: {}'.format( \n",
    "                               epoch+1, num_epochs, i+1, len(train_loader), loss, val_loss, val_acc))\n",
    "                        \n",
    "        # Track loss and accuracy for each epoch\n",
    "        # Compute final stat for training and validation sets\n",
    "        train_loss, train_acc = test_model(train_loader, model)\n",
    "        val_loss, val_acc = test_model(val_loader, model)\n",
    "        train_loss_hist.append(train_loss)\n",
    "        val_loss_hist.append(val_loss)\n",
    "        train_acc_hist.append(train_acc)\n",
    "        val_acc_hist.append(val_acc)\n",
    "        if verbose:\n",
    "            print('-'*50)\n",
    "    print()\n",
    "    print('Final Stats:')\n",
    "    print (\"After training for {} epochs\".format(num_epochs))\n",
    "    print (\"Train Loss: {:.4f}, Train Accuracy: {}\".format(train_loss, train_acc))\n",
    "    print (\"Val loss: {:.4f}, Val Acc: {}\".format(val_loss, val_acc))\n",
    "    print(f'Total training time: {time.time() - start}')\n",
    "    hist = [train_loss_hist,  val_loss_hist, train_acc_hist, val_acc_hist]\n",
    "    return model, val_loss, val_acc, train_loss, train_acc, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [1/782], Train Loss: 1.1157\n",
      "Epoch: [1/10], Step: [151/782], Train Loss: 1.0402\n",
      "Epoch: [1/10], Step: [251/782], Train Loss: 0.9773, Validation Loss: 1.0669, Validation Acc: 50.0\n",
      "Epoch: [1/10], Step: [301/782], Train Loss: 0.9733\n",
      "Epoch: [1/10], Step: [451/782], Train Loss: 1.0237\n",
      "Epoch: [1/10], Step: [501/782], Train Loss: 0.9285, Validation Loss: 1.0080, Validation Acc: 54.7\n",
      "Epoch: [1/10], Step: [601/782], Train Loss: 0.9243\n",
      "Epoch: [1/10], Step: [751/782], Train Loss: 0.9233\n",
      "Epoch: [1/10], Step: [751/782], Train Loss: 0.9233, Validation Loss: 0.9761, Validation Acc: 57.1\n",
      "--------------------------------------------------\n",
      "Epoch: [2/10], Step: [1/782], Train Loss: 0.8763\n",
      "Epoch: [2/10], Step: [151/782], Train Loss: 0.8987\n",
      "Epoch: [2/10], Step: [251/782], Train Loss: 0.8701, Validation Loss: 0.9071, Validation Acc: 59.3\n",
      "Epoch: [2/10], Step: [301/782], Train Loss: 0.9532\n",
      "Epoch: [2/10], Step: [451/782], Train Loss: 0.8102\n",
      "Epoch: [2/10], Step: [501/782], Train Loss: 0.9313, Validation Loss: 0.8615, Validation Acc: 58.7\n",
      "Epoch: [2/10], Step: [601/782], Train Loss: 0.8540\n",
      "Epoch: [2/10], Step: [751/782], Train Loss: 0.9863\n",
      "Epoch: [2/10], Step: [751/782], Train Loss: 0.9863, Validation Loss: 0.8590, Validation Acc: 60.5\n",
      "--------------------------------------------------\n",
      "Epoch: [3/10], Step: [1/782], Train Loss: 0.8117\n",
      "Epoch: [3/10], Step: [151/782], Train Loss: 0.8452\n",
      "Epoch: [3/10], Step: [251/782], Train Loss: 0.8811, Validation Loss: 0.9244, Validation Acc: 59.9\n",
      "Epoch: [3/10], Step: [301/782], Train Loss: 0.7924\n",
      "Epoch: [3/10], Step: [451/782], Train Loss: 0.7602\n",
      "Epoch: [3/10], Step: [501/782], Train Loss: 0.8974, Validation Loss: 0.9076, Validation Acc: 61.2\n",
      "Epoch: [3/10], Step: [601/782], Train Loss: 0.8885\n",
      "Epoch: [3/10], Step: [751/782], Train Loss: 0.9547\n",
      "Epoch: [3/10], Step: [751/782], Train Loss: 0.9547, Validation Loss: 0.8143, Validation Acc: 61.1\n",
      "--------------------------------------------------\n",
      "Epoch: [4/10], Step: [1/782], Train Loss: 0.7914\n",
      "Epoch: [4/10], Step: [151/782], Train Loss: 0.8705\n",
      "Epoch: [4/10], Step: [251/782], Train Loss: 0.8319, Validation Loss: 0.8906, Validation Acc: 61.0\n",
      "Epoch: [4/10], Step: [301/782], Train Loss: 0.8244\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-42fff83aee91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg_baseline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                   \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                   verbose = True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-95accb3bfb1d>\u001b[0m in \u001b[0;36mtrain_and_val\u001b[0;34m(train_loader, val_loader, model, num_epochs, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Implement BoW for logistic regression\n",
    "logreg_baseline = BagOfWords(vocab_size = len(id2token), \n",
    "                   emb_dim = 100, \n",
    "                   interaction = 'concat')\n",
    "\n",
    "# Train and validate model\n",
    "logreg_baseline, val_loss, val_acc, \\\n",
    "    train_loss, train_acc, hist = train_and_val(train_loader = train_loader, \n",
    "                                                  val_loader = val_loader, \n",
    "                                                  model = logreg_baseline, \n",
    "                                                  num_epochs = 10,\n",
    "                                                  verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [1/782], Train Loss: 1.1098\n",
      "Epoch: [1/10], Step: [151/782], Train Loss: 1.0152\n",
      "Epoch: [1/10], Step: [251/782], Train Loss: 0.9207, Validation Loss: 1.0111, Validation Acc: 50.0\n",
      "Epoch: [1/10], Step: [301/782], Train Loss: 1.0043\n",
      "Epoch: [1/10], Step: [451/782], Train Loss: 0.8889\n",
      "Epoch: [1/10], Step: [501/782], Train Loss: 0.9883, Validation Loss: 0.9036, Validation Acc: 54.9\n",
      "Epoch: [1/10], Step: [601/782], Train Loss: 0.8957\n",
      "Epoch: [1/10], Step: [751/782], Train Loss: 0.9897\n",
      "Epoch: [1/10], Step: [751/782], Train Loss: 0.9897, Validation Loss: 0.8437, Validation Acc: 57.1\n",
      "--------------------------------------------------\n",
      "Epoch: [2/10], Step: [1/782], Train Loss: 0.8838\n",
      "Epoch: [2/10], Step: [151/782], Train Loss: 0.8191\n",
      "Epoch: [2/10], Step: [251/782], Train Loss: 0.8114, Validation Loss: 0.9326, Validation Acc: 59.5\n",
      "Epoch: [2/10], Step: [301/782], Train Loss: 0.9380\n",
      "Epoch: [2/10], Step: [451/782], Train Loss: 0.8916\n",
      "Epoch: [2/10], Step: [501/782], Train Loss: 0.8738, Validation Loss: 1.0069, Validation Acc: 61.5\n",
      "Epoch: [2/10], Step: [601/782], Train Loss: 0.7273\n",
      "Epoch: [2/10], Step: [751/782], Train Loss: 0.8588\n",
      "Epoch: [2/10], Step: [751/782], Train Loss: 0.8588, Validation Loss: 0.7789, Validation Acc: 60.9\n",
      "--------------------------------------------------\n",
      "Epoch: [3/10], Step: [1/782], Train Loss: 0.7480\n",
      "Epoch: [3/10], Step: [151/782], Train Loss: 0.8505\n",
      "Epoch: [3/10], Step: [251/782], Train Loss: 0.8261, Validation Loss: 0.9215, Validation Acc: 61.5\n",
      "Epoch: [3/10], Step: [301/782], Train Loss: 0.9025\n",
      "Epoch: [3/10], Step: [451/782], Train Loss: 0.9202\n",
      "Epoch: [3/10], Step: [501/782], Train Loss: 0.7266, Validation Loss: 0.8399, Validation Acc: 62.8\n",
      "Epoch: [3/10], Step: [601/782], Train Loss: 0.7473\n",
      "Epoch: [3/10], Step: [751/782], Train Loss: 0.8151\n",
      "Epoch: [3/10], Step: [751/782], Train Loss: 0.8151, Validation Loss: 0.7579, Validation Acc: 61.6\n",
      "--------------------------------------------------\n",
      "Epoch: [4/10], Step: [1/782], Train Loss: 0.6544\n",
      "Epoch: [4/10], Step: [151/782], Train Loss: 0.7648\n",
      "Epoch: [4/10], Step: [251/782], Train Loss: 0.6205, Validation Loss: 0.8941, Validation Acc: 61.7\n",
      "Epoch: [4/10], Step: [301/782], Train Loss: 0.8118\n",
      "Epoch: [4/10], Step: [451/782], Train Loss: 0.6316\n",
      "Epoch: [4/10], Step: [501/782], Train Loss: 0.7340, Validation Loss: 0.7936, Validation Acc: 62.7\n",
      "Epoch: [4/10], Step: [601/782], Train Loss: 0.7782\n",
      "Epoch: [4/10], Step: [751/782], Train Loss: 0.6638\n",
      "Epoch: [4/10], Step: [751/782], Train Loss: 0.6638, Validation Loss: 0.6608, Validation Acc: 62.9\n",
      "--------------------------------------------------\n",
      "Epoch: [5/10], Step: [1/782], Train Loss: 0.7182\n",
      "Epoch: [5/10], Step: [151/782], Train Loss: 0.6893\n",
      "Epoch: [5/10], Step: [251/782], Train Loss: 0.6675, Validation Loss: 0.7420, Validation Acc: 62.9\n",
      "Epoch: [5/10], Step: [301/782], Train Loss: 0.6333\n",
      "Epoch: [5/10], Step: [451/782], Train Loss: 0.6683\n",
      "Epoch: [5/10], Step: [501/782], Train Loss: 0.7575, Validation Loss: 0.7187, Validation Acc: 63.3\n",
      "Epoch: [5/10], Step: [601/782], Train Loss: 0.7761\n",
      "Epoch: [5/10], Step: [751/782], Train Loss: 0.6788\n",
      "Epoch: [5/10], Step: [751/782], Train Loss: 0.6788, Validation Loss: 0.8302, Validation Acc: 63.2\n",
      "--------------------------------------------------\n",
      "Epoch: [6/10], Step: [1/782], Train Loss: 0.5658\n",
      "Epoch: [6/10], Step: [151/782], Train Loss: 0.8238\n",
      "Epoch: [6/10], Step: [251/782], Train Loss: 0.7423, Validation Loss: 0.7446, Validation Acc: 64.1\n",
      "Epoch: [6/10], Step: [301/782], Train Loss: 0.7644\n",
      "Epoch: [6/10], Step: [451/782], Train Loss: 0.6196\n",
      "Epoch: [6/10], Step: [501/782], Train Loss: 0.6555, Validation Loss: 0.7299, Validation Acc: 63.6\n",
      "Epoch: [6/10], Step: [601/782], Train Loss: 0.7184\n",
      "Epoch: [6/10], Step: [751/782], Train Loss: 0.6420\n",
      "Epoch: [6/10], Step: [751/782], Train Loss: 0.6420, Validation Loss: 0.8850, Validation Acc: 62.8\n",
      "--------------------------------------------------\n",
      "Epoch: [7/10], Step: [1/782], Train Loss: 0.5223\n",
      "Epoch: [7/10], Step: [151/782], Train Loss: 0.6450\n",
      "Epoch: [7/10], Step: [251/782], Train Loss: 0.7207, Validation Loss: 0.9854, Validation Acc: 64.0\n",
      "Epoch: [7/10], Step: [301/782], Train Loss: 0.7304\n",
      "Epoch: [7/10], Step: [451/782], Train Loss: 0.6565\n",
      "Epoch: [7/10], Step: [501/782], Train Loss: 0.5563, Validation Loss: 0.9676, Validation Acc: 62.4\n",
      "Epoch: [7/10], Step: [601/782], Train Loss: 0.6477\n",
      "Epoch: [7/10], Step: [751/782], Train Loss: 0.6343\n",
      "Epoch: [7/10], Step: [751/782], Train Loss: 0.6343, Validation Loss: 0.8548, Validation Acc: 63.6\n",
      "--------------------------------------------------\n",
      "Epoch: [8/10], Step: [1/782], Train Loss: 0.5114\n",
      "Epoch: [8/10], Step: [151/782], Train Loss: 0.6962\n",
      "Epoch: [8/10], Step: [251/782], Train Loss: 0.6069, Validation Loss: 0.8580, Validation Acc: 62.1\n",
      "Epoch: [8/10], Step: [301/782], Train Loss: 0.6714\n",
      "Epoch: [8/10], Step: [451/782], Train Loss: 0.5157\n",
      "Epoch: [8/10], Step: [501/782], Train Loss: 0.7368, Validation Loss: 0.9254, Validation Acc: 63.7\n",
      "Epoch: [8/10], Step: [601/782], Train Loss: 0.6126\n",
      "Epoch: [8/10], Step: [751/782], Train Loss: 0.6102\n",
      "Epoch: [8/10], Step: [751/782], Train Loss: 0.6102, Validation Loss: 1.0611, Validation Acc: 64.0\n",
      "--------------------------------------------------\n",
      "Epoch: [9/10], Step: [1/782], Train Loss: 0.5394\n",
      "Epoch: [9/10], Step: [151/782], Train Loss: 0.5191\n",
      "Epoch: [9/10], Step: [251/782], Train Loss: 0.6043, Validation Loss: 0.7701, Validation Acc: 65.0\n",
      "Epoch: [9/10], Step: [301/782], Train Loss: 0.5935\n",
      "Epoch: [9/10], Step: [451/782], Train Loss: 0.6205\n",
      "Epoch: [9/10], Step: [501/782], Train Loss: 0.5941, Validation Loss: 0.8814, Validation Acc: 63.9\n",
      "Epoch: [9/10], Step: [601/782], Train Loss: 0.6047\n",
      "Epoch: [9/10], Step: [751/782], Train Loss: 0.6698\n",
      "Epoch: [9/10], Step: [751/782], Train Loss: 0.6698, Validation Loss: 0.9781, Validation Acc: 64.1\n",
      "--------------------------------------------------\n",
      "Epoch: [10/10], Step: [1/782], Train Loss: 0.5656\n",
      "Epoch: [10/10], Step: [151/782], Train Loss: 0.4680\n",
      "Epoch: [10/10], Step: [251/782], Train Loss: 0.5671, Validation Loss: 0.8621, Validation Acc: 63.5\n",
      "Epoch: [10/10], Step: [301/782], Train Loss: 0.5195\n",
      "Epoch: [10/10], Step: [451/782], Train Loss: 0.4643\n",
      "Epoch: [10/10], Step: [501/782], Train Loss: 0.4854, Validation Loss: 0.9506, Validation Acc: 64.2\n",
      "Epoch: [10/10], Step: [601/782], Train Loss: 0.5852\n",
      "Epoch: [10/10], Step: [751/782], Train Loss: 0.5921\n",
      "Epoch: [10/10], Step: [751/782], Train Loss: 0.5921, Validation Loss: 1.0309, Validation Acc: 63.6\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5620, Train Accuracy: 78.837\n",
      "Val loss: 0.8390, Val Acc: 63.7\n",
      "Total training time: 316.45563793182373\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 100\n",
    "hidden_dim1 = 50\n",
    "hidden_dim2 = 25\n",
    "nn_baseline = BagOfWords(len(id2token), emb_dim, 'concat', True, hidden_dim1, hidden_dim2)\n",
    "\n",
    "# Train and validate model\n",
    "nn_baseline, val_loss, val_acc, \\\n",
    "    train_loss, train_acc, hist = train_and_val(train_loader = train_loader, \n",
    "                                                  val_loader = val_loader, \n",
    "                                                  model = nn_baseline, \n",
    "                                                  num_epochs = 10,\n",
    "                                                  verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Hyperparameter Tuning\n",
    "We want to fine-tune the following hyperparameters:\n",
    "- Interction methods (concat, sum, point-wise product)\n",
    "- Size of vocabulary\n",
    "- Embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check word frequency\n",
    "token_counter = Counter(all_train_premise_tokens + all_train_hypothesis_tokens)\n",
    "token_counter_df = pd.DataFrame \\\n",
    "                    .from_dict(token_counter, orient = \"index\") \\\n",
    "                    .rename(columns = {\"index\": \"token\", 0 : \"frequency\"}) \\\n",
    "                    .sort_values(by = \"frequency\", ascending = False) \\\n",
    "                    .reset_index()\n",
    "# Visualize word frequency\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(token_counter_df.index, token_counter_df[\"frequency\"])\n",
    "plt.xlabel(\"Rank of Word\")\n",
    "plt.ylabel(\"Word Frequency\")\n",
    "plt.ylim(0, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Tuning Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_list = [2500 * i for i in range(3, 7)]\n",
    "embed_dim_list = [25 * i for i in range(3, 7)]\n",
    "interaction_list = ['concat', 'sum', 'element_wise_product']\n",
    "logreg_result = []\n",
    "best_logreg = None\n",
    "best_hist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size : 7500\n",
      "Embedding dimension : 75\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8696, Train Accuracy: 67.631\n",
      "Val loss: 0.9005, Val Acc: 60.3\n",
      "Total training time: 226.63303899765015\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 75\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.9105, Train Accuracy: 61.365\n",
      "Val loss: 0.9737, Val Acc: 56.3\n",
      "Total training time: 226.33495903015137\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 75\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5266, Train Accuracy: 71.015\n",
      "Val loss: 1.0058, Val Acc: 61.3\n",
      "Total training time: 225.4711880683899\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 100\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8277, Train Accuracy: 67.984\n",
      "Val loss: 0.9097, Val Acc: 60.1\n",
      "Total training time: 248.09367990493774\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 100\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.9767, Train Accuracy: 61.675\n",
      "Val loss: 0.8097, Val Acc: 56.3\n",
      "Total training time: 248.25292897224426\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 100\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5004, Train Accuracy: 72.835\n",
      "Val loss: 0.8414, Val Acc: 60.3\n",
      "Total training time: 265.0144519805908\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 125\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8622, Train Accuracy: 68.495\n",
      "Val loss: 1.0065, Val Acc: 60.2\n",
      "Total training time: 292.63949370384216\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 125\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8321, Train Accuracy: 61.412\n",
      "Val loss: 0.9592, Val Acc: 56.4\n",
      "Total training time: 263.4362099170685\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 125\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5138, Train Accuracy: 74.511\n",
      "Val loss: 0.8723, Val Acc: 60.0\n",
      "Total training time: 268.0603470802307\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 150\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8615, Train Accuracy: 68.591\n",
      "Val loss: 0.9401, Val Acc: 60.2\n",
      "Total training time: 279.70082092285156\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 150\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.9146, Train Accuracy: 61.825\n",
      "Val loss: 1.0019, Val Acc: 55.8\n",
      "Total training time: 286.56102776527405\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 150\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4589, Train Accuracy: 76.146\n",
      "Val loss: 0.9855, Val Acc: 59.9\n",
      "Total training time: 279.33332777023315\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 75\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6839, Train Accuracy: 68.333\n",
      "Val loss: 0.9085, Val Acc: 60.8\n",
      "Total training time: 244.92871499061584\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 75\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8741, Train Accuracy: 62.116\n",
      "Val loss: 0.9203, Val Acc: 56.2\n",
      "Total training time: 245.06352376937866\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 75\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5730, Train Accuracy: 71.741\n",
      "Val loss: 0.8532, Val Acc: 58.9\n",
      "Total training time: 244.4458076953888\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 100\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7784, Train Accuracy: 68.989\n",
      "Val loss: 0.9066, Val Acc: 61.4\n",
      "Total training time: 268.28690099716187\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 100\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8157, Train Accuracy: 62.51\n",
      "Val loss: 1.0080, Val Acc: 56.7\n",
      "Total training time: 268.0242750644684\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 100\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5678, Train Accuracy: 73.682\n",
      "Val loss: 0.7643, Val Acc: 60.8\n",
      "Total training time: 266.91880989074707\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 125\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7994, Train Accuracy: 69.286\n",
      "Val loss: 0.8288, Val Acc: 60.8\n",
      "Total training time: 300.67708373069763\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 125\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7918, Train Accuracy: 62.861\n",
      "Val loss: 1.0484, Val Acc: 56.3\n",
      "Total training time: 299.39449095726013\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 125\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5700, Train Accuracy: 75.422\n",
      "Val loss: 0.7950, Val Acc: 61.3\n",
      "Total training time: 302.2305212020874\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 150\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6920, Train Accuracy: 69.74\n",
      "Val loss: 0.8450, Val Acc: 61.0\n",
      "Total training time: 326.38433718681335\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 150\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8182, Train Accuracy: 62.748\n",
      "Val loss: 1.0664, Val Acc: 56.0\n",
      "Total training time: 323.0602719783783\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 150\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7439, Train Accuracy: 77.31\n",
      "Val loss: 0.9010, Val Acc: 62.3\n",
      "Total training time: 323.9019408226013\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 75\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5515, Train Accuracy: 68.854\n",
      "Val loss: 0.8591, Val Acc: 61.2\n",
      "Total training time: 273.85368299484253\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 75\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.9111, Train Accuracy: 62.987\n",
      "Val loss: 0.9249, Val Acc: 56.2\n",
      "Total training time: 270.80107617378235\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 75\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7325, Train Accuracy: 72.117\n",
      "Val loss: 0.9054, Val Acc: 60.3\n",
      "Total training time: 273.0297646522522\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 100\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6090, Train Accuracy: 69.394\n",
      "Val loss: 0.7897, Val Acc: 60.7\n",
      "Total training time: 302.3423411846161\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 100\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6507, Train Accuracy: 63.247\n",
      "Val loss: 0.9614, Val Acc: 56.8\n",
      "Total training time: 302.14511275291443\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 100\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4544, Train Accuracy: 74.427\n",
      "Val loss: 1.0835, Val Acc: 59.7\n",
      "Total training time: 303.7833068370819\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 125\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6826, Train Accuracy: 70.101\n",
      "Val loss: 0.8090, Val Acc: 60.7\n",
      "Total training time: 338.3026239871979\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 125\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8305, Train Accuracy: 63.385\n",
      "Val loss: 1.0807, Val Acc: 55.5\n",
      "Total training time: 335.02014899253845\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 125\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6020, Train Accuracy: 76.324\n",
      "Val loss: 0.8971, Val Acc: 60.6\n",
      "Total training time: 335.25402903556824\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 150\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5445, Train Accuracy: 70.341\n",
      "Val loss: 0.8429, Val Acc: 60.4\n",
      "Total training time: 392.2899589538574\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 150\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7470, Train Accuracy: 63.399\n",
      "Val loss: 0.8351, Val Acc: 55.7\n",
      "Total training time: 372.1245472431183\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 150\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5282, Train Accuracy: 77.627\n",
      "Val loss: 0.9214, Val Acc: 60.5\n",
      "Total training time: 491.4797320365906\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 75\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.9157, Train Accuracy: 69.126\n",
      "Val loss: 0.9225, Val Acc: 61.3\n",
      "Total training time: 324.137286901474\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 75\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8016, Train Accuracy: 63.536\n",
      "Val loss: 0.9923, Val Acc: 56.4\n",
      "Total training time: 307.4125061035156\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 75\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7991, Train Accuracy: 72.242\n",
      "Val loss: 0.8597, Val Acc: 59.3\n",
      "Total training time: 321.8818337917328\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 100\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.3704, Train Accuracy: 69.818\n",
      "Val loss: 0.8670, Val Acc: 62.0\n",
      "Total training time: 333.22350692749023\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 100\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.8877, Train Accuracy: 63.874\n",
      "Val loss: 0.8267, Val Acc: 55.7\n",
      "Total training time: 343.9889328479767\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 100\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6102, Train Accuracy: 74.638\n",
      "Val loss: 0.7595, Val Acc: 61.8\n",
      "Total training time: 403.3946170806885\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 125\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6820, Train Accuracy: 70.279\n",
      "Val loss: 0.9107, Val Acc: 61.7\n",
      "Total training time: 428.72196984291077\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 125\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.9458, Train Accuracy: 63.746\n",
      "Val loss: 0.8805, Val Acc: 56.3\n",
      "Total training time: 372.1280369758606\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 125\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5244, Train Accuracy: 77.02\n",
      "Val loss: 0.8788, Val Acc: 63.3\n",
      "Total training time: 376.4297969341278\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 150\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7066, Train Accuracy: 70.715\n",
      "Val loss: 0.7995, Val Acc: 60.5\n",
      "Total training time: 411.31856513023376\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 150\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7014, Train Accuracy: 64.195\n",
      "Val loss: 1.0064, Val Acc: 55.3\n",
      "Total training time: 414.7230427265167\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 150\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4596, Train Accuracy: 78.171\n",
      "Val loss: 1.0756, Val Acc: 59.5\n",
      "Total training time: 415.6205487251282\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for v in vocab_size_list:\n",
    "    for e in embed_dim_list:\n",
    "        for i in interaction_list:\n",
    "            print(\"Vocabulary size : {}\".format(v))\n",
    "            print(\"Embedding dimension : {}\".format(e))\n",
    "            print(\"Interaction method: {}\".format(i))\n",
    "            # Convert vocabulary to indices\n",
    "            token2id, id2token, train_premise_ind, train_hypothesis_ind, val_premise_ind, val_hypothesis_ind = token2index_all(v)\n",
    "\n",
    "            # Create SNLIDataset classes\n",
    "            train_dataset = SNLIDataset(train_premise_ind, train_hypothesis_ind, train_snli[\"label\"])\n",
    "            val_dataset = SNLIDataset(val_premise_ind, val_hypothesis_ind, val_snli[\"label\"])\n",
    "\n",
    "            # Create DataLoaders\n",
    "            train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                                       batch_size=BATCH_SIZE,\n",
    "                                                       collate_fn=snli_collate_func,\n",
    "                                                       shuffle=True)\n",
    "            val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                                       batch_size=BATCH_SIZE,\n",
    "                                                       collate_fn=snli_collate_func,\n",
    "                                                       shuffle=True)\n",
    "\n",
    "            # Implement BoW for logistic regression\n",
    "            logreg = BagOfWords(vocab_size = v+2, \n",
    "                                emb_dim = e, \n",
    "                                interaction = i)\n",
    "\n",
    "            # Train and validate model\n",
    "            logreg, val_loss, val_acc, \\\n",
    "                train_loss, train_acc, hist = train_and_val(train_loader = train_loader, \n",
    "                                                              val_loader = val_loader, \n",
    "                                                              model = logreg, \n",
    "                                                              num_epochs = 10,\n",
    "                                                              verbose = False)\n",
    "            # Check the number of trained parameter\n",
    "            num_param = sum(p.numel() for p in logreg.parameters())\n",
    "            \n",
    "            logreg_result.append([v, e, i, val_loss, val_acc, train_loss, train_acc, num_param, hist])\n",
    "            print('-'*50)\n",
    "            # Check if the current model returns the lowest validation loss\n",
    "            if val_acc == max(x[4] for x in logreg_result):\n",
    "                best_logreg = logreg\n",
    "                best_hist = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "#torch.save(best_logreg.state_dict(), 'models/best_logreg.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BagOfWords(\n",
       "  (embed): Embedding(15002, 125, padding_idx=0)\n",
       "  (linear): Linear(in_features=125, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dimension\n",
    "best_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models sorted by validation accuracy\n",
    "logreg_df = pd.DataFrame.from_dict(logreg_result[:7]) \\\n",
    "                        .rename(columns = {0: \"vocab_size\", 1: \"embed_dim\",\n",
    "                                            2: \"interaction\", 3: \"val_loss\", \n",
    "                                            4: \"val_acc\", 5: \"train_loss\", \n",
    "                                           6: \"train_acc\", 7: \"num_param\"}) \\\n",
    "                        .sort_values(\"val_acc\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>interaction</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>num_param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15000</td>\n",
       "      <td>125</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>63.3</td>\n",
       "      <td>0.5244</td>\n",
       "      <td>77.020</td>\n",
       "      <td>1875628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10000</td>\n",
       "      <td>150</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>62.3</td>\n",
       "      <td>0.7439</td>\n",
       "      <td>77.310</td>\n",
       "      <td>1500753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15000</td>\n",
       "      <td>100</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>69.818</td>\n",
       "      <td>1500803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15000</td>\n",
       "      <td>100</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.7595</td>\n",
       "      <td>61.8</td>\n",
       "      <td>0.6102</td>\n",
       "      <td>74.638</td>\n",
       "      <td>1500503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>15000</td>\n",
       "      <td>125</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>61.7</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>70.279</td>\n",
       "      <td>1876003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9066</td>\n",
       "      <td>61.4</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>68.989</td>\n",
       "      <td>1000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10000</td>\n",
       "      <td>125</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.7950</td>\n",
       "      <td>61.3</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>75.422</td>\n",
       "      <td>1250628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7500</td>\n",
       "      <td>75</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.0058</td>\n",
       "      <td>61.3</td>\n",
       "      <td>0.5266</td>\n",
       "      <td>71.015</td>\n",
       "      <td>562878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>15000</td>\n",
       "      <td>75</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>61.3</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>69.126</td>\n",
       "      <td>1125603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12500</td>\n",
       "      <td>75</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>61.2</td>\n",
       "      <td>0.5515</td>\n",
       "      <td>68.854</td>\n",
       "      <td>938103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10000</td>\n",
       "      <td>150</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8450</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>69.740</td>\n",
       "      <td>1501203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10000</td>\n",
       "      <td>75</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>60.8</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>68.333</td>\n",
       "      <td>750603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.7643</td>\n",
       "      <td>60.8</td>\n",
       "      <td>0.5678</td>\n",
       "      <td>73.682</td>\n",
       "      <td>1000503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10000</td>\n",
       "      <td>125</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8288</td>\n",
       "      <td>60.8</td>\n",
       "      <td>0.7994</td>\n",
       "      <td>69.286</td>\n",
       "      <td>1251003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12500</td>\n",
       "      <td>125</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>60.7</td>\n",
       "      <td>0.6826</td>\n",
       "      <td>70.101</td>\n",
       "      <td>1563503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12500</td>\n",
       "      <td>100</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.7897</td>\n",
       "      <td>60.7</td>\n",
       "      <td>0.6090</td>\n",
       "      <td>69.394</td>\n",
       "      <td>1250803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12500</td>\n",
       "      <td>125</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>60.6</td>\n",
       "      <td>0.6020</td>\n",
       "      <td>76.324</td>\n",
       "      <td>1563128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12500</td>\n",
       "      <td>150</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.9214</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>77.627</td>\n",
       "      <td>1875753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15000</td>\n",
       "      <td>150</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.7995</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0.7066</td>\n",
       "      <td>70.715</td>\n",
       "      <td>2251203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12500</td>\n",
       "      <td>150</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8429</td>\n",
       "      <td>60.4</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>70.341</td>\n",
       "      <td>1876203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12500</td>\n",
       "      <td>75</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.9054</td>\n",
       "      <td>60.3</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>72.117</td>\n",
       "      <td>937878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7500</td>\n",
       "      <td>75</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>60.3</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>67.641</td>\n",
       "      <td>563103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7500</td>\n",
       "      <td>100</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>60.3</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>72.835</td>\n",
       "      <td>750503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7500</td>\n",
       "      <td>125</td>\n",
       "      <td>concat</td>\n",
       "      <td>1.0065</td>\n",
       "      <td>60.3</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>68.495</td>\n",
       "      <td>938503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7500</td>\n",
       "      <td>150</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>60.2</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>68.591</td>\n",
       "      <td>1126203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7500</td>\n",
       "      <td>100</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>60.1</td>\n",
       "      <td>0.8277</td>\n",
       "      <td>67.984</td>\n",
       "      <td>750803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7500</td>\n",
       "      <td>125</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.5138</td>\n",
       "      <td>74.511</td>\n",
       "      <td>938128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7500</td>\n",
       "      <td>150</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>59.9</td>\n",
       "      <td>0.4589</td>\n",
       "      <td>76.146</td>\n",
       "      <td>1125753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12500</td>\n",
       "      <td>100</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.0835</td>\n",
       "      <td>59.7</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>74.427</td>\n",
       "      <td>1250503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15000</td>\n",
       "      <td>150</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.0756</td>\n",
       "      <td>59.5</td>\n",
       "      <td>0.4596</td>\n",
       "      <td>78.171</td>\n",
       "      <td>2250753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>15000</td>\n",
       "      <td>75</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>59.3</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>72.242</td>\n",
       "      <td>1125378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10000</td>\n",
       "      <td>75</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.8532</td>\n",
       "      <td>58.9</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>71.741</td>\n",
       "      <td>750378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12500</td>\n",
       "      <td>100</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>56.8</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>63.247</td>\n",
       "      <td>1250503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>sum</td>\n",
       "      <td>1.0080</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.8157</td>\n",
       "      <td>62.510</td>\n",
       "      <td>1000503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7500</td>\n",
       "      <td>125</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>56.4</td>\n",
       "      <td>0.8321</td>\n",
       "      <td>61.412</td>\n",
       "      <td>938128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>15000</td>\n",
       "      <td>75</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>56.4</td>\n",
       "      <td>0.8016</td>\n",
       "      <td>63.536</td>\n",
       "      <td>1125378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7500</td>\n",
       "      <td>75</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>61.365</td>\n",
       "      <td>562878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7500</td>\n",
       "      <td>100</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>61.675</td>\n",
       "      <td>750503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10000</td>\n",
       "      <td>125</td>\n",
       "      <td>sum</td>\n",
       "      <td>1.0484</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0.7918</td>\n",
       "      <td>62.861</td>\n",
       "      <td>1250628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15000</td>\n",
       "      <td>125</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>63.746</td>\n",
       "      <td>1875628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12500</td>\n",
       "      <td>75</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>56.2</td>\n",
       "      <td>0.9111</td>\n",
       "      <td>62.987</td>\n",
       "      <td>937878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10000</td>\n",
       "      <td>75</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9203</td>\n",
       "      <td>56.2</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>62.116</td>\n",
       "      <td>750378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10000</td>\n",
       "      <td>150</td>\n",
       "      <td>sum</td>\n",
       "      <td>1.0664</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>62.748</td>\n",
       "      <td>1500753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7500</td>\n",
       "      <td>150</td>\n",
       "      <td>sum</td>\n",
       "      <td>1.0019</td>\n",
       "      <td>55.8</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>61.825</td>\n",
       "      <td>1125753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15000</td>\n",
       "      <td>100</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.8267</td>\n",
       "      <td>55.7</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>63.874</td>\n",
       "      <td>1500503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12500</td>\n",
       "      <td>150</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>55.7</td>\n",
       "      <td>0.7470</td>\n",
       "      <td>63.399</td>\n",
       "      <td>1875753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12500</td>\n",
       "      <td>125</td>\n",
       "      <td>sum</td>\n",
       "      <td>1.0808</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.8305</td>\n",
       "      <td>63.385</td>\n",
       "      <td>1563128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15000</td>\n",
       "      <td>150</td>\n",
       "      <td>sum</td>\n",
       "      <td>1.0065</td>\n",
       "      <td>55.3</td>\n",
       "      <td>0.7014</td>\n",
       "      <td>64.195</td>\n",
       "      <td>2250753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vocab_size  embed_dim           interaction  val_loss  val_acc  \\\n",
       "44       15000        125  element_wise_product    0.8788     63.3   \n",
       "23       10000        150  element_wise_product    0.9010     62.3   \n",
       "39       15000        100                concat    0.8670     62.0   \n",
       "41       15000        100  element_wise_product    0.7595     61.8   \n",
       "42       15000        125                concat    0.9107     61.7   \n",
       "15       10000        100                concat    0.9066     61.4   \n",
       "20       10000        125  element_wise_product    0.7950     61.3   \n",
       "2         7500         75  element_wise_product    1.0058     61.3   \n",
       "36       15000         75                concat    0.9225     61.3   \n",
       "24       12500         75                concat    0.8591     61.2   \n",
       "21       10000        150                concat    0.8450     61.0   \n",
       "12       10000         75                concat    0.9085     60.8   \n",
       "17       10000        100  element_wise_product    0.7643     60.8   \n",
       "18       10000        125                concat    0.8288     60.8   \n",
       "30       12500        125                concat    0.8090     60.7   \n",
       "27       12500        100                concat    0.7897     60.7   \n",
       "32       12500        125  element_wise_product    0.8971     60.6   \n",
       "35       12500        150  element_wise_product    0.9214     60.5   \n",
       "45       15000        150                concat    0.7995     60.5   \n",
       "33       12500        150                concat    0.8429     60.4   \n",
       "26       12500         75  element_wise_product    0.9054     60.3   \n",
       "0         7500         75                concat    0.9005     60.3   \n",
       "5         7500        100  element_wise_product    0.8414     60.3   \n",
       "6         7500        125                concat    1.0065     60.3   \n",
       "9         7500        150                concat    0.9401     60.2   \n",
       "3         7500        100                concat    0.9097     60.1   \n",
       "8         7500        125  element_wise_product    0.8723     60.0   \n",
       "11        7500        150  element_wise_product    0.9855     59.9   \n",
       "29       12500        100  element_wise_product    1.0835     59.7   \n",
       "47       15000        150  element_wise_product    1.0756     59.5   \n",
       "38       15000         75  element_wise_product    0.8597     59.3   \n",
       "14       10000         75  element_wise_product    0.8532     58.9   \n",
       "28       12500        100                   sum    0.9614     56.8   \n",
       "16       10000        100                   sum    1.0080     56.7   \n",
       "7         7500        125                   sum    0.9592     56.4   \n",
       "37       15000         75                   sum    0.9923     56.4   \n",
       "1         7500         75                   sum    0.9737     56.3   \n",
       "4         7500        100                   sum    0.8097     56.3   \n",
       "19       10000        125                   sum    1.0484     56.3   \n",
       "43       15000        125                   sum    0.8805     56.3   \n",
       "25       12500         75                   sum    0.9249     56.2   \n",
       "13       10000         75                   sum    0.9203     56.2   \n",
       "22       10000        150                   sum    1.0664     56.0   \n",
       "10        7500        150                   sum    1.0019     55.8   \n",
       "40       15000        100                   sum    0.8267     55.7   \n",
       "34       12500        150                   sum    0.8351     55.7   \n",
       "31       12500        125                   sum    1.0808     55.5   \n",
       "46       15000        150                   sum    1.0065     55.3   \n",
       "\n",
       "    train_loss  train_acc  num_param  \n",
       "44      0.5244     77.020    1875628  \n",
       "23      0.7439     77.310    1500753  \n",
       "39      0.3704     69.818    1500803  \n",
       "41      0.6102     74.638    1500503  \n",
       "42      0.6820     70.279    1876003  \n",
       "15      0.7784     68.989    1000803  \n",
       "20      0.5700     75.422    1250628  \n",
       "2       0.5266     71.015     562878  \n",
       "36      0.9157     69.126    1125603  \n",
       "24      0.5515     68.854     938103  \n",
       "21      0.6920     69.740    1501203  \n",
       "12      0.6839     68.333     750603  \n",
       "17      0.5678     73.682    1000503  \n",
       "18      0.7994     69.286    1251003  \n",
       "30      0.6826     70.101    1563503  \n",
       "27      0.6090     69.394    1250803  \n",
       "32      0.6020     76.324    1563128  \n",
       "35      0.5282     77.627    1875753  \n",
       "45      0.7066     70.715    2251203  \n",
       "33      0.5445     70.341    1876203  \n",
       "26      0.7325     72.117     937878  \n",
       "0       0.8696     67.641     563103  \n",
       "5       0.5004     72.835     750503  \n",
       "6       0.8622     68.495     938503  \n",
       "9       0.8615     68.591    1126203  \n",
       "3       0.8277     67.984     750803  \n",
       "8       0.5138     74.511     938128  \n",
       "11      0.4589     76.146    1125753  \n",
       "29      0.4544     74.427    1250503  \n",
       "47      0.4596     78.171    2250753  \n",
       "38      0.7991     72.242    1125378  \n",
       "14      0.5730     71.741     750378  \n",
       "28      0.6507     63.247    1250503  \n",
       "16      0.8157     62.510    1000503  \n",
       "7       0.8321     61.412     938128  \n",
       "37      0.8016     63.536    1125378  \n",
       "1       0.9105     61.365     562878  \n",
       "4       0.9767     61.675     750503  \n",
       "19      0.7918     62.861    1250628  \n",
       "43      0.9458     63.746    1875628  \n",
       "25      0.9111     62.987     937878  \n",
       "13      0.8741     62.116     750378  \n",
       "22      0.8182     62.748    1500753  \n",
       "10      0.9146     61.825    1125753  \n",
       "40      0.8877     63.874    1500503  \n",
       "34      0.7470     63.399    1875753  \n",
       "31      0.8305     63.385    1563128  \n",
       "46      0.7014     64.195    2250753  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table for all metrics\n",
    "logreg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table for all metrics\n",
    "logreg_df = logreg_df.sort_values(\"val_acc\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create visualizations for the best model\n",
    "plt.plot(best_hist[0], label = \"Train Loss\")\n",
    "plt.plot(best_hist[1], label = \"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross-Entrophy Loss\")\n",
    "plt.title(\"Best Logistic Regression Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create visualizations for the best model\n",
    "plt.plot(hist[2], label = \"Train Accuracy\")\n",
    "plt.plot(hist[3], label = \"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Best Logistic Regression Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: three women on a stage one wearing red shoes black pants and a gray shirt is sitting on a prop another is sitting on the floor and the third wearing a black shirt and pants is standing as a gentleman in the back tunes an instrument\n",
      "Hypothesis: there are two women standing on the stage\n",
      "Label: 2\n",
      "\n",
      "Premise: four people sit on a subway two read books one looks at a cellphone and is wearing knee high boots\n",
      "Hypothesis: multiple people are on a subway together with each of them doing their own thing\n",
      "Label: 0\n",
      "\n",
      "Premise: bicycles stationed while a group of people socialize\n",
      "Hypothesis: people get together near a stand of bicycles\n",
      "Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check predictions\n",
    "# Create validation DataLoader for 100 observations\n",
    "token2id, id2token, train_premise_ind, train_hypothesis_ind, val_premise_ind, val_hypothesis_ind = token2index_all(15000)\n",
    "val_dataset = SNLIDataset(val_premise_ind, val_hypothesis_ind, val_snli[\"label\"])\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=len(val_dataset),\n",
    "                                           collate_fn=snli_collate_func,\n",
    "                                           shuffle=False)\n",
    "# Create prediction\n",
    "best_logreg.eval()\n",
    "for premise, p_length, hypothesis, h_length, labels in val_loader:\n",
    "    outputs = best_logreg(premise, p_length, hypothesis, h_length)\n",
    "    predicted = F.softmax(outputs, dim=1).max(1, keepdim=True)[1] \n",
    "    actual_labels = labels.numpy()\n",
    "    predicted_labels = np.hstack(predicted.numpy())\n",
    "\n",
    "# Check first three correct predictions\n",
    "# {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "for i in np.where(actual_labels == predicted_labels)[0][:3]:\n",
    "    premise = np.array(id2token)[val_dataset.premise[i]]\n",
    "    hypothesis = np.array(id2token)[val_dataset.hypothesis[i]]\n",
    "    print(\"Premise: {}\".format(\" \".join(premise)))\n",
    "    print(\"Hypothesis: {}\".format(\" \".join(hypothesis)))\n",
    "    print(\"Label: {}\".format(actual_labels[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: two people are in a green forest\n",
      "Hypothesis: the forest is not dead\n",
      "Label: 0\n",
      "Prediction: 2\n",
      "\n",
      "Premise: two women one walking her dog the other pushing a stroller\n",
      "Hypothesis: there is a snowstorm\n",
      "Label: 2\n",
      "Prediction: 0\n",
      "\n",
      "Premise: three people and a white dog are sitting in the sand on a beach\n",
      "Hypothesis: three dogs and a person are sitting in the snow\n",
      "Label: 2\n",
      "Prediction: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check first three incorrect predictions\n",
    "# {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "for i in np.where(actual_labels != predicted_labels)[0][:3]:\n",
    "    premise = np.array(id2token)[val_dataset.premise[i]]\n",
    "    hypothesis = np.array(id2token)[val_dataset.hypothesis[i]]\n",
    "    print(\"Premise: {}\".format(\" \".join(premise)))\n",
    "    print(\"Hypothesis: {}\".format(\" \".join(hypothesis)))\n",
    "    print(\"Label: {}\".format(actual_labels[i]))\n",
    "    print(\"Prediction: {}\".format(predicted_labels[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Tuning Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed dimension for hidden layers\n",
    "hidden_dim1 = 50\n",
    "hidden_dim2 = 25\n",
    "\n",
    "# Tuning parameters\n",
    "vocab_size_list = [2500 * i for i in range(3, 7)]\n",
    "embed_dim_list = [25 * i for i in range(3, 7)]\n",
    "interaction_list = ['concat', 'sum', 'element_wise_product']\n",
    "nn_result = []\n",
    "best_nn = None\n",
    "best_hist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size : 7500\n",
      "Embedding dimension : 75\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.3723, Train Accuracy: 76.218\n",
      "Val loss: 0.8953, Val Acc: 61.8\n",
      "Total training time: 279.19124603271484\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 75\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7365, Train Accuracy: 69.117\n",
      "Val loss: 0.8903, Val Acc: 59.6\n",
      "Total training time: 288.26658296585083\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 75\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5287, Train Accuracy: 74.25\n",
      "Val loss: 0.9020, Val Acc: 58.4\n",
      "Total training time: 287.1514208316803\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 100\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4901, Train Accuracy: 78.194\n",
      "Val loss: 0.9933, Val Acc: 62.1\n",
      "Total training time: 318.8278398513794\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 100\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4627, Train Accuracy: 69.966\n",
      "Val loss: 0.9763, Val Acc: 58.4\n",
      "Total training time: 309.3420958518982\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 100\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7532, Train Accuracy: 76.903\n",
      "Val loss: 1.0544, Val Acc: 57.8\n",
      "Total training time: 309.78632378578186\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 125\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.3412, Train Accuracy: 79.453\n",
      "Val loss: 0.9152, Val Acc: 64.8\n",
      "Total training time: 329.88629603385925\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 125\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5308, Train Accuracy: 71.671\n",
      "Val loss: 0.9894, Val Acc: 58.4\n",
      "Total training time: 336.8060419559479\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 125\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7467, Train Accuracy: 79.044\n",
      "Val loss: 1.0721, Val Acc: 60.0\n",
      "Total training time: 328.56311416625977\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 150\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4178, Train Accuracy: 79.963\n",
      "Val loss: 0.7687, Val Acc: 63.4\n",
      "Total training time: 361.3794901371002\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 150\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6193, Train Accuracy: 72.345\n",
      "Val loss: 0.9819, Val Acc: 56.7\n",
      "Total training time: 347.259388923645\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 7500\n",
      "Embedding dimension : 150\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4144, Train Accuracy: 81.614\n",
      "Val loss: 0.8563, Val Acc: 57.7\n",
      "Total training time: 355.11306524276733\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 75\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4850, Train Accuracy: 77.745\n",
      "Val loss: 0.8291, Val Acc: 64.7\n",
      "Total training time: 312.9249458312988\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 75\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6233, Train Accuracy: 69.584\n",
      "Val loss: 0.8505, Val Acc: 57.8\n",
      "Total training time: 310.88374304771423\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 75\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6670, Train Accuracy: 74.676\n",
      "Val loss: 1.0274, Val Acc: 58.8\n",
      "Total training time: 311.64539098739624\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 100\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5839, Train Accuracy: 79.35\n",
      "Val loss: 0.9262, Val Acc: 63.7\n",
      "Total training time: 344.33310985565186\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 100\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7415, Train Accuracy: 71.824\n",
      "Val loss: 0.9613, Val Acc: 57.4\n",
      "Total training time: 335.2970931529999\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 100\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7141, Train Accuracy: 78.172\n",
      "Val loss: 1.0532, Val Acc: 58.3\n",
      "Total training time: 342.52568101882935\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 125\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5931, Train Accuracy: 80.474\n",
      "Val loss: 0.6839, Val Acc: 65.0\n",
      "Total training time: 371.4843759536743\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 125\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7164, Train Accuracy: 72.29\n",
      "Val loss: 0.9640, Val Acc: 58.8\n",
      "Total training time: 368.5945029258728\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 125\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5646, Train Accuracy: 80.551\n",
      "Val loss: 1.0223, Val Acc: 58.5\n",
      "Total training time: 369.1339499950409\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 150\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5450, Train Accuracy: 82.233\n",
      "Val loss: 0.8085, Val Acc: 65.2\n",
      "Total training time: 394.8099629878998\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 150\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7538, Train Accuracy: 72.79\n",
      "Val loss: 0.8057, Val Acc: 57.8\n",
      "Total training time: 392.5880582332611\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 10000\n",
      "Embedding dimension : 150\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4679, Train Accuracy: 82.718\n",
      "Val loss: 1.1233, Val Acc: 58.3\n",
      "Total training time: 392.6340389251709\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 75\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6237, Train Accuracy: 77.027\n",
      "Val loss: 0.6562, Val Acc: 64.6\n",
      "Total training time: 332.61516404151917\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 75\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5560, Train Accuracy: 70.613\n",
      "Val loss: 0.9679, Val Acc: 57.0\n",
      "Total training time: 331.7249140739441\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 75\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5507, Train Accuracy: 75.474\n",
      "Val loss: 0.9660, Val Acc: 55.0\n",
      "Total training time: 333.47946286201477\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 100\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6646, Train Accuracy: 79.851\n",
      "Val loss: 0.8546, Val Acc: 64.7\n",
      "Total training time: 372.58225893974304\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 100\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7920, Train Accuracy: 71.604\n",
      "Val loss: 0.9207, Val Acc: 59.7\n",
      "Total training time: 370.3814709186554\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 100\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6264, Train Accuracy: 78.422\n",
      "Val loss: 1.1006, Val Acc: 57.6\n",
      "Total training time: 372.272922039032\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 125\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5985, Train Accuracy: 80.744\n",
      "Val loss: 0.9627, Val Acc: 61.9\n",
      "Total training time: 406.2489490509033\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 125\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5061, Train Accuracy: 72.055\n",
      "Val loss: 0.9380, Val Acc: 58.7\n",
      "Total training time: 402.9192488193512\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 125\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.6565, Train Accuracy: 80.662\n",
      "Val loss: 0.9882, Val Acc: 58.5\n",
      "Total training time: 404.6265490055084\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 150\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4033, Train Accuracy: 81.535\n",
      "Val loss: 0.8735, Val Acc: 62.9\n",
      "Total training time: 437.45687985420227\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 150\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5312, Train Accuracy: 74.489\n",
      "Val loss: 1.1427, Val Acc: 57.4\n",
      "Total training time: 435.5067801475525\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 12500\n",
      "Embedding dimension : 150\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4278, Train Accuracy: 83.208\n",
      "Val loss: 1.2244, Val Acc: 60.4\n",
      "Total training time: 444.08871483802795\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 75\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5811, Train Accuracy: 78.507\n",
      "Val loss: 0.8665, Val Acc: 62.4\n",
      "Total training time: 356.5332601070404\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 75\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7784, Train Accuracy: 71.102\n",
      "Val loss: 1.0660, Val Acc: 60.7\n",
      "Total training time: 353.38102316856384\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 75\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4719, Train Accuracy: 76.069\n",
      "Val loss: 1.0091, Val Acc: 59.5\n",
      "Total training time: 355.3913221359253\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 100\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5308, Train Accuracy: 80.353\n",
      "Val loss: 0.8616, Val Acc: 62.3\n",
      "Total training time: 403.1957709789276\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 100\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7418, Train Accuracy: 72.254\n",
      "Val loss: 0.9955, Val Acc: 57.4\n",
      "Total training time: 400.52364110946655\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 100\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5129, Train Accuracy: 79.035\n",
      "Val loss: 1.0386, Val Acc: 58.0\n",
      "Total training time: 402.05149388313293\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 125\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.4040, Train Accuracy: 81.398\n",
      "Val loss: 1.0046, Val Acc: 63.9\n",
      "Total training time: 443.9193868637085\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 125\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.7458, Train Accuracy: 73.376\n",
      "Val loss: 1.1178, Val Acc: 58.1\n",
      "Total training time: 441.38918805122375\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 125\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.3758, Train Accuracy: 80.673\n",
      "Val loss: 1.1520, Val Acc: 57.0\n",
      "Total training time: 443.66149520874023\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 150\n",
      "Interaction method: concat\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.3949, Train Accuracy: 82.933\n",
      "Val loss: 1.0073, Val Acc: 63.6\n",
      "Total training time: 483.4027259349823\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 150\n",
      "Interaction method: sum\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.5686, Train Accuracy: 74.728\n",
      "Val loss: 0.9201, Val Acc: 57.7\n",
      "Total training time: 482.5818040370941\n",
      "--------------------------------------------------\n",
      "Vocabulary size : 15000\n",
      "Embedding dimension : 150\n",
      "Interaction method: element_wise_product\n",
      "\n",
      "Final Stats:\n",
      "After training for 10 epochs\n",
      "Train Loss: 0.3684, Train Accuracy: 83.655\n",
      "Val loss: 1.1053, Val Acc: 57.6\n",
      "Total training time: 488.9298770427704\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for v in vocab_size_list:\n",
    "    for e in embed_dim_list:\n",
    "        for i in interaction_list:\n",
    "            print(\"Vocabulary size : {}\".format(v))\n",
    "            print(\"Embedding dimension : {}\".format(e))\n",
    "            print(\"Interaction method: {}\".format(i))\n",
    "            # Convert vocabulary to indices\n",
    "            token2id, id2token, train_premise_ind, train_hypothesis_ind, val_premise_ind, val_hypothesis_ind = token2index_all(v)\n",
    "\n",
    "            # Create SNLIDataset classes\n",
    "            train_dataset = SNLIDataset(train_premise_ind, train_hypothesis_ind, train_snli[\"label\"])\n",
    "            val_dataset = SNLIDataset(val_premise_ind, val_hypothesis_ind, val_snli[\"label\"])\n",
    "\n",
    "            # Create DataLoaders\n",
    "            train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                                       batch_size=BATCH_SIZE,\n",
    "                                                       collate_fn=snli_collate_func,\n",
    "                                                       shuffle=True)\n",
    "            val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                                       batch_size=BATCH_SIZE,\n",
    "                                                       collate_fn=snli_collate_func,\n",
    "                                                       shuffle=True)\n",
    "\n",
    "            # Implement BoW for logistic regression\n",
    "            neural_net = BagOfWords(vocab_size = v+2, \n",
    "                                    emb_dim = e, \n",
    "                                    interaction = i, \n",
    "                                    neural_net = True,\n",
    "                                    hidden_dim1 = hidden_dim1, \n",
    "                                    hidden_dim2 = hidden_dim2)\n",
    "\n",
    "            # Train and validate model\n",
    "            neural_net, val_loss, val_acc, \\\n",
    "                train_loss, train_acc, hist = train_and_val(train_loader = train_loader, \n",
    "                                                          val_loader = val_loader, \n",
    "                                                          model = neural_net, \n",
    "                                                          num_epochs = 10,\n",
    "                                                          verbose = False)\n",
    "            # Check the number of trained parameter\n",
    "            num_param = sum(p.numel() for p in neural_net.parameters())\n",
    "            \n",
    "            nn_result.append([v, e, i, val_loss, val_acc, train_loss, train_acc, num_param, hist])\n",
    "            print('-'*50)\n",
    "            # Check if the current model returns the lowest validation loss\n",
    "            if val_acc == max(x[4] for x in nn_result):\n",
    "                best_nn = neural_net\n",
    "                best_hist = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_nn.state_dict(), 'models/best_nn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BagOfWords(\n",
       "  (embed): Embedding(10002, 150, padding_idx=0)\n",
       "  (first_layer): Linear(in_features=300, out_features=50, bias=True)\n",
       "  (second_layer): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (last_linear): Linear(in_features=25, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dimension\n",
    "best_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models sorted by validation accuracy\n",
    "nn_df = pd.DataFrame.from_dict(nn_result[:7]) \\\n",
    "                    .rename(columns = {0: \"vocab_size\", 1: \"embed_dim\",\n",
    "                                        2: \"interaction\", 3: \"val_loss\", \n",
    "                                        4: \"val_acc\", 5: \"train_loss\", \n",
    "                                       6: \"train_acc\", 7:\"num_param\"}) \\\n",
    "                    .sort_values(\"val_acc\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>interaction</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>num_param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10000</td>\n",
       "      <td>150</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>65.2</td>\n",
       "      <td>0.5450</td>\n",
       "      <td>82.233</td>\n",
       "      <td>1516703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10000</td>\n",
       "      <td>125</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.5931</td>\n",
       "      <td>80.474</td>\n",
       "      <td>1264153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7500</td>\n",
       "      <td>125</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>64.8</td>\n",
       "      <td>0.3412</td>\n",
       "      <td>79.453</td>\n",
       "      <td>951653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12500</td>\n",
       "      <td>100</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8546</td>\n",
       "      <td>64.7</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>79.851</td>\n",
       "      <td>1261603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10000</td>\n",
       "      <td>75</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>64.7</td>\n",
       "      <td>0.4850</td>\n",
       "      <td>77.745</td>\n",
       "      <td>759053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12500</td>\n",
       "      <td>75</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>64.6</td>\n",
       "      <td>0.6237</td>\n",
       "      <td>77.027</td>\n",
       "      <td>946553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>15000</td>\n",
       "      <td>125</td>\n",
       "      <td>concat</td>\n",
       "      <td>1.0046</td>\n",
       "      <td>63.9</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>81.398</td>\n",
       "      <td>1889153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>63.7</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>79.350</td>\n",
       "      <td>1011603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15000</td>\n",
       "      <td>150</td>\n",
       "      <td>concat</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>63.6</td>\n",
       "      <td>0.3949</td>\n",
       "      <td>82.933</td>\n",
       "      <td>2266703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7500</td>\n",
       "      <td>150</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.7687</td>\n",
       "      <td>63.4</td>\n",
       "      <td>0.4178</td>\n",
       "      <td>79.063</td>\n",
       "      <td>1141703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12500</td>\n",
       "      <td>150</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>62.9</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>81.535</td>\n",
       "      <td>1891703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>15000</td>\n",
       "      <td>75</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8665</td>\n",
       "      <td>62.4</td>\n",
       "      <td>0.5811</td>\n",
       "      <td>78.507</td>\n",
       "      <td>1134053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15000</td>\n",
       "      <td>100</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>62.3</td>\n",
       "      <td>0.5308</td>\n",
       "      <td>80.353</td>\n",
       "      <td>1511603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7500</td>\n",
       "      <td>100</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>62.1</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>78.194</td>\n",
       "      <td>761603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12500</td>\n",
       "      <td>125</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>61.9</td>\n",
       "      <td>0.5985</td>\n",
       "      <td>80.744</td>\n",
       "      <td>1576653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7500</td>\n",
       "      <td>75</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.8953</td>\n",
       "      <td>61.8</td>\n",
       "      <td>0.3723</td>\n",
       "      <td>76.218</td>\n",
       "      <td>571553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>15000</td>\n",
       "      <td>75</td>\n",
       "      <td>sum</td>\n",
       "      <td>1.0660</td>\n",
       "      <td>60.7</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>71.102</td>\n",
       "      <td>1130303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12500</td>\n",
       "      <td>150</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.2244</td>\n",
       "      <td>60.4</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>83.208</td>\n",
       "      <td>1884203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7500</td>\n",
       "      <td>125</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.0721</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7467</td>\n",
       "      <td>79.044</td>\n",
       "      <td>945403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12500</td>\n",
       "      <td>100</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9207</td>\n",
       "      <td>59.7</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>71.604</td>\n",
       "      <td>1256603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7500</td>\n",
       "      <td>75</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>69.117</td>\n",
       "      <td>567803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>15000</td>\n",
       "      <td>75</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.0091</td>\n",
       "      <td>59.5</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>76.069</td>\n",
       "      <td>1130303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10000</td>\n",
       "      <td>75</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.0274</td>\n",
       "      <td>58.8</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>74.676</td>\n",
       "      <td>755303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10000</td>\n",
       "      <td>125</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>58.8</td>\n",
       "      <td>0.7164</td>\n",
       "      <td>72.290</td>\n",
       "      <td>1257903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12500</td>\n",
       "      <td>125</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>58.7</td>\n",
       "      <td>0.5061</td>\n",
       "      <td>72.055</td>\n",
       "      <td>1570403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12500</td>\n",
       "      <td>125</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>80.662</td>\n",
       "      <td>1570403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10000</td>\n",
       "      <td>125</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.0223</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.5646</td>\n",
       "      <td>80.551</td>\n",
       "      <td>1257903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7500</td>\n",
       "      <td>75</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.5287</td>\n",
       "      <td>74.250</td>\n",
       "      <td>567803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7500</td>\n",
       "      <td>100</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9763</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.4627</td>\n",
       "      <td>69.966</td>\n",
       "      <td>756603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7500</td>\n",
       "      <td>125</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.5308</td>\n",
       "      <td>71.671</td>\n",
       "      <td>945403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10000</td>\n",
       "      <td>150</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.1233</td>\n",
       "      <td>58.3</td>\n",
       "      <td>0.4679</td>\n",
       "      <td>82.718</td>\n",
       "      <td>1509203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.0532</td>\n",
       "      <td>58.3</td>\n",
       "      <td>0.7147</td>\n",
       "      <td>78.172</td>\n",
       "      <td>1006603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15000</td>\n",
       "      <td>125</td>\n",
       "      <td>sum</td>\n",
       "      <td>1.1178</td>\n",
       "      <td>58.1</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>73.376</td>\n",
       "      <td>1882903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15000</td>\n",
       "      <td>100</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.0386</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.5129</td>\n",
       "      <td>79.035</td>\n",
       "      <td>1506603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7500</td>\n",
       "      <td>100</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.0544</td>\n",
       "      <td>57.8</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>76.903</td>\n",
       "      <td>756603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10000</td>\n",
       "      <td>150</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>57.8</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>72.790</td>\n",
       "      <td>1509203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10000</td>\n",
       "      <td>75</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>57.8</td>\n",
       "      <td>0.6233</td>\n",
       "      <td>69.584</td>\n",
       "      <td>755303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15000</td>\n",
       "      <td>150</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>57.7</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>74.728</td>\n",
       "      <td>2259203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7500</td>\n",
       "      <td>150</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>57.7</td>\n",
       "      <td>0.4144</td>\n",
       "      <td>81.614</td>\n",
       "      <td>1134203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15000</td>\n",
       "      <td>150</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.1053</td>\n",
       "      <td>57.6</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>83.655</td>\n",
       "      <td>2259203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12500</td>\n",
       "      <td>100</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.1006</td>\n",
       "      <td>57.6</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>78.422</td>\n",
       "      <td>1256603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15000</td>\n",
       "      <td>100</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.7418</td>\n",
       "      <td>72.254</td>\n",
       "      <td>1506603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12500</td>\n",
       "      <td>150</td>\n",
       "      <td>sum</td>\n",
       "      <td>1.1427</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.5312</td>\n",
       "      <td>74.489</td>\n",
       "      <td>1884203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>71.824</td>\n",
       "      <td>1006603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15000</td>\n",
       "      <td>125</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>1.1520</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>80.673</td>\n",
       "      <td>1882903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12500</td>\n",
       "      <td>75</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.5560</td>\n",
       "      <td>70.613</td>\n",
       "      <td>942803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7500</td>\n",
       "      <td>150</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.6193</td>\n",
       "      <td>72.345</td>\n",
       "      <td>1134203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12500</td>\n",
       "      <td>75</td>\n",
       "      <td>element_wise_product</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>75.474</td>\n",
       "      <td>942803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vocab_size  embed_dim           interaction  val_loss  val_acc  \\\n",
       "21       10000        150                concat    0.8085     65.2   \n",
       "18       10000        125                concat    0.6839     65.0   \n",
       "6         7500        125                concat    0.9152     64.8   \n",
       "27       12500        100                concat    0.8546     64.7   \n",
       "12       10000         75                concat    0.8291     64.7   \n",
       "24       12500         75                concat    0.6562     64.6   \n",
       "42       15000        125                concat    1.0046     63.9   \n",
       "15       10000        100                concat    0.9262     63.7   \n",
       "45       15000        150                concat    1.0073     63.6   \n",
       "9         7500        150                concat    0.7687     63.4   \n",
       "33       12500        150                concat    0.8735     62.9   \n",
       "36       15000         75                concat    0.8665     62.4   \n",
       "39       15000        100                concat    0.8616     62.3   \n",
       "3         7500        100                concat    0.9933     62.1   \n",
       "30       12500        125                concat    0.9627     61.9   \n",
       "0         7500         75                concat    0.8953     61.8   \n",
       "37       15000         75                   sum    1.0660     60.7   \n",
       "35       12500        150  element_wise_product    1.2244     60.4   \n",
       "8         7500        125  element_wise_product    1.0721     60.0   \n",
       "28       12500        100                   sum    0.9207     59.7   \n",
       "1         7500         75                   sum    0.8903     59.6   \n",
       "38       15000         75  element_wise_product    1.0091     59.5   \n",
       "14       10000         75  element_wise_product    1.0274     58.8   \n",
       "19       10000        125                   sum    0.9640     58.8   \n",
       "31       12500        125                   sum    0.9380     58.7   \n",
       "32       12500        125  element_wise_product    0.9882     58.5   \n",
       "20       10000        125  element_wise_product    1.0223     58.5   \n",
       "2         7500         75  element_wise_product    0.9020     58.4   \n",
       "4         7500        100                   sum    0.9763     58.4   \n",
       "7         7500        125                   sum    0.9894     58.4   \n",
       "23       10000        150  element_wise_product    1.1233     58.3   \n",
       "17       10000        100  element_wise_product    1.0532     58.3   \n",
       "43       15000        125                   sum    1.1178     58.1   \n",
       "41       15000        100  element_wise_product    1.0386     58.0   \n",
       "5         7500        100  element_wise_product    1.0544     57.8   \n",
       "22       10000        150                   sum    0.8057     57.8   \n",
       "13       10000         75                   sum    0.8505     57.8   \n",
       "46       15000        150                   sum    0.9201     57.7   \n",
       "11        7500        150  element_wise_product    0.8563     57.7   \n",
       "47       15000        150  element_wise_product    1.1053     57.6   \n",
       "29       12500        100  element_wise_product    1.1006     57.6   \n",
       "40       15000        100                   sum    0.9955     57.4   \n",
       "34       12500        150                   sum    1.1427     57.4   \n",
       "16       10000        100                   sum    0.9613     57.4   \n",
       "44       15000        125  element_wise_product    1.1520     57.0   \n",
       "25       12500         75                   sum    0.9679     57.0   \n",
       "10        7500        150                   sum    0.9819     56.7   \n",
       "26       12500         75  element_wise_product    0.9660     55.0   \n",
       "\n",
       "    train_loss  train_acc  num_param  \n",
       "21      0.5450     82.233    1516703  \n",
       "18      0.5931     80.474    1264153  \n",
       "6       0.3412     79.453     951653  \n",
       "27      0.6646     79.851    1261603  \n",
       "12      0.4850     77.745     759053  \n",
       "24      0.6237     77.027     946553  \n",
       "42      0.4040     81.398    1889153  \n",
       "15      0.5839     79.350    1011603  \n",
       "45      0.3949     82.933    2266703  \n",
       "9       0.4178     79.063    1141703  \n",
       "33      0.4033     81.535    1891703  \n",
       "36      0.5811     78.507    1134053  \n",
       "39      0.5308     80.353    1511603  \n",
       "3       0.4901     78.194     761603  \n",
       "30      0.5985     80.744    1576653  \n",
       "0       0.3723     76.218     571553  \n",
       "37      0.7784     71.102    1130303  \n",
       "35      0.4278     83.208    1884203  \n",
       "8       0.7467     79.044     945403  \n",
       "28      0.7920     71.604    1256603  \n",
       "1       0.7365     69.117     567803  \n",
       "38      0.4719     76.069    1130303  \n",
       "14      0.6670     74.676     755303  \n",
       "19      0.7164     72.290    1257903  \n",
       "31      0.5061     72.055    1570403  \n",
       "32      0.6565     80.662    1570403  \n",
       "20      0.5646     80.551    1257903  \n",
       "2       0.5287     74.250     567803  \n",
       "4       0.4627     69.966     756603  \n",
       "7       0.5308     71.671     945403  \n",
       "23      0.4679     82.718    1509203  \n",
       "17      0.7147     78.172    1006603  \n",
       "43      0.7458     73.376    1882903  \n",
       "41      0.5129     79.035    1506603  \n",
       "5       0.7532     76.903     756603  \n",
       "22      0.7538     72.790    1509203  \n",
       "13      0.6233     69.584     755303  \n",
       "46      0.5686     74.728    2259203  \n",
       "11      0.4144     81.614    1134203  \n",
       "47      0.3684     83.655    2259203  \n",
       "29      0.6264     78.422    1256603  \n",
       "40      0.7418     72.254    1506603  \n",
       "34      0.5312     74.489    1884203  \n",
       "16      0.7415     71.824    1006603  \n",
       "44      0.3758     80.673    1882903  \n",
       "25      0.5560     70.613     942803  \n",
       "10      0.6193     72.345    1134203  \n",
       "26      0.5507     75.474     942803  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table for all metrics\n",
    "nn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create visualizations for the best model\n",
    "plt.plot(best_hist[0], label = \"Train Loss\")\n",
    "plt.plot(best_hist[1], label = \"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross-Entrophy Loss\")\n",
    "plt.title(\"Best Neural Network Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist[2], label = \"Train Accuracy\")\n",
    "plt.plot(hist[3], label = \"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Best Neural Network\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: four people sit on a subway two read books one looks at a cellphone and is wearing knee high boots\n",
      "Hypothesis: multiple people are on a subway together with each of them doing their own thing\n",
      "Label: 0\n",
      "\n",
      "Premise: man in overalls with two horses\n",
      "Hypothesis: a man in overalls with two horses\n",
      "Label: 0\n",
      "\n",
      "Premise: two men are listening to music through headphones\n",
      "Hypothesis: two men listen to music\n",
      "Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check predictions\n",
    "# Create validation DataLoader for 100 observations\n",
    "token2id, id2token, train_premise_ind, train_hypothesis_ind, val_premise_ind, val_hypothesis_ind = token2index_all(10000)\n",
    "val_dataset = SNLIDataset(val_premise_ind, val_hypothesis_ind, val_snli[\"label\"])\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=len(val_dataset),\n",
    "                                           collate_fn=snli_collate_func,\n",
    "                                           shuffle=False)\n",
    "# Create prediction\n",
    "best_nn.eval()\n",
    "for premise, p_length, hypothesis, h_length, labels in val_loader:\n",
    "    outputs = best_nn(premise, p_length, hypothesis, h_length)\n",
    "    predicted = F.softmax(outputs, dim=1).max(1, keepdim=True)[1] \n",
    "    actual_labels = labels.numpy()\n",
    "    predicted_labels = np.hstack(predicted.numpy())\n",
    "\n",
    "# Check first three correct predictions\n",
    "# {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "for i in np.where(actual_labels == predicted_labels)[0][:3]:\n",
    "    premise = np.array(id2token)[val_dataset.premise[i]]\n",
    "    hypothesis = np.array(id2token)[val_dataset.hypothesis[i]]\n",
    "    print(\"Premise: {}\".format(\" \".join(premise)))\n",
    "    print(\"Hypothesis: {}\".format(\" \".join(hypothesis)))\n",
    "    print(\"Label: {}\".format(actual_labels[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: three women on a stage one wearing red shoes black pants and a gray shirt is sitting on a prop another is sitting on the floor and the third wearing a black shirt and pants is standing as a gentleman in the back tunes an instrument\n",
      "Hypothesis: there are two women standing on the stage\n",
      "Label: 2\n",
      "Prediction: 0\n",
      "\n",
      "Premise: bicycles stationed while a group of people socialize\n",
      "Hypothesis: people get together near a stand of bicycles\n",
      "Label: 0\n",
      "Prediction: 2\n",
      "\n",
      "Premise: man observes a <unk> given off by an electronic device\n",
      "Hypothesis: the man is examining what <unk> is given off by the device\n",
      "Label: 0\n",
      "Prediction: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check first three incorrect predictions\n",
    "# {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "for i in np.where(actual_labels != predicted_labels)[0][:3]:\n",
    "    premise = np.array(id2token)[val_dataset.premise[i]]\n",
    "    hypothesis = np.array(id2token)[val_dataset.hypothesis[i]]\n",
    "    print(\"Premise: {}\".format(\" \".join(premise)))\n",
    "    print(\"Hypothesis: {}\".format(\" \".join(hypothesis)))\n",
    "    print(\"Label: {}\".format(actual_labels[i]))\n",
    "    print(\"Prediction: {}\".format(predicted_labels[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Best Models\n",
    "#### 2.3.1 Best Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "best_logreg_path = os.path.join(root, 'models/best_logreg.pth')\n",
    "best_logreg_embed_dim = 125\n",
    "best_logreg_interaction = 'element_wise_product'\n",
    "\n",
    "# Load saved tokens\n",
    "token2id = pkl.load(open('tokens/logreg_token2id.p', 'rb'))\n",
    "id2token = pkl.load(open('tokens/logreg_id2token.p', 'rb'))\n",
    "# Load saved model\n",
    "best_logreg = BagOfWords(vocab_size = len(id2token), \n",
    "                                emb_dim = best_logreg_embed_dim, \n",
    "                                interaction = best_logreg_interaction)\n",
    "\n",
    "best_logreg.load_state_dict(torch.load(best_logreg_path))\n",
    "best_logreg.eval()\n",
    "\n",
    "# Recreate the validation set\n",
    "# Convert tokens in premise and hypothesis in the validation set into indices\n",
    "val_premise_ind = token2index_dataset(val_data_premise_tokens, token2id)\n",
    "val_hypothesis_ind = token2index_dataset(val_data_hypothesis_tokens, token2id)\n",
    "# Create SNLIDataset\n",
    "val_dataset = SNLIDataset(val_premise_ind, val_hypothesis_ind, val_snli[\"label\"])\n",
    "# Create DataLoader\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                                       batch_size=128,\n",
    "                                                       collate_fn=snli_collate_func,\n",
    "                                                       shuffle=True)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc = test_model(val_loader, best_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tokens/nn_token2id.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7b7fe5599a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load saved tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtoken2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokens/nn_token2id.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mid2token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokens/nn_id2token.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tokens/nn_token2id.p'"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "best_nn_path = os.path.join(root, 'models/best_nn.pth')\n",
    "best_nn_embed_dim = 150\n",
    "best_nn_interaction = 'concat'\n",
    "\n",
    "# Load saved tokens\n",
    "token2id = pkl.load(open('tokens/nn_token2id.p', 'rb'))\n",
    "id2token = pkl.load(open('tokens/nn_id2token.p', 'rb'))\n",
    "# Load saved model\n",
    "best_nn = BagOfWords(vocab_size = len(id2token), \n",
    "                                emb_dim = best_nn_embed_dim, \n",
    "                                interaction = best_nn_interaction,\n",
    "                                neural_net = True,\n",
    "                                hidden_dim1 = 50, \n",
    "                                hidden_dim2 = 25)\n",
    "\n",
    "best_nn.load_state_dict(torch.load(best_nn_path))\n",
    "best_nn.eval()\n",
    "\n",
    "# Recreate the validation set\n",
    "# Convert tokens in premise and hypothesis in the validation set into indices\n",
    "val_premise_ind = token2index_dataset(val_data_premise_tokens, token2id)\n",
    "val_hypothesis_ind = token2index_dataset(val_data_hypothesis_tokens, token2id)\n",
    "# Create SNLIDataset\n",
    "val_dataset = SNLIDataset(val_premise_ind, val_hypothesis_ind, val_snli[\"label\"])\n",
    "# Create DataLoader\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                                       batch_size=128,\n",
    "                                                       collate_fn=snli_collate_func,\n",
    "                                                       shuffle=True)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc = test_model(val_loader, best_nn)\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
