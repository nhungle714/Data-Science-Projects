{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1: Bag-of-Words based Natural Language Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II - MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_rows', 50)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import spacy\n",
    "import string\n",
    "import pickle as pkl\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "naming_dict = {'sentence1':'premise', 'sentence2':'hypothesis'}\n",
    "mnli_train = pd.read_csv('data/mnli_train.tsv', sep = '\\t').rename(columns = naming_dict)\n",
    "mnli_val = pd.read_csv('data/mnli_val.tsv', sep = '\\t').rename(columns = naming_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and now that was in fifty one that 's forty years ago that it was already a problem so it 's now uh</td>\n",
       "      <td>It was already a problem forty years ago but now it 's ten times worse !</td>\n",
       "      <td>neutral</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jon could smell baked bread on the air and his stomach rumbled .</td>\n",
       "      <td>Jon smelt food in the air and was hungry .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it will be like Italian basketball with the uh with with the uh NBA</td>\n",
       "      <td>This type of Italian basketball is nothing like the NBA .</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>well i think that 's about uh that 's about covered it for me so i think i 'll say good-bye and we 'll</td>\n",
       "      <td>Sorry but we are not done just yet .</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good job tenure , that is -- because in yet another column , she sneers at Sara Davidson for working on Dr. Quinn , Medicine Woman . Why ca n't the silly creature get a perfect job like hers ?</td>\n",
       "      <td>Dr. Quinn , Medicine Woman , was worked on by Sara Davidson .</td>\n",
       "      <td>entailment</td>\n",
       "      <td>slate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                            premise  \\\n",
       "0  and now that was in fifty one that 's forty years ago that it was already a problem so it 's now uh                                                                                                \n",
       "1  Jon could smell baked bread on the air and his stomach rumbled .                                                                                                                                   \n",
       "2  it will be like Italian basketball with the uh with with the uh NBA                                                                                                                                \n",
       "3  well i think that 's about uh that 's about covered it for me so i think i 'll say good-bye and we 'll                                                                                             \n",
       "4  Good job tenure , that is -- because in yet another column , she sneers at Sara Davidson for working on Dr. Quinn , Medicine Woman . Why ca n't the silly creature get a perfect job like hers ?   \n",
       "\n",
       "                                                                 hypothesis  \\\n",
       "0  It was already a problem forty years ago but now it 's ten times worse !   \n",
       "1  Jon smelt food in the air and was hungry .                                 \n",
       "2  This type of Italian basketball is nothing like the NBA .                  \n",
       "3  Sorry but we are not done just yet .                                       \n",
       "4  Dr. Quinn , Medicine Woman , was worked on by Sara Davidson .              \n",
       "\n",
       "           label      genre  \n",
       "0  neutral        telephone  \n",
       "1  neutral        fiction    \n",
       "2  contradiction  telephone  \n",
       "3  contradiction  telephone  \n",
       "4  entailment     slate      "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Not entirely , ' I snapped , harsher than intended .</td>\n",
       "      <td>I spoke more harshly than I wanted to .</td>\n",
       "      <td>entailment</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cook and then the next time it would be my turn and i 'd try to outdo him and then he 'd try to outdo me and we we was really a lot of fun and</td>\n",
       "      <td>I would cook and then the next turn would be his and we would try to outdo each other but sometimes we would get in a fight over things .</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The disorder hardly seemed to exist before the stimulant Ritalin came along .</td>\n",
       "      <td>The disorder did n't seem to be as common when Ritalin was n't around .</td>\n",
       "      <td>entailment</td>\n",
       "      <td>slate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Report and Order , in large part , adopts the unanimous recommendations of the Hearing Aid Compatibility Negotiated Rulemaking Committee , an advisory committee established by the Federal Communications Commission in 1995 .</td>\n",
       "      <td>The Report and Order ignores recommendations from committees associated with the Federal Communications Commission .</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDPA 's OIG 's mission is to prevent , detect , and eliminate fraud , waste , abuse , and misconduct in various payment programs .</td>\n",
       "      <td>IDPA 's OIG 's mission is clear and cares about payment programs .</td>\n",
       "      <td>entailment</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                               premise  \\\n",
       "0  'Not entirely , ' I snapped , harsher than intended .                                                                                                                                                                                 \n",
       "1  cook and then the next time it would be my turn and i 'd try to outdo him and then he 'd try to outdo me and we we was really a lot of fun and                                                                                        \n",
       "2  The disorder hardly seemed to exist before the stimulant Ritalin came along .                                                                                                                                                         \n",
       "3  The Report and Order , in large part , adopts the unanimous recommendations of the Hearing Aid Compatibility Negotiated Rulemaking Committee , an advisory committee established by the Federal Communications Commission in 1995 .   \n",
       "4  IDPA 's OIG 's mission is to prevent , detect , and eliminate fraud , waste , abuse , and misconduct in various payment programs .                                                                                                    \n",
       "\n",
       "                                                                                                                                  hypothesis  \\\n",
       "0  I spoke more harshly than I wanted to .                                                                                                     \n",
       "1  I would cook and then the next turn would be his and we would try to outdo each other but sometimes we would get in a fight over things .   \n",
       "2  The disorder did n't seem to be as common when Ritalin was n't around .                                                                     \n",
       "3  The Report and Order ignores recommendations from committees associated with the Federal Communications Commission .                        \n",
       "4  IDPA 's OIG 's mission is clear and cares about payment programs .                                                                          \n",
       "\n",
       "           label       genre  \n",
       "0  entailment     fiction     \n",
       "1  contradiction  telephone   \n",
       "2  entailment     slate       \n",
       "3  contradiction  government  \n",
       "4  entailment     government  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What kind of genres are there in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "telephone     4270\n",
       "slate         4026\n",
       "travel        3985\n",
       "government    3883\n",
       "fiction       3836\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "government    1016\n",
       "telephone     1005\n",
       "slate         1002\n",
       "fiction       995 \n",
       "travel        982 \n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_val['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Evaluating on Multi-NLI\n",
    "\n",
    "You task is to take your best trained model, one each for Logistic Regression and Neural Net based classiﬁer, and evaluate them on the provided MultiNLI data, for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_val_gov = mnli_val[mnli_val['genre'] == 'government']\n",
    "mnli_val_tel = mnli_val[mnli_val['genre'] == 'telephone']\n",
    "mnli_val_slate = mnli_val[mnli_val['genre'] == 'slate']\n",
    "mnli_val_fiction = mnli_val[mnli_val['genre'] == 'fiction']\n",
    "mnli_val_travel = mnli_val[mnli_val['genre'] == 'travel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1016, 4)\n",
      "(1005, 4)\n",
      "(1002, 4)\n",
      "(995, 4)\n",
      "(982, 4)\n"
     ]
    }
   ],
   "source": [
    "print(mnli_val_gov.shape)\n",
    "print(mnli_val_tel.shape)\n",
    "print(mnli_val_slate.shape)\n",
    "print(mnli_val_fiction.shape)\n",
    "print(mnli_val_travel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_val_gov = mnli_val_gov.drop(['genre'], axis = 1).reset_index(drop = True)\n",
    "mnli_val_tel = mnli_val_tel.drop(['genre'], axis = 1).reset_index(drop = True)\n",
    "mnli_val_slate = mnli_val_slate.drop(['genre'], axis = 1).reset_index(drop = True)\n",
    "mnli_val_fiction = mnli_val_fiction.drop(['genre'], axis = 1).reset_index(drop = True)\n",
    "mnli_val_travel = mnli_val_travel.drop(['genre'], axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1016, 3)\n",
      "(1005, 3)\n",
      "(1002, 3)\n",
      "(995, 3)\n",
      "(982, 3)\n"
     ]
    }
   ],
   "source": [
    "print(mnli_val_gov.shape)\n",
    "print(mnli_val_tel.shape)\n",
    "print(mnli_val_slate.shape)\n",
    "print(mnli_val_fiction.shape)\n",
    "print(mnli_val_travel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load best Logistic Regression model\n",
    "\n",
    "Logistic Regression (SNLI Validation Accuracy: 63.3%)\n",
    "\n",
    "- Vocab size: 15000\n",
    "- Embedding dimension: 125 \n",
    "- Interaction: element-wise product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_BagOfWords(nn.Module):\n",
    "    '''\n",
    "    Bag-of-Words classification model.\n",
    "    '''\n",
    "    def __init__(self, vocab_size, emb_dim, interaction):\n",
    "        '''\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding.\n",
    "        @param interaction: the way to combine the two vector representations.\n",
    "        '''\n",
    "        super(LR_BagOfWords, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx = 0)\n",
    "        self.interaction = interaction\n",
    "        if interaction == 'concat':\n",
    "            self.linear = nn.Linear(2 * emb_dim, 3)\n",
    "        else:\n",
    "            self.linear = nn.Linear(emb_dim, 3)\n",
    "        \n",
    "    def forward(self, premise, len_premise, hypothesis, len_hypothesis):\n",
    "        '''\n",
    "        @param premise: matrix of size (batch_size, max_sentence_length). Each row represents a \n",
    "            premise that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param len_premise: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each premise in the data.\n",
    "        @param hypothesis: matrix of size (batch_size, max_sentence_length). Each row represents a \n",
    "            hypothesis that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param len_hypothesis: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each hypothesis in the data.\n",
    "        '''\n",
    "        premise_out = self.embed(premise)\n",
    "        premise_out = torch.sum(premise_out, dim = 1)\n",
    "        premise_out /= len_premise.view(len_premise.size()[0], 1).expand_as(premise_out).float()\n",
    "        \n",
    "        hypothesis_out = self.embed(hypothesis)\n",
    "        hypothesis_out = torch.sum(hypothesis_out, dim = 1)\n",
    "        hypothesis_out /= len_hypothesis.view(len_hypothesis.size()[0], 1).expand_as(hypothesis_out).float()\n",
    "        \n",
    "        # combine the two vector representations\n",
    "        out = self.interaction_func(premise_out, hypothesis_out)\n",
    "     \n",
    "        # return logits\n",
    "        out = self.linear(out.float())\n",
    "        return out\n",
    "    \n",
    "    def interaction_func(self, premise, hypothesis):\n",
    "        '''\n",
    "        Combines the two vector representations based on the specified interaction method.\n",
    "        '''\n",
    "        if self.interaction == 'concat':\n",
    "            return torch.cat((premise, hypothesis), dim = 1)\n",
    "        if self.interaction == 'sum':\n",
    "            return (premise + hypothesis)\n",
    "        if self.interaction == 'element_wise_product':\n",
    "            return (premise * hypothesis)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id = pkl.load(open('tokens/logreg_token2id.p', 'rb'))\n",
    "id2token = pkl.load(open('tokens/logreg_id2token.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15002\n",
      "15002\n"
     ]
    }
   ],
   "source": [
    "print(len(token2id))\n",
    "print(len(id2token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_lr_vocab_size = 15000\n",
    "best_lr_emb_dim = 125 \n",
    "best_lr_interaction = 'element_wise_product'\n",
    "best_lr_path = 'models/best_logreg.pth' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR_BagOfWords(\n",
       "  (embed): Embedding(15002, 125, padding_idx=0)\n",
       "  (linear): Linear(in_features=125, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the best LR model\n",
    "best_lr = LR_BagOfWords(len(id2token), best_lr_emb_dim, best_lr_interaction)\n",
    "best_lr.load_state_dict(torch.load(best_lr_path))\n",
    "best_lr.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "MAX_SENTENCE_LENGTH = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# lowercase and remove punctuation\n",
    "def tokenize(sent):\n",
    "  tokens = tokenizer(sent)\n",
    "  return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    token_dataset = []\n",
    "    all_tokens = []\n",
    "    \n",
    "    for sample in dataset:\n",
    "        tokens = tokenize(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "\n",
    "    return token_dataset, all_tokens\n",
    "\n",
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIDataset(Dataset):\n",
    "    '''\n",
    "    Class that represents a dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, premise_list, hypothesis_list, label_list):\n",
    "        '''\n",
    "        @param premise_list: list of premise tokens \n",
    "        @param hypothesis_list: list of hypothesis tokens\n",
    "        @param label_list: list of labels\n",
    "        '''\n",
    "        self.premise_list = premise_list\n",
    "        self.hypothesis_list = hypothesis_list\n",
    "        self.label_list = label_list.replace({'entailment': 0, 'neutral': 1, 'contradiction': 2})\n",
    "        assert (len(self.premise_list) == len(self.hypothesis_list))\n",
    "        assert (len(self.premise_list) == len(self.label_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.premise_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        '''\n",
    "        Triggered when you call dataset[i]\n",
    "        '''\n",
    "        premise = self.premise_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        hypothesis = self.hypothesis_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.label_list[key]\n",
    "        return [premise, len(premise), hypothesis, len(hypothesis), label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collate Function\n",
    "def snli_data_collate_func(batch):\n",
    "    '''\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length.\n",
    "    '''\n",
    "    premise_list = []\n",
    "    premise_length_list = []\n",
    "    hypothesis_list = []\n",
    "    hypothesis_length_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[4])\n",
    "        premise_length_list.append(datum[1])\n",
    "        hypothesis_length_list.append(datum[3])\n",
    "    \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_p_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width = ((0, MAX_SENTENCE_LENGTH - datum[1])), \n",
    "                                mode = 'constant', constant_values = 0)\n",
    "        premise_list.append(padded_p_vec)\n",
    "        \n",
    "        padded_h_vec = np.pad(np.array(datum[2]), \n",
    "                                pad_width = ((0, MAX_SENTENCE_LENGTH - datum[3])), \n",
    "                                mode = 'constant', constant_values = 0)\n",
    "        hypothesis_list.append(padded_h_vec)\n",
    "        \n",
    "    return [torch.from_numpy(np.array(premise_list)), torch.LongTensor(premise_length_list), \n",
    "            torch.from_numpy(np.array(hypothesis_list)), torch.LongTensor(hypothesis_length_list),\n",
    "            torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all the data processing steps and evaluation into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    '''\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for premise, len_premise, hypothesis, len_hypothesis, labels in loader:\n",
    "        outputs = model(premise, len_premise, hypothesis, len_hypothesis)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, labels)\n",
    "        predicted = F.softmax(outputs, dim = 1).max(1, keepdim = True)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return loss, (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lr_mnli(mnli_val_data, model):\n",
    "    premise_tokens, all_premise_tokens = tokenize_dataset(mnli_val_data['premise'])\n",
    "    hypothesis_tokens, all_hypothesis_tokens = tokenize_dataset(mnli_val_data['hypothesis'])\n",
    "    premise_indices = token2index_dataset(premise_tokens)\n",
    "    hypothesis_indices = token2index_dataset(hypothesis_tokens)\n",
    "    val_dataset = SNLIDataset(premise_indices, hypothesis_indices, mnli_val_data['label'])\n",
    "    val_loader = torch.utils.data.DataLoader(dataset = val_dataset, \n",
    "                                             batch_size = BATCH_SIZE,\n",
    "                                             collate_fn = snli_data_collate_func,\n",
    "                                             shuffle = True)\n",
    "    val_loss, val_acc = test_model(val_loader, model)\n",
    "    return val_loss.item(), val_acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_val_dfs = [mnli_val_gov, mnli_val_tel, mnli_val_slate, mnli_val_fiction, mnli_val_travel]\n",
    "mnli_val_accs_lr = []\n",
    "for df in mnli_val_dfs:\n",
    "    val_acc = evaluate_lr_mnli(df, best_lr)[1]\n",
    "    mnli_val_accs_lr.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37.696850393700785,\n",
       " 35.223880597014926,\n",
       " 39.12175648702595,\n",
       " 41.10552763819096,\n",
       " 34.92871690427699]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_val_accs_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load best Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network (SNLI Validation Accuracy: 65.2%)\n",
    "\n",
    "- Vocab size: 10000\n",
    "- Embedding dimension: 150\n",
    "- Interaction: concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_BagOfWords(nn.Module):\n",
    "    '''\n",
    "    BagOfWords classification model.\n",
    "    '''\n",
    "    def __init__(self, vocab_size, emb_dim, interaction, hidden_dim1, hidden_dim2):\n",
    "        '''\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding.\n",
    "        @param interaction: the way to combine the two vector representations.\n",
    "        @param hidden_dim1: dimension of the first hidden layer of neural nets.\n",
    "        @param hidden_dim2: dimension of the second hidden layer of neural nets.\n",
    "        '''\n",
    "        super(NN_BagOfWords, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx = 0)\n",
    "        self.interaction = interaction\n",
    "        if interaction == 'concat':\n",
    "            self.first_layer = nn.Linear(2 * emb_dim, hidden_dim1)\n",
    "        else:\n",
    "            self.first_layer = nn.Linear(emb_dim, hidden_dim1)\n",
    "        self.second_layer = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.last_linear = nn.Linear(hidden_dim2, 3)\n",
    "    \n",
    "    def forward(self, premise, len_premise, hypothesis, len_hypothesis):\n",
    "        '''\n",
    "        @param premise: matrix of size (batch_size, max_sentence_length). Each row represents a \n",
    "            premise that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param len_premise: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each premise in the data.\n",
    "        @param hypothesis: matrix of size (batch_size, max_sentence_length). Each row represents a \n",
    "            hypothesis that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param len_hypothesis: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each hypothesis in the data.\n",
    "        '''\n",
    "        premise_out = self.embed(premise)\n",
    "        premise_out = torch.sum(premise_out, dim = 1)\n",
    "        premise_out /= len_premise.view(len_premise.size()[0],1).expand_as(premise_out).float()\n",
    "     \n",
    "        hypothesis_out = self.embed(hypothesis)\n",
    "        hypothesis_out = torch.sum(hypothesis_out, dim = 1)\n",
    "        hypothesis_out /= len_hypothesis.view(len_hypothesis.size()[0],1).expand_as(hypothesis_out).float()\n",
    "    \n",
    "        out = self.interaction_func(premise_out, hypothesis_out)\n",
    "        \n",
    "        # return logits\n",
    "        out = F.relu(self.first_layer(out.float()))\n",
    "        out = F.relu(self.second_layer(out))\n",
    "        out = self.last_linear(out)\n",
    "        return out\n",
    "    \n",
    "    def interaction_func(self, premise, hypothesis):\n",
    "        '''\n",
    "        Combines the two vector representations based on the specified interaction method.\n",
    "        '''\n",
    "        if self.interaction == 'concat':\n",
    "            return torch.cat((premise, hypothesis), dim = 1)\n",
    "        if self.interaction == 'sum':\n",
    "            return (premise + hypothesis)\n",
    "        if self.interaction == 'element_wise_product':\n",
    "            return (premise * hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id = pkl.load(open('tokens/nn_token2id.p', 'rb'))\n",
    "id2token = pkl.load(open('tokens/nn_id2token.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10002\n",
      "10002\n"
     ]
    }
   ],
   "source": [
    "print(len(token2id))\n",
    "print(len(id2token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_nn_vocab_size = 10000\n",
    "best_nn_emb_dim = 150\n",
    "best_nn_interaction = 'concat'\n",
    "hidden_dim1 = 50\n",
    "hidden_dim2 = 25\n",
    "best_nn_path = 'models/best_nn.pth' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_BagOfWords(\n",
       "  (embed): Embedding(10002, 150, padding_idx=0)\n",
       "  (first_layer): Linear(in_features=300, out_features=50, bias=True)\n",
       "  (second_layer): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (last_linear): Linear(in_features=25, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the best NN model\n",
    "best_nn = NN_BagOfWords(len(id2token), best_nn_emb_dim, best_nn_interaction, hidden_dim1, hidden_dim2)\n",
    "best_nn.load_state_dict(torch.load(best_nn_path))\n",
    "best_nn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nn_mnli(mnli_val_data, model):\n",
    "    premise_tokens, all_premise_tokens = tokenize_dataset(mnli_val_data['premise'])\n",
    "    hypothesis_tokens, all_hypothesis_tokens = tokenize_dataset(mnli_val_data['hypothesis'])\n",
    "    premise_indices = token2index_dataset(premise_tokens)\n",
    "    hypothesis_indices = token2index_dataset(hypothesis_tokens)\n",
    "    val_dataset = SNLIDataset(premise_indices, hypothesis_indices, mnli_val_data['label'])\n",
    "    val_loader = torch.utils.data.DataLoader(dataset = val_dataset, \n",
    "                                             batch_size = BATCH_SIZE,\n",
    "                                             collate_fn = snli_data_collate_func,\n",
    "                                             shuffle = True)\n",
    "    val_loss, val_acc = test_model(val_loader, model)\n",
    "    return val_loss.item(), val_acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_val_accs_nn = []\n",
    "for df in mnli_val_dfs:\n",
    "    val_acc = evaluate_nn_mnli(df, best_nn)[1]\n",
    "    mnli_val_accs_nn.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40.45275590551181,\n",
       " 43.681592039801,\n",
       " 38.522954091816366,\n",
       " 43.41708542713568,\n",
       " 40.73319755600814]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_val_accs_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['government', 'telephone', 'slate', 'fiction', 'travel']\n",
    "columns = ['Logistic Regression', 'Neural Network']\n",
    "val_accs_df = pd.DataFrame(list(zip(mnli_val_accs_lr, mnli_val_accs_nn)), columns = columns, index = genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Neural Network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>government</td>\n",
       "      <td>37.6969</td>\n",
       "      <td>40.4528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>telephone</td>\n",
       "      <td>35.2239</td>\n",
       "      <td>43.6816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>slate</td>\n",
       "      <td>39.1218</td>\n",
       "      <td>38.5230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fiction</td>\n",
       "      <td>41.1055</td>\n",
       "      <td>43.4171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>travel</td>\n",
       "      <td>34.9287</td>\n",
       "      <td>40.7332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Logistic Regression  Neural Network\n",
       "government 37.6969              40.4528        \n",
       "telephone  35.2239              43.6816        \n",
       "slate      39.1218              38.5230        \n",
       "fiction    41.1055              43.4171        \n",
       "travel     34.9287              40.7332        "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "val_accs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Fine-tuning on MultiNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will ﬁne-tune our SNLI model on training data for each MultiNLI genre (training set), and evaluate it on that genre (validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_BagOfWords(\n",
       "  (embed): Embedding(10002, 150, padding_idx=0)\n",
       "  (first_layer): Linear(in_features=300, out_features=50, bias=True)\n",
       "  (second_layer): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (last_linear): Linear(in_features=25, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best trained SNLI model\n",
    "best_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "telephone     4270\n",
       "slate         4026\n",
       "travel        3985\n",
       "government    3883\n",
       "fiction       3836\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare training data for each genre\n",
    "mnli_train['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train_tel = mnli_train[mnli_train['genre'] == 'telephone']\n",
    "mnli_train_slate = mnli_train[mnli_train['genre'] == 'slate']\n",
    "mnli_train_travel = mnli_train[mnli_train['genre'] == 'travel']\n",
    "mnli_train_gov = mnli_train[mnli_train['genre'] == 'government']\n",
    "mnli_train_fiction = mnli_train[mnli_train['genre'] == 'fiction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4270, 4)\n",
      "(4026, 4)\n",
      "(3985, 4)\n",
      "(3883, 4)\n",
      "(3836, 4)\n"
     ]
    }
   ],
   "source": [
    "print(mnli_train_tel.shape)\n",
    "print(mnli_train_slate.shape)\n",
    "print(mnli_train_travel.shape)\n",
    "print(mnli_train_gov.shape)\n",
    "print(mnli_train_fiction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train_tel = mnli_train_tel.drop(['genre'], axis = 1).reset_index(drop = True)\n",
    "mnli_train_slate = mnli_train_slate.drop(['genre'], axis = 1).reset_index(drop = True)\n",
    "mnli_train_travel = mnli_train_travel.drop(['genre'], axis = 1).reset_index(drop = True)\n",
    "mnli_train_gov = mnli_train_gov.drop(['genre'], axis = 1).reset_index(drop = True)\n",
    "mnli_train_fiction = mnli_train_fiction.drop(['genre'], axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4270, 3)\n",
      "(4026, 3)\n",
      "(3985, 3)\n",
      "(3883, 3)\n",
      "(3836, 3)\n"
     ]
    }
   ],
   "source": [
    "print(mnli_train_tel.shape)\n",
    "print(mnli_train_slate.shape)\n",
    "print(mnli_train_travel.shape)\n",
    "print(mnli_train_gov.shape)\n",
    "print(mnli_train_fiction.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our SNLI model is already trained, we do not need (nor want) to over-train our model. Hence, we can continue training just on a small number of epochs, or use a lower learning rate.\n",
    "\n",
    "Let's try `num_epochs` = 5, `learning_rate` = 0.001 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(best_nn.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10002, 150])\n",
      "torch.Size([50, 300])\n",
      "torch.Size([50])\n",
      "torch.Size([25, 50])\n",
      "torch.Size([25])\n",
      "torch.Size([3, 25])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# double checking\n",
    "for x in best_nn.parameters():\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_genre_model(model, train_genre_loader, val_genre_loader, num_epochs, val_1 = 50, val_2 = 100):\n",
    "    '''\n",
    "    Train model and evaluate for a specific genre.\n",
    "    '''\n",
    "    start = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (premise, len_premise, hypothesis, len_hypothesis, labels) in enumerate(train_genre_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(premise, len_premise, hypothesis, len_hypothesis)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print training loss every val_1 iterations\n",
    "            if i > 0 and i % val_1 == 0:\n",
    "                print(f'Epoch: [{epoch+1}/{num_epochs}], Step: [{i+1}/{len(train_genre_loader)}], Train Loss: {loss:.4f}')\n",
    "\n",
    "            # validate every val_2 iterations\n",
    "            if i > 0 and i % val_2 == 0:\n",
    "                # validate\n",
    "                val_loss, val_acc = test_model(val_genre_loader, model)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Acc: {}'\n",
    "                      .format(epoch+1, num_epochs, i+1, len(train_genre_loader), loss, val_loss, val_acc))\n",
    "        print('-'*50)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print('Final Stats:')\n",
    "    print('After training for {} epochs'.format(num_epochs))\n",
    "    train_loss, train_acc = test_model(train_genre_loader, model)\n",
    "    print('Train Loss: {:.4f}, Train Accuracy: {}'.format(train_loss, train_acc))\n",
    "    val_loss, val_acc = test_model(val_genre_loader, model)\n",
    "    print('Val loss: {:.4f}, Val Accuracy: {}'.format(val_loss, val_acc))\n",
    "\n",
    "    print(f'Total training time: {time.time() - start}')\n",
    "    return val_acc, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, batch_size = 32):\n",
    "    '''\n",
    "    Creates PyTorch DataLoader from a DataFrame for model training and evaluation.\n",
    "    '''\n",
    "    premise_tokens, all_premise_tokens = tokenize_dataset(df['premise'])\n",
    "    hypothesis_tokens, all_hypothesis_tokens = tokenize_dataset(df['hypothesis'])\n",
    "    premise_indices = token2index_dataset(premise_tokens)\n",
    "    hypothesis_indices = token2index_dataset(hypothesis_tokens)\n",
    "    dataset = SNLIDataset(premise_indices, hypothesis_indices, df['label'])\n",
    "    loader = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         collate_fn = snli_data_collate_func,\n",
    "                                         shuffle = True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tel_loader = create_data_loader(mnli_train_tel)\n",
    "train_slate_loader = create_data_loader(mnli_train_slate)\n",
    "train_travel_loader = create_data_loader(mnli_train_travel)\n",
    "train_gov_loader = create_data_loader(mnli_train_gov)\n",
    "train_fiction_loader = create_data_loader(mnli_train_fiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tel_loader = create_data_loader(mnli_val_tel)\n",
    "val_slate_loader = create_data_loader(mnli_val_slate)\n",
    "val_travel_loader = create_data_loader(mnli_val_travel)\n",
    "val_gov_loader = create_data_loader(mnli_val_gov)\n",
    "val_fiction_loader = create_data_loader(mnli_val_fiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [51/122], Train Loss: 0.9939\n",
      "Epoch: [1/5], Step: [101/122], Train Loss: 1.1811\n",
      "Epoch: [1/5], Step: [101/122], Train Loss: 1.1811, Validation Loss: 1.2477, Validation Acc: 45.07874015748032\n",
      "--------------------------------------------------\n",
      "Epoch: [2/5], Step: [51/122], Train Loss: 0.9461\n",
      "Epoch: [2/5], Step: [101/122], Train Loss: 0.9862\n",
      "Epoch: [2/5], Step: [101/122], Train Loss: 0.9862, Validation Loss: 1.0220, Validation Acc: 47.24409448818898\n",
      "--------------------------------------------------\n",
      "Epoch: [3/5], Step: [51/122], Train Loss: 0.9370\n",
      "Epoch: [3/5], Step: [101/122], Train Loss: 0.8111\n",
      "Epoch: [3/5], Step: [101/122], Train Loss: 0.8111, Validation Loss: 1.0948, Validation Acc: 48.12992125984252\n",
      "--------------------------------------------------\n",
      "Epoch: [4/5], Step: [51/122], Train Loss: 0.9101\n",
      "Epoch: [4/5], Step: [101/122], Train Loss: 0.6499\n",
      "Epoch: [4/5], Step: [101/122], Train Loss: 0.6499, Validation Loss: 1.1584, Validation Acc: 48.12992125984252\n",
      "--------------------------------------------------\n",
      "Epoch: [5/5], Step: [51/122], Train Loss: 0.7527\n",
      "Epoch: [5/5], Step: [101/122], Train Loss: 0.8055\n",
      "Epoch: [5/5], Step: [101/122], Train Loss: 0.8055, Validation Loss: 1.0048, Validation Acc: 47.83464566929134\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Stats:\n",
      "After training for 5 epochs\n",
      "Train Loss: 0.6335, Train Accuracy: 69.68838526912181\n",
      "Val loss: 0.8214, Val Accuracy: 46.75196850393701\n",
      "Total training time: 8.498979091644287\n"
     ]
    }
   ],
   "source": [
    "# government\n",
    "val_acc_gov, model_gov = train_genre_model(best_nn, train_gov_loader, val_gov_loader, num_epochs)\n",
    "torch.save(model_gov.state_dict(), 'models/model_gov.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [51/134], Train Loss: 1.0533\n",
      "Epoch: [1/5], Step: [101/134], Train Loss: 1.0438\n",
      "Epoch: [1/5], Step: [101/134], Train Loss: 1.0438, Validation Loss: 1.0230, Validation Acc: 43.18407960199005\n",
      "--------------------------------------------------\n",
      "Epoch: [2/5], Step: [51/134], Train Loss: 0.9272\n",
      "Epoch: [2/5], Step: [101/134], Train Loss: 1.0601\n",
      "Epoch: [2/5], Step: [101/134], Train Loss: 1.0601, Validation Loss: 1.1692, Validation Acc: 45.57213930348259\n",
      "--------------------------------------------------\n",
      "Epoch: [3/5], Step: [51/134], Train Loss: 1.0609\n",
      "Epoch: [3/5], Step: [101/134], Train Loss: 0.9378\n",
      "Epoch: [3/5], Step: [101/134], Train Loss: 0.9378, Validation Loss: 0.9825, Validation Acc: 47.960199004975124\n",
      "--------------------------------------------------\n",
      "Epoch: [4/5], Step: [51/134], Train Loss: 0.9295\n",
      "Epoch: [4/5], Step: [101/134], Train Loss: 0.9514\n",
      "Epoch: [4/5], Step: [101/134], Train Loss: 0.9514, Validation Loss: 1.2954, Validation Acc: 46.26865671641791\n",
      "--------------------------------------------------\n",
      "Epoch: [5/5], Step: [51/134], Train Loss: 0.6784\n",
      "Epoch: [5/5], Step: [101/134], Train Loss: 0.6246\n",
      "Epoch: [5/5], Step: [101/134], Train Loss: 0.6246, Validation Loss: 1.4873, Validation Acc: 45.07462686567164\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Stats:\n",
      "After training for 5 epochs\n",
      "Train Loss: 0.4856, Train Accuracy: 74.63700234192038\n",
      "Val loss: 1.1058, Val Accuracy: 46.666666666666664\n",
      "Total training time: 9.848854780197144\n"
     ]
    }
   ],
   "source": [
    "# telephone\n",
    "val_acc_tel, model_tel = train_genre_model(best_nn, train_tel_loader, val_tel_loader, num_epochs)\n",
    "torch.save(model_tel.state_dict(), 'models/model_tel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [51/126], Train Loss: 1.0707\n",
      "Epoch: [1/5], Step: [101/126], Train Loss: 1.0819\n",
      "Epoch: [1/5], Step: [101/126], Train Loss: 1.0819, Validation Loss: 0.9088, Validation Acc: 41.417165668662676\n",
      "--------------------------------------------------\n",
      "Epoch: [2/5], Step: [51/126], Train Loss: 1.0024\n",
      "Epoch: [2/5], Step: [101/126], Train Loss: 1.0874\n",
      "Epoch: [2/5], Step: [101/126], Train Loss: 1.0874, Validation Loss: 0.7009, Validation Acc: 42.81437125748503\n",
      "--------------------------------------------------\n",
      "Epoch: [3/5], Step: [51/126], Train Loss: 1.0118\n",
      "Epoch: [3/5], Step: [101/126], Train Loss: 1.0712\n",
      "Epoch: [3/5], Step: [101/126], Train Loss: 1.0712, Validation Loss: 0.7466, Validation Acc: 41.31736526946108\n",
      "--------------------------------------------------\n",
      "Epoch: [4/5], Step: [51/126], Train Loss: 0.8895\n",
      "Epoch: [4/5], Step: [101/126], Train Loss: 1.0374\n",
      "Epoch: [4/5], Step: [101/126], Train Loss: 1.0374, Validation Loss: 1.6993, Validation Acc: 42.41516966067864\n",
      "--------------------------------------------------\n",
      "Epoch: [5/5], Step: [51/126], Train Loss: 0.6671\n",
      "Epoch: [5/5], Step: [101/126], Train Loss: 0.6787\n",
      "Epoch: [5/5], Step: [101/126], Train Loss: 0.6787, Validation Loss: 1.2089, Validation Acc: 42.81437125748503\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Stats:\n",
      "After training for 5 epochs\n",
      "Train Loss: 0.5069, Train Accuracy: 74.44113263785395\n",
      "Val loss: 1.1333, Val Accuracy: 41.11776447105788\n",
      "Total training time: 9.999510049819946\n"
     ]
    }
   ],
   "source": [
    "# slate\n",
    "val_acc_slate, model_slate = train_genre_model(best_nn, train_slate_loader, val_slate_loader, num_epochs)\n",
    "torch.save(model_slate.state_dict(), 'models/model_slate.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [51/120], Train Loss: 1.1900\n",
      "Epoch: [1/5], Step: [101/120], Train Loss: 0.9569\n",
      "Epoch: [1/5], Step: [101/120], Train Loss: 0.9569, Validation Loss: 0.9110, Validation Acc: 44.02010050251256\n",
      "--------------------------------------------------\n",
      "Epoch: [2/5], Step: [51/120], Train Loss: 0.9135\n",
      "Epoch: [2/5], Step: [101/120], Train Loss: 0.9029\n",
      "Epoch: [2/5], Step: [101/120], Train Loss: 0.9029, Validation Loss: 0.8610, Validation Acc: 46.733668341708544\n",
      "--------------------------------------------------\n",
      "Epoch: [3/5], Step: [51/120], Train Loss: 0.6393\n",
      "Epoch: [3/5], Step: [101/120], Train Loss: 0.8558\n",
      "Epoch: [3/5], Step: [101/120], Train Loss: 0.8558, Validation Loss: 0.8840, Validation Acc: 47.93969849246231\n",
      "--------------------------------------------------\n",
      "Epoch: [4/5], Step: [51/120], Train Loss: 0.6479\n",
      "Epoch: [4/5], Step: [101/120], Train Loss: 0.6801\n",
      "Epoch: [4/5], Step: [101/120], Train Loss: 0.6801, Validation Loss: 1.7502, Validation Acc: 48.44221105527638\n",
      "--------------------------------------------------\n",
      "Epoch: [5/5], Step: [51/120], Train Loss: 0.6534\n",
      "Epoch: [5/5], Step: [101/120], Train Loss: 0.4644\n",
      "Epoch: [5/5], Step: [101/120], Train Loss: 0.4644, Validation Loss: 0.9217, Validation Acc: 47.437185929648244\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Stats:\n",
      "After training for 5 epochs\n",
      "Train Loss: 0.6782, Train Accuracy: 81.83003128258602\n",
      "Val loss: 1.1474, Val Accuracy: 46.834170854271356\n",
      "Total training time: 10.224982023239136\n"
     ]
    }
   ],
   "source": [
    "# fiction\n",
    "val_acc_fiction, model_fiction = train_genre_model(best_nn, train_fiction_loader, val_fiction_loader, num_epochs)\n",
    "torch.save(model_fiction.state_dict(), 'models/model_fiction.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [51/125], Train Loss: 1.0403\n",
      "Epoch: [1/5], Step: [101/125], Train Loss: 1.0341\n",
      "Epoch: [1/5], Step: [101/125], Train Loss: 1.0341, Validation Loss: 0.9516, Validation Acc: 45.11201629327902\n",
      "--------------------------------------------------\n",
      "Epoch: [2/5], Step: [51/125], Train Loss: 0.9570\n",
      "Epoch: [2/5], Step: [101/125], Train Loss: 1.0023\n",
      "Epoch: [2/5], Step: [101/125], Train Loss: 1.0023, Validation Loss: 1.1595, Validation Acc: 43.788187372708755\n",
      "--------------------------------------------------\n",
      "Epoch: [3/5], Step: [51/125], Train Loss: 0.7789\n",
      "Epoch: [3/5], Step: [101/125], Train Loss: 0.7905\n",
      "Epoch: [3/5], Step: [101/125], Train Loss: 0.7905, Validation Loss: 1.0877, Validation Acc: 42.973523421588595\n",
      "--------------------------------------------------\n",
      "Epoch: [4/5], Step: [51/125], Train Loss: 0.6550\n",
      "Epoch: [4/5], Step: [101/125], Train Loss: 0.7023\n",
      "Epoch: [4/5], Step: [101/125], Train Loss: 0.7023, Validation Loss: 1.1686, Validation Acc: 47.25050916496945\n",
      "--------------------------------------------------\n",
      "Epoch: [5/5], Step: [51/125], Train Loss: 0.5675\n",
      "Epoch: [5/5], Step: [101/125], Train Loss: 0.6942\n",
      "Epoch: [5/5], Step: [101/125], Train Loss: 0.6942, Validation Loss: 1.0390, Validation Acc: 45.723014256619145\n",
      "--------------------------------------------------\n",
      "\n",
      "Final Stats:\n",
      "After training for 5 epochs\n",
      "Train Loss: 0.6302, Train Accuracy: 77.76662484316185\n",
      "Val loss: 1.0323, Val Accuracy: 43.890020366598776\n",
      "Total training time: 11.531609058380127\n"
     ]
    }
   ],
   "source": [
    "# travel\n",
    "val_acc_travel, model_travel = train_genre_model(best_nn, train_travel_loader, val_travel_loader, num_epochs)\n",
    "torch.save(model_travel.state_dict(), 'models/model_travel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_val_accs_finetuned_nn = [val_acc_gov, val_acc_tel, val_acc_slate, val_acc_fiction, val_acc_travel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['government', 'telephone', 'slate', 'fiction', 'travel']\n",
    "columns = ['Without Fine-tuning', 'With Fine-tuning']\n",
    "val_accs_df2 = pd.DataFrame(list(zip(mnli_val_accs_nn, mnli_val_accs_finetuned_nn)), columns = columns, index = genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Without Fine-tuning</th>\n",
       "      <th>With Fine-tuning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>government</td>\n",
       "      <td>40.4528</td>\n",
       "      <td>46.7520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>telephone</td>\n",
       "      <td>43.6816</td>\n",
       "      <td>46.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>slate</td>\n",
       "      <td>38.5230</td>\n",
       "      <td>41.1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fiction</td>\n",
       "      <td>43.4171</td>\n",
       "      <td>46.8342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>travel</td>\n",
       "      <td>40.7332</td>\n",
       "      <td>43.8900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Without Fine-tuning  With Fine-tuning\n",
       "government 40.4528              46.7520          \n",
       "telephone  43.6816              46.6667          \n",
       "slate      38.5230              41.1178          \n",
       "fiction    43.4171              46.8342          \n",
       "travel     40.7332              43.8900          "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "val_accs_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further evaluate each ﬁne-tuned model on every other genre, to see if that ﬁne-tuning carries over to the other genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_genre(model_path, loader_ls):\n",
    "    '''\n",
    "    Load a fine-tuned model and evaluate the model on every other genre.\n",
    "    '''\n",
    "    model= NN_BagOfWords(len(id2token), best_nn_emb_dim, best_nn_interaction, hidden_dim1, hidden_dim2)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    val_accs = []\n",
    "    for loader in loader_ls:\n",
    "        val_acc = test_model(loader, model)[1]\n",
    "        val_accs.append(val_acc)\n",
    "    return val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_model_path = 'models/model_gov.pth'\n",
    "tel_model_path = 'models/model_tel.pth'\n",
    "slate_model_path = 'models/model_slate.pth'\n",
    "fiction_model_path = 'models/model_fiction.pth'\n",
    "travel_model_path = 'models/model_travel.pth'\n",
    "loader_ls = [val_gov_loader, val_tel_loader, val_slate_loader, val_fiction_loader, val_travel_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40.45275590551181,\n",
       " 43.681592039801,\n",
       " 38.522954091816366,\n",
       " 43.41708542713568,\n",
       " 40.73319755600814]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without fine-tuning\n",
    "mnli_val_accs_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the fine-tuned model on every other genre\n",
    "val_accs_gov = eval_model_genre(gov_model_path, loader_ls)\n",
    "val_accs_tel = eval_model_genre(tel_model_path, loader_ls)\n",
    "val_accs_slate = eval_model_genre(slate_model_path, loader_ls)\n",
    "val_accs_fiction = eval_model_genre(fiction_model_path, loader_ls)\n",
    "val_accs_travel = eval_model_genre(travel_model_path, loader_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_genres = ['government', 'telephone', 'slate', 'fiction', 'travel']\n",
    "idx_models = ['No Fine-tuning', 'Fine-tuned on government', 'Fine-tuned on telephone', 'Fine-tuned on slate',\n",
    "              'Fine-tuned on fiction', 'Fine-tuned on travel']\n",
    "val_accs_df3 = pd.DataFrame([mnli_val_accs_nn, val_accs_gov, val_accs_tel, \n",
    "                            val_accs_slate, val_accs_fiction, val_accs_travel], columns = col_genres, index = idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>government</th>\n",
       "      <th>telephone</th>\n",
       "      <th>slate</th>\n",
       "      <th>fiction</th>\n",
       "      <th>travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>No Fine-tuning</td>\n",
       "      <td>40.4528</td>\n",
       "      <td>43.6816</td>\n",
       "      <td>38.5230</td>\n",
       "      <td>43.4171</td>\n",
       "      <td>40.7332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fine-tuned on government</td>\n",
       "      <td>46.7520</td>\n",
       "      <td>45.5721</td>\n",
       "      <td>39.5210</td>\n",
       "      <td>42.9146</td>\n",
       "      <td>42.5662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fine-tuned on telephone</td>\n",
       "      <td>47.5394</td>\n",
       "      <td>46.6667</td>\n",
       "      <td>41.5170</td>\n",
       "      <td>44.1206</td>\n",
       "      <td>42.7699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fine-tuned on slate</td>\n",
       "      <td>47.2441</td>\n",
       "      <td>46.2687</td>\n",
       "      <td>41.1178</td>\n",
       "      <td>42.7136</td>\n",
       "      <td>44.3992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fine-tuned on fiction</td>\n",
       "      <td>45.6693</td>\n",
       "      <td>45.8706</td>\n",
       "      <td>40.8184</td>\n",
       "      <td>46.8342</td>\n",
       "      <td>46.1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fine-tuned on travel</td>\n",
       "      <td>47.0472</td>\n",
       "      <td>45.6716</td>\n",
       "      <td>41.4172</td>\n",
       "      <td>46.3317</td>\n",
       "      <td>43.8900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          government  telephone   slate  fiction  travel\n",
       "No Fine-tuning           40.4528     43.6816    38.5230 43.4171  40.7332\n",
       "Fine-tuned on government 46.7520     45.5721    39.5210 42.9146  42.5662\n",
       "Fine-tuned on telephone  47.5394     46.6667    41.5170 44.1206  42.7699\n",
       "Fine-tuned on slate      47.2441     46.2687    41.1178 42.7136  44.3992\n",
       "Fine-tuned on fiction    45.6693     45.8706    40.8184 46.8342  46.1303\n",
       "Fine-tuned on travel     47.0472     45.6716    41.4172 46.3317  43.8900"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "val_accs_df3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
